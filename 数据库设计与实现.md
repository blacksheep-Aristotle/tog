# 表的逻辑结构



- 外键（关联两个表的列）

  再单独建一个表，记录两个列的映射

  ![image-20221128041251865](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128041251865.png)



##  存储引擎

**为什么不适用操作系统自带的磁盘管理模块**

操作系统并不知道我们的数据库系统在做什么，操作系统只看到了要将这些page进行换入和换出，操作系统只能看到对这些页面进行的写入和读取操作，他无法理解高级的语义，要查询什么，要去读取哪些数据。

操作系统的磁盘管理模块并没有、也不可能会有 DBMS 中的领域知识，因此 DBMS 比 操作系统拥有更多、更充分的知识来决定数据移动的时机和数量，具体包括：

- 将 dirty pages 按正确地顺序写到磁盘
- 根据具体情况预获取数据（预存数据）
- 定制化缓存置换（buffer replacement）策略
- 线程/进程调度

如果我们想要通过mmap来将文件内容保存到某个进程的地址空间，我们无须无需自己绞尽脑汁的在数据库系统中来搞，只需要交给操作系统就行了，无须关心读取写入文件背后的任何事情。

使用操作系统的mmap，如果是读取文件还好说。但如果是写入文件就会出现问题，操作系统并不知道某些pages必须要在其他pages执行之前先从内存刷到磁盘上——日志和并发控制会涉及到。但是可以给操作系统一些“提示”来解决这个问题。

- madvise: 告诉操作系统您希望如何读取某些pages。
- mlock: 告诉操作系统内存中哪些范围的pages不能被调出（阻止pages被回收）。
- msync: 告诉操作系统将哪些内存范围中的pages刷新到磁盘。

实际上并没有多少使用操作系统mmap的数据库系统，下列数据库使用了操作系统的mmap：

[![img](数据库设计与实现/word-image-6.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-6.png)

上述的数据库使用mmap，但仍然需要做一些额外的事情来防止操作系统做出错误的事情。

下列是部分使用mmap的数据库系统，有些会提供特定的设定才会启用mmap，在默认情况下不会使用mmap。

[![img](数据库设计与实现/word-image-7.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-7.png)

实际上很多系统都是不使用mmap的，他们会使用一些buffer池之类的技术：

主流数据库MySQL、DB2、Oracle、SQL server等都没有使用mmap。

总之，老师认为数据库系统使用mmap是很糟糕的，**因为数据库总是很确定的知道查询要做什么，知道工作负载是怎么样的，数据库系统可以作出最佳选择，但是操作系统什么都不知道，他只知道读取、写入文件。**

再后面我们会讨论如果不使用mmap，我们也会使用预存、更好的替换策略、更好的调度之类的东西。

总之，操作系统并不是你的朋友，你不能依赖他，我们应该尽可能尝试避开他。他可能会做出对我们数据库系统有害的决策。操作系统既是朋友也是敌人。

**第一层：磁盘存储**

**问题一：如何表示磁盘上文件中的数据？**

数据库就是磁盘上的一堆文件。sqlite的数据库就是一个db文件,以文件的形式存储在磁盘上，以一页（5kb-16kb）为一文件块，但其他大部分数据库会将这些东西分为多个文件保存。

操作系统并不知道这个db文件是什么，操作系统只知道这是一堆二进制数据。这些文件的格式通常不是通用的，每个DBMS的数据库文件格式都是专属于某个DBMS的。

这些数据库文件通常会存放在操作系统提供给我们的文件系统中，我们**基于操作系统文件管理的API来对文件进行读写**。

在1980年代，人们尝试在裸存储设备（没有操作系统）上构建自定义文件系统的数据库系统，**在某些高端企业级数据库系统还会自己有一套文件管理系统**，并不需要操作系统的文件系统提供接口来读写数据库文件，是裸体运行在一块磁盘上的。但近些年新的DBMS往往不用裸体运行这种方式，因为这种方式开发DBMS会把大量时间用在文件系统上，也大大降低了可移植性，文件系统这显然不是数据库的研究重点。

本节所要构建的是存储管理器，或者叫存储引擎。他是我们数据库系统中的一个组件，负责维护在磁盘上的数据库文件。在某些高端数据库系统，他们在文件系统之上还有个shim层，会允许数据库去做一些磁盘调度，例如可以通过一堆线程来对彼此邻近的区块进行写入，可以将这些块合并，作为一次写入请求。但是大部分的数据库系统都没有shim层，我们课程实验也不涉及到shim内容，这是高级课程中的。

问：放入磁盘上的单个文件有大小限制，请问放在内存中的文件是否有大小限制？

答：如果是虚拟内存则没有限制，但操作系统会限制物理内存大小，

问：操作系统是否会对进程创建文件有数量限制？

答： 并不会限制创建文件的数量，但是通常在打开所创建的文件的时候会有句柄数的限制。



![image-20221128042348907](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128042348907.png)



**将对应页的数据写入磁盘，也就是写入文件对应偏移量的位置**

```c++
void DiskManager::WritePage(page_id_t page_id, const char *page_data) {
  std::scoped_lock scoped_db_io_latch(db_io_latch_);
  //这一页存储的数据在文件中的位置
  size_t offset = static_cast<size_t>(page_id) * PAGE_SIZE;
  // set write cursor to offset
  num_writes_ += 1;
  db_io_.seekp(offset); //偏移offset的量
  db_io_.write(page_data, PAGE_SIZE);
  // check for I/O error
  if (db_io_.bad()) {
    LOG_DEBUG("I/O error while writing");
    return;
  }
  // needs to flush to keep disk file in sync
  db_io_.flush();
}

```

**读取对应页面的数据**

```c++
void DiskManager::ReadPage(page_id_t page_id, char *page_data) {
  std::scoped_lock scoped_db_io_latch(db_io_latch_);
  int offset = page_id * PAGE_SIZE;
  // check if read beyond file length
  if (offset > GetFileSize(file_name_)) {
    LOG_DEBUG("I/O error reading past end of file");
    // std::cerr << "I/O error while reading" << std::endl;
  } else {
    // set read cursor to offset
    db_io_.seekp(offset);
    db_io_.read(page_data, PAGE_SIZE);
    if (db_io_.bad()) {
      LOG_DEBUG("I/O error while reading");
      return;
    }
    // if file ends before reading PAGE_SIZE
    int read_count = db_io_.gcount();
    if (read_count < PAGE_SIZE) {
      LOG_DEBUG("Read less than a page");
      db_io_.clear();
      // std::cerr << "Read less than a page" << std::endl;
      memset(page_data + read_count, 0, PAGE_SIZE - read_count);
    }
  }
}

```





### 页面结构

#### **如何在page上组织数据库？**

数据库page：

1. Page是一个固定大小的数据块，一个page能够保存任何东西，可以保存数据库里面的tuple，也可以保存元数据、索引、日志。
2. 现在有些数据库要求page是self-contained的，也就是说该表的内容的元数据存储在一个page中，该表内容的tuple存储在另一个page中，如果数据库schema布局的那个page灭失就不能解释这个表内容的元数据了（表的列意义、列属性、列类型等）。所以现在某些数据库系统例如Oracle就需要元数据的page和内容数据的page一同保存在同一个page中。
3. 另外大多数系统不会在page中混合使用不同类型的数据。
4. 每个page都会被赋予一个唯一的内容标识符，数据库系统会生成page ID。考虑到有时候会将数据库系统的page移动至另一个磁盘、压缩磁盘等操作，所以系统还有一个indirection层，记录了page ID和位置信息，这样indirection就会告诉我们page ID对应在什么位置，以保证我们移动磁盘时候page ID不会发生改变。

硬件page、操作系统page和数据库page 需要分清楚：

- 硬件Page：通常大小为 4KB
- 操作系统Page: 通常大小为 4KB
- 数据库Page：(1-16KB)

[![img](数据库设计与实现/word-image-9.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-9.png)

[<img src="数据库设计与实现/word-image-10.png" alt="img" style="zoom:50%;" />](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-10.png)

1. 每种数据库的page都不一定相同，最低是512bytes（512字节）。有些高级的数据库系统允许数据库管理员设定page的大小。
2. 我们主要关心的是**hardware page**，他是我们执行**原子写入存储设备**的最底层的东西。如果我们写入8Kb的数据，一个**hardware page**是4Kb，分成两页也能写入，但是这样虽然都写入了，但是这两段数据并不连续，导致写入的16kb数据并不具备原子性，失败后不会回滚。

#### 如何将这些page存储在文件中？

不同 DBMS 管理 pages 的方式不同，主要分为以下几种：

- 堆文件组织
- 连续/分类文件组织
- hash文件组织

**堆文件组织**

堆文件组织：

- 它是最简单，最基础的组织类型。它适用于数据块。**在堆文件组织中，记录将插入文件的末尾。**插入记录时，不需要对记录进行排序和排序。
- 当数据块已满时，新记录将存储在其他某个块中。这个新数据块不必是下一个数据块，但是它可以选择内存中的任何数据块来存储新记录。堆文件也称为无序文件。
- 在文件中，每个记录都有唯一的ID，并且文件中的每个页面都具有相同的大小。DBMS负责存储和管理新记录。
- heap file 指的是一个无序的 pages 集合，pages 管理模块需要记录哪些 pages 已经被使用，而哪些 pages 尚未被使用。那么具体如何来记录和管理呢？主要有以下两种方法 Linked List 和 Page Directory。

**方法过程**

[![DBMS Heap文件组织](https://gaozhiyuan.net/wp-content/uploads/2022/03/dbms-heap.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/dbms-heap.png)

**插入新记录**

假设我们在堆中有五个记录R1，R3，R6，R4和R5，并且我们想在堆中插入新记录R2。如果数据块3已满，那么它将被插入DBMS选择的任何数据库中，比方说数据块1。

[![DBMS Heap文件组织](https://gaozhiyuan.net/wp-content/uploads/2022/03/dbms-heap-1.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/dbms-heap-1.png)

**搜索**

如果要搜索，更新或删除堆文件组织中的数据，则需要遍历文件的开头直到获得请求的记录为止。如果数据库非常大，则由于没有记录的排序或排序，因此搜索，更新或删除记录将非常耗时。在堆文件组织中，我们需要检查所有数据，直到获得请求的记录。

**优点和缺点**

堆文件组织的优点

- 这是用于批量插入的非常好的文件组织方法。如果一次需要将大量数据加载到数据库中，则此方法最适合。
- 对于小型数据库，记录的获取和检索比顺序记录要快。

堆文件组织的缺点

- 对于大型数据库，此方法效率不高，因为它需要花费时间来搜索或修改记录。
- 对于大型数据库，此方法效率低下。

**堆文件组织通常使用一个Page Direct，这个page Directory不仅有page所在的物理位置，也有这个page的额外信息（剩余空间。。。）**

<img src="数据库设计与实现/word-image-15.png" alt="img" style="zoom:50%;" />

**存储data的page通常使用slotted page**

slotted pages含有Header和Tuple。如下图所示，header 中的 slot array 记录每个 slot 的信息，如大小、位移等。下面tuple的长度不必限制都是等长的，完全可以变长。

每一个page都有 header。

在header 中通常包含以下信息：

- Page 大小
- Checksum
  - checksum在故障恢复中有用，[![img](数据库设计与实现/word-image-18.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-18.png)，在第一个page的header里面会放一个checksum，[![img](数据库设计与实现/word-image-19.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-19.png)

当从故障中恢复后，会查看最后一个page中所计算出的checksum，发现和预定的值不匹配是因为数据没有写进去，于是就报错。——这一部分在后面的日志中讨论。

![image-20221128043247975](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128043247975.png)

bus中的page Header：记录了这个page的pageid和前后页的pageid，存储的tuple数量，指向存储着tuple的内存的开头指针，一个tuple的大小

```c++
Header format (size in bytes):
 *  ----------------------------------------------------------------------------
 *  | PageId (4)| LSN (4)| PrevPageId (4)| NextPageId (4)| FreeSpacePointer(4) |
 *  ----------------------------------------------------------------------------
 *  ----------------------------------------------------------------
 *  | TupleCount (4) | Tuple_1 offset (4) | Tuple_1 size (4) | ... |
 *  ----------------------------------------------------------------
```

页面一分为二，使用一个从头往后增的slot数组，每个元素记载相应tuple在页面中的偏移量。一个从尾往前增的tuple数组

![image-20221128043703181](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128043703181.png)

- 如何存储行元素？

  行中元素为null的属性怎么表示？

![image-20221128043625815](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128043625815.png)

- 如何精确的表示数字？

  - 将数字变成字符串

    ![image-20221128044137854](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128044137854.png)

  - 使用结构体来表示数字

    ![image-20221128044247399](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128044247399.png)

- tuple比一页还大时如何存储

![image-20221128044424536](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20221128044424536.png)



#### 存储页面

**page只负责内存管理，不涉及页面内部数据结构的存放，页面内部管理是由继承page的子类自行设计**

```c++

/**
	page：
	| data   |<--mem_point
	| data   |
	| data   |	从mem_point到下来连续的4kbit内存，对页读写就是从mem_point开始读取4kbit数据
	| ...... |
			  <--end

 * Slotted page format:
 *  ---------------------------------------------------------
 *  | HEADER | ... FREE SPACE ... | ... INSERTED TUPLES ... |
 *  ---------------------------------------------------------
 *                                ^
 *                                free space pointer
 *
 *  Header format (size in bytes):
 *  ----------------------------------------------------------------------------
 *  | PageId (4)| LSN (4)| PrevPageId (4)| NextPageId (4)| FreeSpacePointer(4) |
 *  ----------------------------------------------------------------------------
 *  ----------------------------------------------------------------
 *  | TupleCount (4) | Tuple_1 offset (4) | Tuple_1 size (4) | ... |
 *  ----------------------------------------------------------------
 *
 */
```

cmu的存储页面是一个继承basepage的派生页，每一页是一个4kb大小的连续内存。

所有page的子类的全部数据结构都必须在char data_[PAGE_SIZE]{};中！也就是说读写page实质上就是读写data _.在通过reter _cast<>(data _)将数据转换成我们定义的tuple page

```c++
class Page {
  // There is book-keeping information inside the page that should only be relevant to the buffer pool manager.
  friend class BufferPoolManagerInstance;

 public:
  /** Constructor. Zeros out the page data. */
  Page() { ResetMemory(); }

  /** Default destructor. */
  ~Page() = default;

  /** @return the actual data contained within this page */
  inline char *GetData() { return data_; }

  /** @return the page id of this page */
  inline page_id_t GetPageId() { return page_id_; }

  /** @return the pin count of this page */
  inline int GetPinCount() { return pin_count_; }

  /** @return true if the page in memory has been modified from the page on disk, false otherwise */
  inline bool IsDirty() { return is_dirty_; }

  /** Acquire the page write latch. */
  inline void WLatch() { rwlatch_.WLock(); }

  /** Release the page write latch. */
  inline void WUnlatch() { rwlatch_.WUnlock(); }

  /** Acquire the page read latch. */
  inline void RLatch() { rwlatch_.RLock(); }

  /** Release the page read latch. */
  inline void RUnlatch() { rwlatch_.RUnlock(); }

  /** @return the page LSN. */
  inline lsn_t GetLSN() { return *reinterpret_cast<lsn_t *>(GetData() + OFFSET_LSN); }

  /** Sets the page LSN. */
  inline void SetLSN(lsn_t lsn) { memcpy(GetData() + OFFSET_LSN, &lsn, sizeof(lsn_t)); }

 protected:
  static_assert(sizeof(page_id_t) == 4);
  static_assert(sizeof(lsn_t) == 4);

  static constexpr size_t SIZE_PAGE_HEADER = 8;
  static constexpr size_t OFFSET_PAGE_START = 0;
  static constexpr size_t OFFSET_LSN = 4;

 private:
  /** Zeroes out the data that is held within the page. */
  inline void ResetMemory() { memset(data_, OFFSET_PAGE_START, PAGE_SIZE); }

  /** The actual data that is stored within a page. */
  char data_[PAGE_SIZE]{};
  /** The ID of this page. */
  page_id_t page_id_ = INVALID_PAGE_ID;
  /** The pin count of this page. */
  int pin_count_ = 0;
  /** True if the page is dirty, i.e. it is different from its corresponding page on disk. */
  bool is_dirty_ = false;
  /** Page latch. */
  ReaderWriterLatch rwlatch_;
};

```



#### Slotpage

Tablepage就是slotpage，在basepage上增加了对tuple的序列反序列和操作函数的封装。因为slotpage的所有成员变量都必须包含在data_ 里，所以我们不能在额外添加成员变量！！

那么怎么表示slotpage的header和tuple呢？

我们事先定义好各个成员变量在data_中的位置（位移量），再通过reter _cast<>转成我们需要的类型即可。并且位移量用static定义，使其存储在区，而不占用data _的空间。

```c++

/**
 * Slotted page format:
 *  ---------------------------------------------------------
 *  | HEADER | ... FREE SPACE ... | ... INSERTED TUPLES ... |
 *  ---------------------------------------------------------
 *                                ^
 *                                free space pointer
   Header format (size in bytes 32):
 *  ----------------------------------------------------------------------------
 *  | PageId (4)| LSN (4)| PrevPageId (4)| NextPageId (4)| FreeSpacePointer(4) |
 *  ----------------------------------------------------------------------------
 *  ----------------------------------------------------------------
 *  | TupleCount (4) | Tuple_1 offset (4) | Tuple_1 size (4) | ... FREE SPACE|
 *  ----------------------------------------------------------------
```

![image-20221128043703181](file://C:/Users/asus/AppData/Roaming/Typora/typora-user-images/image-20221128043703181.png?lastModify=1673350013)

- 主要功能：
  - 增删改查tuple，获取前/下一页pageid
  - 如何获取增删改查tuple的内存位置----data_+对应的偏移量

**constexpr**：将表达式提前在编译器执行，而不是等到运行时再执行。提高执行效率。constexpr 可用于修饰普通变量、函数（包括模板函数）以及类的构造函数。

```c++

class TablePage : public Page {
 public:
  /**
   * Initialize the TablePage header.
   * @param page_id the page ID of this table page
   * @param page_size the size of this table page
   * @param prev_page_id the previous table page ID
   * @param log_manager the log manager in use
   * @param txn the transaction that this page is created in
   */
  void Init(page_id_t page_id, uint32_t page_size, page_id_t prev_page_id, LogManager *log_manager, Transaction *txn);

  /** @return the page ID of this table page */
  page_id_t GetTablePageId() { return *reinterpret_cast<page_id_t *>(GetData()); }

  /** @return the page ID of the previous table page */
  page_id_t GetPrevPageId() { return *reinterpret_cast<page_id_t *>(GetData() + OFFSET_PREV_PAGE_ID); }

  /** @return the page ID of the next table page */
  page_id_t GetNextPageId() { return *reinterpret_cast<page_id_t *>(GetData() + OFFSET_NEXT_PAGE_ID); }

  /** Set the page id of the previous page in the table. */
  void SetPrevPageId(page_id_t prev_page_id) {
    memcpy(GetData() + OFFSET_PREV_PAGE_ID, &prev_page_id, sizeof(page_id_t));
  }

  /** Set the page id of the next page in the table. */
  void SetNextPageId(page_id_t next_page_id) {
    memcpy(GetData() + OFFSET_NEXT_PAGE_ID, &next_page_id, sizeof(page_id_t));
  }

  /**
   * Insert a tuple into the table.
   * @param tuple tuple to insert
   * @param[out] rid rid of the inserted tuple
   * @param txn transaction performing the insert
   * @param lock_manager the lock manager
   * @param log_manager the log manager
   * @return true if the insert is successful (i.e. there is enough space)
   */
  bool InsertTuple(const Tuple &tuple, RID *rid, Transaction *txn, LockManager *lock_manager, LogManager *log_manager);
  {
  BUSTUB_ASSERT(tuple.size_ > 0, "Cannot have empty tuples.");
  // If there is not enough space, then return false.
  if (GetFreeSpaceRemaining() < tuple.size_ + SIZE_TUPLE) {
    return false;
  }
   // Try to find a free slot to reuse.
  uint32_t i;
  for (i = 0; i < GetTupleCount(); i++) {
    // If the slot is empty, i.e. its tuple has size 0,
    if (GetTupleSize(i) == 0) {
      // Then we break out of the loop at index i.
      break;
    }
  }

  // If there was no free slot left, and we cannot claim it from the free space, then we give up.
  if (i == GetTupleCount() && GetFreeSpaceRemaining() < tuple.size_ + SIZE_TUPLE) {
    return false;
  }

  // Otherwise we claim available free space..
  SetFreeSpacePointer(GetFreeSpacePointer() - tuple.size_);
  memcpy(GetData() + GetFreeSpacePointer(), tuple.data_, tuple.size_);

  // Set the tuple.
  SetTupleOffsetAtSlot(i, GetFreeSpacePointer());
  SetTupleSize(i, tuple.size_);

  rid->Set(GetTablePageId(), i);
  if (i == GetTupleCount()) {
    SetTupleCount(GetTupleCount() + 1);
  }

  // Write the log record.
  if (enable_logging) {
    BUSTUB_ASSERT(!txn->IsSharedLocked(*rid) && !txn->IsExclusiveLocked(*rid), "A new tuple should not be locked.");
    // Acquire an exclusive lock on the new tuple.
    bool locked = lock_manager->LockExclusive(txn, *rid);
    BUSTUB_ASSERT(locked, "Locking a new tuple should always work.");
    LogRecord log_record(txn->GetTransactionId(), txn->GetPrevLSN(), LogRecordType::INSERT, *rid, tuple);
    lsn_t lsn = log_manager->AppendLogRecord(&log_record);
    SetLSN(lsn);
    txn->SetPrevLSN(lsn);
  }
  return true;
      
  }
  /**
   * Mark a tuple as deleted. This does not actually delete the tuple.
   * @param rid rid of the tuple to mark as deleted
   * @param txn transaction performing the delete
   * @param lock_manager the lock manager
   * @param log_manager the log manager
   * @return true if marking the tuple as deleted is successful (i.e the tuple exists)
   */
  bool MarkDelete(const RID &rid, Transaction *txn, LockManager *lock_manager, LogManager *log_manager);
{
  uint32_t slot_num = rid.GetSlotNum();
  // If the slot number is invalid, abort the transaction.
  if (slot_num >= GetTupleCount()) {
    if (enable_logging) {
      txn->SetState(TransactionState::ABORTED);
    }
    return false;
  }

  uint32_t tuple_size = GetTupleSize(slot_num);
  // If the tuple is already deleted, abort the transaction.
  if (IsDeleted(tuple_size)) {
    if (enable_logging) {
      txn->SetState(TransactionState::ABORTED);
    }
    return false;
  }

  if (enable_logging) {
    // Acquire an exclusive lock, upgrading from a shared lock if necessary.
    if (txn->IsSharedLocked(rid)) {
      if (!lock_manager->LockUpgrade(txn, rid)) {
        return false;
      }
    } else if (!txn->IsExclusiveLocked(rid) && !lock_manager->LockExclusive(txn, rid)) {
      return false;
    }
    Tuple dummy_tuple;
    LogRecord log_record(txn->GetTransactionId(), txn->GetPrevLSN(), LogRecordType::MARKDELETE, rid, dummy_tuple);
    lsn_t lsn = log_manager->AppendLogRecord(&log_record);
    SetLSN(lsn);
    txn->SetPrevLSN(lsn);
  }

  // Mark the tuple as deleted.
  if (tuple_size > 0) {
    SetTupleSize(slot_num, SetDeletedFlag(tuple_size));
  }
  return true;
}
  /**
   * Update a tuple.
   * @param new_tuple new value of the tuple
   * @param[out] old_tuple old value of the tuple
   * @param rid rid of the tuple
   * @param txn transaction performing the update
   * @param lock_manager the lock manager
   * @param log_manager the log manager
   * @return true if updating the tuple succeeded
   */
  bool UpdateTuple(const Tuple &new_tuple, Tuple *old_tuple, const RID &rid, Transaction *txn,
                   LockManager *lock_manager, LogManager *log_manager);
  {
  BUSTUB_ASSERT(new_tuple.size_ > 0, "Cannot have empty tuples.");
  uint32_t slot_num = rid.GetSlotNum();
  // If the slot number is invalid, abort the transaction.
  if (slot_num >= GetTupleCount()) {
    if (enable_logging) {
      txn->SetState(TransactionState::ABORTED);
    }
    return false;
  }
  uint32_t tuple_size = GetTupleSize(slot_num);
  // If the tuple is deleted, abort the transaction.
  if (IsDeleted(tuple_size)) {
    if (enable_logging) {
      txn->SetState(TransactionState::ABORTED);
    }
    return false;
  }
  // If there is not enuogh space to update, we need to update via delete followed by an insert (not enough space).
  if (GetFreeSpaceRemaining() + tuple_size < new_tuple.size_) {
    return false;
  }

  // Copy out the old value.
  uint32_t tuple_offset = GetTupleOffsetAtSlot(slot_num);
  old_tuple->size_ = tuple_size;
  if (old_tuple->allocated_) {
    delete[] old_tuple->data_;
  }
  old_tuple->data_ = new char[old_tuple->size_];
  memcpy(old_tuple->data_, GetData() + tuple_offset, old_tuple->size_);
  old_tuple->rid_ = rid;
  old_tuple->allocated_ = true;

  if (enable_logging) {
    // Acquire an exclusive lock, upgrading from shared if necessary.
    if (txn->IsSharedLocked(rid)) {
      if (!lock_manager->LockUpgrade(txn, rid)) {
        return false;
      }
    } else if (!txn->IsExclusiveLocked(rid) && !lock_manager->LockExclusive(txn, rid)) {
      return false;
    }
    LogRecord log_record(txn->GetTransactionId(), txn->GetPrevLSN(), LogRecordType::UPDATE, rid, *old_tuple, new_tuple);
    lsn_t lsn = log_manager->AppendLogRecord(&log_record);
    SetLSN(lsn);
    txn->SetPrevLSN(lsn);
  }

  // Perform the update.
  uint32_t free_space_pointer = GetFreeSpacePointer();
  BUSTUB_ASSERT(tuple_offset >= free_space_pointer, "Offset should appear after current free space position.");

  memmove(GetData() + free_space_pointer + tuple_size - new_tuple.size_, GetData() + free_space_pointer,
          tuple_offset - free_space_pointer);
  SetFreeSpacePointer(free_space_pointer + tuple_size - new_tuple.size_);
  memcpy(GetData() + tuple_offset + tuple_size - new_tuple.size_, new_tuple.data_, new_tuple.size_);
  SetTupleSize(slot_num, new_tuple.size_);

  // Update all tuple offsets.
  for (uint32_t i = 0; i < GetTupleCount(); ++i) {
    uint32_t tuple_offset_i = GetTupleOffsetAtSlot(i);
    if (GetTupleSize(i) > 0 && tuple_offset_i < tuple_offset + tuple_size) {
      SetTupleOffsetAtSlot(i, tuple_offset_i + tuple_size - new_tuple.size_);
    }
  }
  return true;
}


  /** To be called on commit or abort. Actually perform the delete or rollback an insert. */
  void ApplyDelete(const RID &rid, Transaction *txn, LogManager *log_manager);

  /** To be called on abort. Rollback a delete, i.e. this reverses a MarkDelete. */
  void RollbackDelete(const RID &rid, Transaction *txn, LogManager *log_manager);

  /**
   * Read a tuple from a table.
   * @param rid rid of the tuple to read
   * @param[out] tuple the tuple that was read
   * @param txn transaction performing the read
   * @param lock_manager the lock manager
   * @return true if the read is successful (i.e. the tuple exists)
   */
  bool GetTuple(const RID &rid, Tuple *tuple, Transaction *txn, LockManager *lock_manager);
{
  // Get the current slot number.
  uint32_t slot_num = rid.GetSlotNum();
  // If somehow we have more slots than tuples, abort the transaction.
  if (slot_num >= GetTupleCount()) {
    if (enable_logging) {
      txn->SetState(TransactionState::ABORTED);
    }
    return false;
  }
  // Otherwise get the current tuple size too.
  uint32_t tuple_size = GetTupleSize(slot_num);
  // If the tuple is deleted, abort the transaction.
  if (IsDeleted(tuple_size)) {
    if (enable_logging) {
      txn->SetState(TransactionState::ABORTED);
    }
    return false;
  }

  // Otherwise we have a valid tuple, try to acquire at least a shared lock.
  if (enable_logging) {
    if (!txn->IsSharedLocked(rid) && !txn->IsExclusiveLocked(rid) && !lock_manager->LockShared(txn, rid)) {
      return false;
    }
  }

  // At this point, we have at least a shared lock on the RID. Copy the tuple data into our result.
  uint32_t tuple_offset = GetTupleOffsetAtSlot(slot_num);
  tuple->size_ = tuple_size;
  if (tuple->allocated_) {
    delete[] tuple->data_;
  }
  tuple->data_ = new char[tuple->size_];
  memcpy(tuple->data_, GetData() + tuple_offset, tuple->size_);
  tuple->rid_ = rid;
  tuple->allocated_ = true;
  return true;
}

  /** @return the rid of the first tuple in this page */

  /**
   * @param[out] first_rid the RID of the first tuple in this page
   * @return true if the first tuple exists, false otherwise
   */
  bool GetFirstTupleRid(RID *first_rid);

  /**
   * @param cur_rid the RID of the current tuple
   * @param[out] next_rid the RID of the tuple following the current tuple
   * @return true if the next tuple exists, false otherwise
   */
  bool GetNextTupleRid(const RID &cur_rid, RID *next_rid);

 private:
  static_assert(sizeof(page_id_t) == 4);

  static constexpr size_t SIZE_TABLE_PAGE_HEADER = 24;
  static constexpr size_t SIZE_TUPLE = 8;
  static constexpr size_t OFFSET_PREV_PAGE_ID = 8;
  static constexpr size_t OFFSET_NEXT_PAGE_ID = 12;
  static constexpr size_t OFFSET_FREE_SPACE = 16;
  static constexpr size_t OFFSET_TUPLE_COUNT = 20;
  static constexpr size_t OFFSET_TUPLE_OFFSET = 24;  // Naming things is hard.
  static constexpr size_t OFFSET_TUPLE_SIZE = 28;

  /** @return pointer to the end of the current free space, see header comment */
  uint32_t GetFreeSpacePointer() { return *reinterpret_cast<uint32_t *>(GetData() + OFFSET_FREE_SPACE); }

  /** Sets the pointer, this should be the end of the current free space. */
  void SetFreeSpacePointer(uint32_t free_space_pointer) {
    memcpy(GetData() + OFFSET_FREE_SPACE, &free_space_pointer, sizeof(uint32_t));
  }

  /**
   * @note returned tuple count may be an overestimate because some slots may be empty
   * @return at least the number of tuples in this page
   */
  uint32_t GetTupleCount() { return *reinterpret_cast<uint32_t *>(GetData() + OFFSET_TUPLE_COUNT); }

  /** Set the number of tuples in this page. */
  void SetTupleCount(uint32_t tuple_count) { memcpy(GetData() + OFFSET_TUPLE_COUNT, &tuple_count, sizeof(uint32_t)); }

  uint32_t GetFreeSpaceRemaining() {
    return GetFreeSpacePointer() - SIZE_TABLE_PAGE_HEADER - SIZE_TUPLE * GetTupleCount();
  }

  /** @return tuple offset at slot slot_num */
  uint32_t GetTupleOffsetAtSlot(uint32_t slot_num) {
    return *reinterpret_cast<uint32_t *>(GetData() + OFFSET_TUPLE_OFFSET + SIZE_TUPLE * slot_num);
  }

  /** Set tuple offset at slot slot_num. */
  void SetTupleOffsetAtSlot(uint32_t slot_num, uint32_t offset) {
    memcpy(GetData() + OFFSET_TUPLE_OFFSET + SIZE_TUPLE * slot_num, &offset, sizeof(uint32_t));
  }

  /** @return tuple size at slot slot_num */
  uint32_t GetTupleSize(uint32_t slot_num) {
    return *reinterpret_cast<uint32_t *>(GetData() + OFFSET_TUPLE_SIZE + SIZE_TUPLE * slot_num);
  }

  /** Set tuple size at slot slot_num. */
  void SetTupleSize(uint32_t slot_num, uint32_t size) {
    memcpy(GetData() + OFFSET_TUPLE_SIZE + SIZE_TUPLE * slot_num, &size, sizeof(uint32_t));
  }

  /** @return true if the tuple is deleted or empty */
  static bool IsDeleted(uint32_t tuple_size) { return static_cast<bool>(tuple_size & DELETE_MASK) || tuple_size == 0; }

  /** @return tuple size with the deleted flag set */
  static uint32_t SetDeletedFlag(uint32_t tuple_size) { return static_cast<uint32_t>(tuple_size | DELETE_MASK); }

  /** @return tuple size with the deleted flag unset */
  static uint32_t UnsetDeletedFlag(uint32_t tuple_size) { return static_cast<uint32_t>(tuple_size & (~DELETE_MASK)); }
};
```

实际上，bus通过一个tablepage将slotpage聚合起来，对tuple的增删改查是通过tablepage执行的，tablepage定位到对应的slotpage再调用该page的函数

- tableHeap

TableHeap本质上是由Page组成的链表。在每个page中，按slot存储tuple中的data。TableHeap类本身并不存储schema，schema存储在catalog中。

TableHeapIterator用于对TableHeap进行遍历。它本仅存储一个当前Tuple。在取*时返回该tuple；在递增(++)时，取出该tuple中的rid，在table中定位对应的slot。然后逐slot向下遍历，直至找到下一个valid rid。

TableHeap表示磁盘上的物理表。一个双重链接的页面列表。对接收的tuple和Rid定位到对应到tuple所在的page，并对其增删改查

相较于soltpage，相当于多了一个定位页面的功能。

**insert tuple**

```c++
//从第一页不断往下插入，直到第一个空闲的页面，在该页面插入tuple
while (!cur_page->InsertTuple(tuple, rid, txn, lock_manager_, log_manager_)) {
    auto next_page_id = cur_page->GetNextPageId();
    // If the next page is a valid page,
    if (next_page_id != INVALID_PAGE_ID) {
      // Unlatch and unpin the current page.
      cur_page->WUnlatch();
      buffer_pool_manager_->UnpinPage(cur_page->GetTablePageId(), false);
      // And repeat the process with the next page.
      cur_page = static_cast<TablePage *>(buffer_pool_manager_->FetchPage(next_page_id));
      cur_page->WLatch();
    } else {
      // Otherwise we have run out of valid pages. We need to create a new page.
      auto new_page = static_cast<TablePage *>(buffer_pool_manager_->NewPage(&next_page_id));
      // If we could not create a new page,
      if (new_page == nullptr) {
        // Then life sucks and we abort the transaction.
        cur_page->WUnlatch();
        buffer_pool_manager_->UnpinPage(cur_page->GetTablePageId(), false);
        txn->SetState(TransactionState::ABORTED);
        return false;
      }
      // Otherwise we were able to create a new page. We initialize it now.
      new_page->WLatch();
      cur_page->SetNextPageId(next_page_id);
      new_page->Init(next_page_id, PAGE_SIZE, cur_page->GetTablePageId(), log_manager_, txn);
      cur_page->WUnlatch();
      buffer_pool_manager_->UnpinPage(cur_page->GetTablePageId(), true);
      cur_page = new_page;
    }
  }
```

**删除**

首先标记要删除的tuple，等到真正删除的时候在将之前标记的tuple删除

```c++
bool TableHeap::MarkDelete(const RID &rid, Transaction *txn) {
  // TODO(Amadou): remove empty page
  // Find the page which contains the tuple.
  auto page = reinterpret_cast<TablePage *>(buffer_pool_manager_->FetchPage(rid.GetPageId()));
  // If the page could not be found, then abort the transaction.
  if (page == nullptr) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }
  // Otherwise, mark the tuple as deleted.
  page->WLatch();
  page->MarkDelete(rid, txn, lock_manager_, log_manager_);
  page->WUnlatch();
  buffer_pool_manager_->UnpinPage(page->GetTablePageId(), true);
  // Update the transaction's write set.
  txn->GetWriteSet()->emplace_back(rid, WType::DELETE, Tuple{}, this);
  return true;
}

void TableHeap::ApplyDelete(const RID &rid, Transaction *txn) {
  // Find the page which contains the tuple.
  auto page = reinterpret_cast<TablePage *>(buffer_pool_manager_->FetchPage(rid.GetPageId()));
  BUSTUB_ASSERT(page != nullptr, "Couldn't find a page containing that RID.");
  // Delete the tuple from the page.
  page->WLatch();
  page->ApplyDelete(rid, txn, log_manager_);
  lock_manager_->Unlock(txn, rid);
  page->WUnlatch();
  buffer_pool_manager_->UnpinPage(page->GetTablePageId(), true);
}
```



### 元组结构

![image-20230108200440276](数据库设计与实现/image-20230108200440276.png)

- Schema的本质是vector of columns。它描述了一个tuple内存储的数据。

- Column包含该column的名字、类型，以及一个Expression（optional），描述该column如何构造。注意这个Expression的类型应为ColumnExpression，在执行projection时用到。

- Tuple存储了一行数据。它包含Data和RID。**注意，tuple中不存储schema**；TableHeap中不直接在page中保存tuple，而是保存serialize后的tuple data（二进制）。

- Value表示一个值（Int、Char、Varchar等）。用一个Value vector和一个schema，可以构建一个tuple。

- RID记录tuple的存储位置。包括page id+slot id。

- Expression以树的形式递归地表示一个表达式。Expression共包含Const、Comparison、Column、Aggregation四种类型，分别用于不同的场合。下面加以详细阐述：

[<img src="数据库设计与实现/word-image-35.png" alt="img" style="zoom:50%;" />](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-35.png)

本质上，一个tuple就是一串字节序列，DBMS有解码方案去解释这些字节序列。

[<img src="数据库设计与实现/word-image-36.png" alt="img" style="zoom:50%;" />](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-36.png)

[<img src="数据库设计与实现/word-image-37.png" alt="img" style="zoom:50%;" />](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-37.png)

[<img src="数据库设计与实现/word-image-38.png" alt="img" style="zoom:50%;" />](https://gaozhiyuan.net/wp-content/uploads/2022/03/word-image-38.png)

#### tuble

tuble以行为单位，存储多个col对应的value。所以tuble的读写要配合schema来操作。根据schema的col类型和col对应value的offset从内存中获取对应的value data。

```c++

class Tuple {
  friend class TablePage;
  friend class TableHeap;
  friend class TableIterator;

 public:
  // Default constructor (to create a dummy tuple)
  Tuple() = default;

  // constructor for table heap tuple
  explicit Tuple(RID rid) : rid_(rid) {}

  // constructor for creating a new tuple based on input value
  Tuple(std::vector<Value> values, const Schema *schema);

  // copy constructor, deep copy
  Tuple(const Tuple &other);

  // assign operator, deep copy
  Tuple &operator=(const Tuple &other);

  ~Tuple() {
    if (allocated_) {
      delete[] data_;
    }
    allocated_ = false;
    data_ = nullptr;
  }
  // serialize tuple data
  void SerializeTo(char *storage) const;

  // deserialize tuple data(deep copy)
  void DeserializeFrom(const char *storage);

  // return RID of current tuple
  inline RID GetRid() const { return rid_; }

  // Get the address of this tuple in the table's backing store
  inline char *GetData() const { return data_; }

  // Get length of the tuple, including varchar legth
  inline uint32_t GetLength() const { return size_; }

  // Get the value of a specified column (const)
  // checks the schema to see how to return the Value.
  Value GetValue(const Schema *schema, uint32_t column_idx) const;

  // Generates a key tuple given schemas and attributes
  Tuple KeyFromTuple(const Schema &schema, const Schema &key_schema, const std::vector<uint32_t> &key_attrs);

  // Is the column value null ?
  inline bool IsNull(const Schema *schema, uint32_t column_idx) const {
    Value value = GetValue(schema, column_idx);
    return value.IsNull();
  }
  inline bool IsAllocated() { return allocated_; }

  std::string ToString(const Schema *schema) const;

 private:
  // Get the starting storage address of specific column
  const char *GetDataPtr(const Schema *schema, uint32_t column_idx) const;

  bool allocated_{false};  // is allocated?
  RID rid_{};              // if pointing to the table heap, the rid is valid
  uint32_t size_{0};
  char *data_{nullptr};	   //如果tuple数据没有存放在页面中，tuple自己分配内存
};

```

RID:记录了tuple所在的物理page和在改页面的slot号

```c++

class RID {
 public:
  /** The default constructor creates an invalid RID! */
  RID() = default;

  /**
   * Creates a new Record Identifier for the given page identifier and slot number.
   * @param page_id page identifier
   * @param slot_num slot number
   */
  RID(page_id_t page_id, uint32_t slot_num) : page_id_(page_id), slot_num_(slot_num) {}

  explicit RID(int64_t rid) : page_id_(static_cast<page_id_t>(rid >> 32)), slot_num_(static_cast<uint32_t>(rid)) {}

  inline int64_t Get() const { return (static_cast<int64_t>(page_id_)) << 32 | slot_num_; }

  inline page_id_t GetPageId() const { return page_id_; }

  inline uint32_t GetSlotNum() const { return slot_num_; }

  inline void Set(page_id_t page_id, uint32_t slot_num) {
    page_id_ = page_id;
    slot_num_ = slot_num;
  }

  inline std::string ToString() const {
    std::stringstream os;
    os << "page_id: " << page_id_;
    os << " slot_num: " << slot_num_ << "\n";

    return os.str();
  }

  friend std::ostream &operator<<(std::ostream &os, const RID &rid) {
    os << rid.ToString();
    return os;
  }

  bool operator==(const RID &other) const { return page_id_ == other.page_id_ && slot_num_ == other.slot_num_; }

 private:
  page_id_t page_id_{INVALID_PAGE_ID};
  uint32_t slot_num_{0};  // logical offset from 0, 1...
};

}  // namespace bustub

namespace std {
template <>
struct hash<bustub::RID> {
  size_t operator()(const bustub::RID &obj) const { return hash<int64_t>()(obj.Get()); }
};
```



#### value

- value负责数据的序列化和反序列化，将value序列化成二进制数据保存在tuple中，从tuple中的二进制数据解析成value

```c++

// A value is an abstract class that represents a view over SQL data stored in
// some materialized state. All values have a type and comparison functions, but
// subclasses implement other type-specific functionality.
class Value {
  // Friend Type classes
  friend class Type;
  friend class NumericType;
  friend class IntegerParentType;
  friend class TinyintType;
  friend class SmallintType;
  friend class IntegerType;
  friend class BigintType;
  friend class DecimalType;
  friend class TimestampType;
  friend class BooleanType;
  friend class VarlenType;

 public:
  //enum TypeId { INVALID = 0, BOOLEAN, TINYINT, SMALLINT, INTEGER, BIGINT, DECIMAL, VARCHAR, TIMESTAMP };表示值的类型
  explicit Value(const TypeId type) : manage_data_(false), type_id_(type) { size_.len_ = BUSTUB_VALUE_NULL; }
  //重构构造函数。以满足各类val的创建
  // BOOLEAN and TINYINT
  Value(TypeId type, int8_t i);
  // DECIMAL
  Value(TypeId type, double d);
  Value(TypeId type, float f);
  // SMALLINT
  Value(TypeId type, int16_t i);
  // INTEGER
  Value(TypeId type, int32_t i);
  // BIGINT
  Value(TypeId type, int64_t i);
  // TIMESTAMP
  Value(TypeId type, uint64_t i);
  // VARCHAR
  Value(TypeId type, const char *data, uint32_t len, bool manage_data);
  Value(TypeId type, const std::string &data);

  Value() : Value(TypeId::INVALID) {}
  Value(const Value &other);
  Value &operator=(Value other);
  ~Value();
  // NOLINTNEXTLINE
    
  //
  friend void Swap(Value &first, Value &second) {
    std::swap(first.value_, second.value_);
    std::swap(first.size_, second.size_);
    std::swap(first.manage_data_, second.manage_data_);
    std::swap(first.type_id_, second.type_id_);
  }
  // 是否是int型
  bool CheckInteger() const;
  bool CheckComparable(const Value &o) const;

  // Get the type of this value
  inline TypeId GetTypeId() const { return type_id_; }

  // val长度
  inline uint32_t GetLength() const { return Type::GetInstance(type_id_)->GetLength(*this); }
  // 获取val的值
  inline const char *GetData() const { return Type::GetInstance(type_id_)->GetData(*this); }

  template <class T>
  inline T GetAs() const {
    return *reinterpret_cast<const T *>(&value_);
  }

  inline Value CastAs(const TypeId type_id) const { return Type::GetInstance(type_id_)->CastAs(*this, type_id); }
  // Comparison Methods
  //比较函数
  inline CmpBool CompareEquals(const Value &o) const { return Type::GetInstance(type_id_)->CompareEquals(*this, o); }
  inline CmpBool CompareNotEquals(const Value &o) const {
    return Type::GetInstance(type_id_)->CompareNotEquals(*this, o);
  }
  inline CmpBool CompareLessThan(const Value &o) const {
    return Type::GetInstance(type_id_)->CompareLessThan(*this, o);
  }
  inline CmpBool CompareLessThanEquals(const Value &o) const {
    return Type::GetInstance(type_id_)->CompareLessThanEquals(*this, o);
  }
  inline CmpBool CompareGreaterThan(const Value &o) const {
    return Type::GetInstance(type_id_)->CompareGreaterThan(*this, o);
  }
  inline CmpBool CompareGreaterThanEquals(const Value &o) const {
    return Type::GetInstance(type_id_)->CompareGreaterThanEquals(*this, o);
  }

  // Other mathematical functions
  //对val增删改查大小余
  inline Value Add(const Value &o) const { return Type::GetInstance(type_id_)->Add(*this, o); }
  inline Value Subtract(const Value &o) const { return Type::GetInstance(type_id_)->Subtract(*this, o); }
  inline Value Multiply(const Value &o) const { return Type::GetInstance(type_id_)->Multiply(*this, o); }
  inline Value Divide(const Value &o) const { return Type::GetInstance(type_id_)->Divide(*this, o); }
  inline Value Modulo(const Value &o) const { return Type::GetInstance(type_id_)->Modulo(*this, o); }
  inline Value Min(const Value &o) const { return Type::GetInstance(type_id_)->Min(*this, o); }
  inline Value Max(const Value &o) const { return Type::GetInstance(type_id_)->Max(*this, o); }
  inline Value Sqrt() const { return Type::GetInstance(type_id_)->Sqrt(*this); }

  inline Value OperateNull(const Value &o) const { return Type::GetInstance(type_id_)->OperateNull(*this, o); }
  inline bool IsZero() const { return Type::GetInstance(type_id_)->IsZero(*this); }
  inline bool IsNull() const { return size_.len_ == BUSTUB_VALUE_NULL; }

  // Serialize this value into the given storage space. The inlined parameter
  // indicates whether we are allowed to inline this value into the storage
  // space, or whether we must store only a reference to this value. If inlined
  // is false, we may use the provided data pool to allocate space for this
  // value, storing a reference into the allocated pool space in the storage.
  /*
  	将此值序列化到给定的存储空间中。内联参数指示是否允许将此值内联到存储中空间，
  	或者是否必须仅存储对此值的引用。如果内联为false，我们可以使用提供的数据池为此分配空间值，
  	将引用存储到存储器中分配的池空间中
  */
  inline void SerializeTo(char *storage) const { Type::GetInstance(type_id_)->SerializeTo(*this, storage); }
  /*

void BigintType::SerializeTo(const Value &val, char *storage) const {
  *reinterpret_cast<int64_t *>(storage) = val.value_.bigint_;
}

// Deserialize a value of the given type from the given storage space.
Value BigintType::DeserializeFrom(const char *storage) const {
  int64_t val = *reinterpret_cast<const int64_t *>(storage);
  return Value(type_id_, val);
}
  */
  
  // Deserialize a value of the given type from the given storage space.
  
  inline static Value DeserializeFrom(const char *storage, const TypeId type_id) {
    return Type::GetInstance(type_id)->DeserializeFrom(storage);
  }

  // Return a string version of this value
  inline std::string ToString() const { return Type::GetInstance(type_id_)->ToString(*this); }
  // Create a copy of this value
  inline Value Copy() const { return Type::GetInstance(type_id_)->Copy(*this); }

 protected:
  // The actual value item
  union Val {
    int8_t boolean_;
    int8_t tinyint_;
    int16_t smallint_;
    int32_t integer_;
    int64_t bigint_;
    double decimal_;
    uint64_t timestamp_;
    char *varlen_;
    const char *const_varlen_;
  } value_;

  union {
    uint32_t len_;
    TypeId elem_type_id_;
  } size_;

  bool manage_data_;
  // The data type
  TypeId type_id_;
};
```



#### col

Column包含该column的名字、类型，**在tuple中的位移**，描述value在tuple中的位置和类别。以及一个Expression（optional），描述该column如何构造(构造出的是一个Value)。注意这个Expression的类型应为ColumnExpression，在执行projection时用到。

```c++

class Column {
  friend class Schema;

 public:
  /**
   * Non-variable-length constructor for creating a Column.
   * @param column_name name of the column
   * @param type type of the column
   * @param expr expression used to create this column
   */
  Column(std::string column_name, TypeId type, const AbstractExpression *expr = nullptr)
      : column_name_(std::move(column_name)), column_type_(type), fixed_length_(TypeSize(type)), expr_{expr} {
    BUSTUB_ASSERT(type != TypeId::VARCHAR, "Wrong constructor for VARCHAR type.");
  }

  /**
   * Variable-length constructor for creating a Column.
   * @param column_name name of the column
   * @param type type of column
   * @param length length of the varlen
   * @param expr expression used to create this column
   */
  Column(std::string column_name, TypeId type, uint32_t length, const AbstractExpression *expr = nullptr)
      : column_name_(std::move(column_name)), column_type_(type), fixed_length_(TypeSize(type)), expr_{expr} {
    BUSTUB_ASSERT(type == TypeId::VARCHAR, "Wrong constructor for non-VARCHAR type.");
  }

  /** @return column name */
  std::string GetName() const { return column_name_; }

  /** @return column length */
  uint32_t GetLength() const {
    if (IsInlined()) {
      return fixed_length_;
    }
    return variable_length_;
  }

  /** @return column fixed length */
  uint32_t GetFixedLength() const { return fixed_length_; }

  /** @return column variable length */
  uint32_t GetVariableLength() const { return variable_length_; }

  /** @return column's offset in the tuple */
  uint32_t GetOffset() const { return column_offset_; }

  /** @return column type */
  TypeId GetType() const { return column_type_; }

  /** @return true if column is inlined, false otherwise */
  bool IsInlined() const { return column_type_ != TypeId::VARCHAR; }

  /** @return a string representation of this column */
  std::string ToString() const;

  /** @return the expression used to create this column */
  const AbstractExpression *GetExpr() const { return expr_; }

 private:
  /**
   * Return the size in bytes of the type.
   * @param type type whose size is to be determined
   * @return size in bytes
   */
  static uint8_t TypeSize(TypeId type) {
    switch (type) {
      case TypeId::BOOLEAN:
        return 1;
      case TypeId::TINYINT:
        return 1;
      case TypeId::SMALLINT:
        return 2;
      case TypeId::INTEGER:
        return 4;
      case TypeId::BIGINT:
      case TypeId::DECIMAL:
      case TypeId::TIMESTAMP:
        return 8;
      case TypeId::VARCHAR:
        // TODO(Amadou): Confirm this.
        return 12;
      default: {
        UNREACHABLE("Cannot get size of invalid type");
      }
    }
  }

  /** Column name. */
  std::string column_name_;

  /** Column value's type. */
  TypeId column_type_;

  /** For a non-inlined column, this is the size of a pointer. Otherwise, the size of the fixed length column. */
  //
  uint32_t fixed_length_;

  //可变长度列的长度
  uint32_t variable_length_{0};

  //此col的value在tuple中的位移
  uint32_t column_offset_{0};

  /** Expression used to create this column **/
  //表达器用来创造一个列
  const AbstractExpression *expr_;
};

```



#### schema

Schema的本质是vector of columns。它描述了一个tuple内存储的数据。根据schema和tuple来获取value。

```c++

class Schema {
 public:
  /**
   * Constructs the schema corresponding to the vector of columns, read left-to-right.
   * @param columns columns that describe the schema's individual columns
   */
  explicit Schema(const std::vector<Column> &columns);

  static Schema *CopySchema(const Schema *from, const std::vector<uint32_t> &attrs) {
    std::vector<Column> cols;
    cols.reserve(attrs.size());
    for (const auto i : attrs) {
      cols.emplace_back(from->columns_[i]);
    }
    return new Schema{cols};
  }

  /** @return all the columns in the schema */
  const std::vector<Column> &GetColumns() const { return columns_; }

  /**
   * Returns a specific column from the schema.
   * @param col_idx index of requested column
   * @return requested column
   */
  const Column &GetColumn(const uint32_t col_idx) const { return columns_[col_idx]; }

  /**
   * Looks up and returns the index of the first column in the schema with the specified name.
   * If multiple columns have the same name, the first such index is returned.
   * @param col_name name of column to look for
   * @return the index of a column with the given name, throws an exception if it does not exist
   */
  uint32_t GetColIdx(const std::string &col_name) const {
    for (uint32_t i = 0; i < columns_.size(); ++i) {
      if (columns_[i].GetName() == col_name) {
        return i;
      }
    }
    UNREACHABLE("Column does not exist");
  }

  /** @return the indices of non-inlined columns */
  const std::vector<uint32_t> &GetUnlinedColumns() const { return uninlined_columns_; }

  /** @return the number of columns in the schema for the tuple */
  uint32_t GetColumnCount() const { return static_cast<uint32_t>(columns_.size()); }

  /** @return the number of non-inlined columns */
  uint32_t GetUnlinedColumnCount() const { return static_cast<uint32_t>(uninlined_columns_.size()); }

  /** @return the number of bytes used by one tuple */
  inline uint32_t GetLength() const { return length_; }

  /** @return true if all columns are inlined, false otherwise */
  inline bool IsInlined() const { return tuple_is_inlined_; }

  /** @return string representation of this schema */
  std::string ToString() const;

 private:
  /** Fixed-length column size, i.e. the number of bytes used by one tuple. */
  uint32_t length_;

  /** All the columns in the schema, inlined and uninlined. */
  std::vector<Column> columns_;

  /** True if all the columns are inlined, false otherwise. */
  bool tuple_is_inlined_;

  /** Indices of all uninlined columns. */
  std::vector<uint32_t> uninlined_columns_;
};
```



#### table

一个table由三部分部分组成，一部分是存储tuple的元数据页面，一部分是存储了索引的索引页面(索引可能有多个，因为一张表可以有多个索引)，最后一部分是存储schema的catalog。

在B+索引中，索引页面即可直接作为元数据页面（叶子页面），查索引的过程中就能直接读写到tuple的物理位置。使用哈希表索引中，索引页面和元数据页面分别独立开来，索引页面中存储着tuple的元信息，再通过元信息读取相应的物理位置。

<img src="数据库设计与实现/image-20230118160744194.png" alt="image-20230118160744194" style="zoom:67%;" />



```c++

/**
 * The TableInfo class maintains metadata about a table.
 * tableinfo包含了tableheap和schema
 */
struct TableInfo {
  /**
   * Construct a new TableInfo instance.
   * @param schema The table schema
   * @param name The table name
   * @param table An owning pointer to the table heap
   * @param oid The unique OID for the table
   */
  TableInfo(Schema schema, std::string name, std::unique_ptr<TableHeap> &&table, table_oid_t oid)
      : schema_{std::move(schema)}, name_{std::move(name)}, table_{std::move(table)}, oid_{oid} {}
  /** The table schema */
  Schema schema_;
  /** The table name */
  const std::string name_;
  /** An owning pointer to the table heap */
  std::unique_ptr<TableHeap> table_;
  /** The table OID */
  const table_oid_t oid_;
};

/**
 * The IndexInfo class maintains metadata about a index.
 * IndexInfo包含了lab2的哈希表
 */
struct IndexInfo {
  /**
   * Construct a new IndexInfo instance.
   * @param key_schema The schema for the index key
   * @param name The name of the index
   * @param index An owning pointer to the index
   * @param index_oid The unique OID for the index
   * @param table_name The name of the table on which the index is created
   * @param key_size The size of the index key, in bytes
   */
  IndexInfo(Schema key_schema, std::string name, std::unique_ptr<Index> &&index, index_oid_t index_oid,
            std::string table_name, size_t key_size)
      : key_schema_{std::move(key_schema)},
        name_{std::move(name)},
        index_{std::move(index)},
        index_oid_{index_oid},
        table_name_{std::move(table_name)},
        key_size_{key_size} {}
  /** The schema for the index key */
  Schema key_schema_;
  /** The name of the index */
  std::string name_;
  /** An owning pointer to the index */
  std::unique_ptr<Index> index_;
  /** The unique OID for the index */
  index_oid_t index_oid_;
  /** The name of the table on which the index is created */
  std::string table_name_;
  /** The size of the index key, in bytes */
  const size_t key_size_;
};

```



### 缓存池

ps：关闭os的缓冲

为什么DBMS要使用自己的内存映射系统而不是直接使用操作系统的虚拟内存？

- 可以预先读取，而不用等到os调用
- 自己定义替换策略，追踪数据的位置（何时给数据上锁，何时给数据写入磁盘）。
- 可以控制多用户（进程/线程）下的读写顺序

预读：提前知道要全表扫描时，提前将孙旭的页面读进缓存区

![image-20221203000509495](数据库设计与实现/image-20221203000509495.png)

共享扫描：当两个事务请求一致时，只做一次请求，将结果返回给事务

- 与result caching的区别：result cachin 是将结果缓存下来，遇到相同的事务时直接返回结果。共享扫描是将两个事务中相同的部分同时进行，等一个事务完成，再去补另一个事务的剩余操作

![image-20221203001219984](数据库设计与实现/image-20221203001219984.png)

Q1先执行，读到page3时Q2到来，Q1和Q2都是全表扫描，Q2与Q1一起执行从page3开始读页面，等Q1读完再从头读page0，1，2

**wanging：当你要读page0开始的100个数时，启用共享扫描时可能就会从page3开始读100个数**

直读：当用户知道页面不会再访问时，页面不进内存池，就读一次性。（通常是读大片数据：sort，join时启用）

```c++
class BufferPoolManagerInstance{
    /** Number of pages in the buffer pool. */
  const size_t pool_size_;
  /** How many instances are in the parallel BPM (if present, otherwise just 1 BPI) */
  const uint32_t num_instances_ = 1;
  /** Index of this BPI in the parallel BPM (if present, otherwise just 0) */
  const uint32_t instance_index_ = 0;
  /** Each BPI maintains its own counter for page_ids to hand out, must ensure they mod back to its instance_index_ */
  std::atomic<page_id_t> next_page_id_ = instance_index_;

  /** Array of buffer pool pages. */
  Page *pages_;
  /** Pointer to the disk manager. */
  DiskManager *disk_manager_ __attribute__((__unused__));
  /** Pointer to the log manager. */
  LogManager *log_manager_ __attribute__((__unused__));
  /** Page table for keeping track of buffer pool pages. */
  std::unordered_map<page_id_t, frame_id_t> page_table_;
  /** Replacer to find unpinned pages for replacement. */
  Replacer *replacer_;  // LRU_replacer 所有unpinned pages都插入到到LRU_replacer中，由LRU_replacer来绝决定换出哪个frame
  /** List of free pages. */
  std::list<frame_id_t> free_list_;  // frame_id 0 1 2 3 4 5 ... Page *page = &pages[frame_id]
  /** This latch protects shared data structures. We recommend updating this comment to describe what it protects. */
  std::mutex latch_;
}

/**
 * 将页的内容刷到磁盘
 * 如果此页没有数据，则返回false
 * 如果此页数据是脏的，则刷盘，返回true
 */
bool BufferPoolManagerInstance::FlushPgImp(page_id_t page_id) {
  // Make sure you call DiskManager::WritePage!
  std::lock_guard<std::mutex> guard(latch_);
  assert(page_id != INVALID_PAGE_ID);
  auto it = page_table_.find(page_id);
  if (it == page_table_.end()) {
    return false;
  }
  frame_id_t ft = it->second;
  Page *page = &pages_[ft];
  if (page->is_dirty_) {
    disk_manager_->WritePage(page_id, page->GetData());
    page->is_dirty_ = false;
  }
  return true;
}

// 页表的数据全部刷盘
void BufferPoolManagerInstance::FlushAllPgsImp() {
  // You can do it!
  std::lock_guard<std::mutex> guard(latch_);
  for (size_t i = 0; i < pool_size_; i++) {
    Page *page = &pages_[i];
    if (page->page_id_ != INVALID_PAGE_ID && page->is_dirty_) {
      disk_manager_->WritePage(page->page_id_, page->GetData());
      page->is_dirty_ = false;
    }
  }
}

bool BufferPoolManagerInstance::FindFreePage(frame_id_t *ft) {
  if (!free_list_.empty()) {
    *ft = free_list_.front();
    free_list_.pop_front();
    return true;
  }
  if (!replacer_->Victim(ft)) {
    return false;
  }
  Page *page = &pages_[*ft];
  if (page->is_dirty_) {
    disk_manager_->WritePage(page->page_id_, page->GetData());
    page->is_dirty_ = false;
  }
  page_table_.erase(page->page_id_);
  return true;
}

/**
 * 这个特别容易出错
 * 1.创建一个新page，首先在bufferpool中找到一个可以防止page的位置(frame_id)
 *  1.1 优先选择free list里是否有空闲frameid,如果没有，看是否可以换出
 *  1.2 这里处理换出需要进行维护：对于要换出的page 刷盘，删除页表项，清空page内存.pin_count=0
 * 2. ok现在已经有可以安放新page的frame_id了，需要维护新的page相关信息
 *  2.1 获取page_id (AllocatePage),在页表中添加(page_id,frame_id)页表项，清空page内存
 *  2.2 pin_count = 1,从LRU中剔除该frame_id
 * */
Page *BufferPoolManagerInstance::NewPgImp(page_id_t *page_id) {
  // 0.   Make sure you call AllocatePage!
  // 1.   If all the pages in the buffer pool are pinned, return nullptr.
  // 2.   Pick a victim page P from either the free list or the replacer. Always pick from the free list first.
  // 3.   Update P's metadata, zero out memory and add P to the page table.
  // 4.   Set the page ID output parameter. Return a pointer to P.
  std::lock_guard<std::mutex> guard(latch_);

  frame_id_t ft = -1;
  bool ok = FindFreePage(&ft);
  if (!ok) {
    return nullptr;
  }
  *page_id = AllocatePage();
  Page *page = &pages_[ft];
  page_table_.emplace(*page_id, ft);
  page->ResetMemory();
  page->page_id_ = *page_id;
  page->is_dirty_ = false;
  page->pin_count_ = 1;
  replacer_->Pin(ft);
  return page;
}

// 思路同上，结合下面，按照下面注释来写即可
Page *BufferPoolManagerInstance::FetchPgImp(page_id_t page_id) {
  // 1.     Search the page table for the requested page (P).
  // 1.1    If P exists, pin it and return it immediately.
  // 1.2    If P does not exist, find a replacement page (R) from either the free list or the replacer.
  //        Note that pages are always found from the free list first.
  // 2.     If R is dirty, write it back to the disk.
  // 3.     Delete R from the page table and insert P.
  // 4.     Update P's metadata, read in the page content from disk, and then return a pointer to P.
  std::lock_guard<std::mutex> guard(latch_);
  // 此page在buffer_pool中
  auto it = page_table_.find(page_id);
  if (it != page_table_.end()) {
    frame_id_t ft = it->second;
    Page *page = &pages_[ft];
    replacer_->Pin(ft);
    page->pin_count_++;
    return page;
  }
  // 此page不在buffer_pool中,说明在磁盘上，此时首先需要在页表中找一个页号（其实就是frame_id），然后将磁盘数据加载到Page里
  // 并维护好页表
  frame_id_t ft = -1;
  bool is_ft = FindFreePage(&ft);
  if (!is_ft) {
    return nullptr;
  }
  Page *page = &pages_[ft];
  if (page_id != INVALID_PAGE_ID) {
    page_table_.emplace(page_id, ft);
    page->page_id_ = page_id;
    disk_manager_->ReadPage(page_id, page->data_);
    replacer_->Pin(ft);
    page->pin_count_ = 1;
    page->is_dirty_ = false;
    return page;
  }
  return nullptr;
}

/**
 * 如果page不在page_table中返回true
 * 如果pin_count > 0,说明还有线程在占用，返回false
 */
bool BufferPoolManagerInstance::DeletePgImp(page_id_t page_id) {
  // 0.   Make sure you call DeallocatePage!
  // 1.   Search the page table for the requested page (P).
  // 1.   If P does not exist, return true.
  // 2.   If P exists, but has a non-zero pin-count, return false. Someone is using the page.
  // 3.   Otherwise, P can be deleted. Remove P from the page table, reset its metadata and return it to the free list.
  std::lock_guard<std::mutex> guard(latch_);
  // 如果此页不在页表里，返回true
  auto it = page_table_.find(page_id);
  if (it == page_table_.end()) {
    return true;
  }
  // 在页表里，但是有线程在占用，不能删除，返回false
  frame_id_t ft = it->second;
  Page *page = &pages_[ft];
  if (page->pin_count_ > 0) {
    return false;
  }
  // 在页表里，且没有线程占用，可以删除页表里此页的数据
  if (page->is_dirty_) {
    disk_manager_->WritePage(page->page_id_, page->GetData());
    page->is_dirty_ = false;
  }
  DeallocatePage(page_id);      // 释放磁盘空间
  page_table_.erase(page_id);   // 页表里删除该页
  free_list_.emplace_back(ft);  // 添加到空闲页表list中
  // 重置元数据
  page->ResetMemory();
  page->page_id_ = INVALID_PAGE_ID;
  page->pin_count_ = 0;
  page->is_dirty_ = false;
  return true;
}

/**
 * 某个线程unpin某个page产生什么影响
 * 1. 首先判断page_table中是否有这个page
 *  1.1 如果没有直接返回false
 *  1.2 如果有，获取到该page
 * 2. 获取到page后，page->pin_count--,但是事先应该判断pin_count是否已经是0了
 *  2.1 已经是0，返回false
 *  2.2 page_count--,如果page_count=0，将该frame_id加入到LRU_replacer中,表示该page作为待换出
 * */
bool BufferPoolManagerInstance::UnpinPgImp(page_id_t page_id, bool is_dirty) {
  std::lock_guard<std::mutex> guard(latch_);

  auto it = page_table_.find(page_id);
  if (it == page_table_.end()) {
    return false;
  }
  frame_id_t ft = it->second;
  Page *page = &pages_[ft];
  if (is_dirty) {
    page->is_dirty_ = true;
  }
  if (page->pin_count_ == 0) {
    return false;
  }
  page->pin_count_--;
  if (page->pin_count_ == 0) {
    replacer_->Unpin(ft);
  }
  return true;
}

page_id_t BufferPoolManagerInstance::AllocatePage() {
  const page_id_t next_page_id = next_page_id_;
  next_page_id_ += num_instances_;
  ValidatePageId(next_page_id);
  return next_page_id;
}

void BufferPoolManagerInstance::ValidatePageId(const page_id_t page_id) const {
  assert(page_id % num_instances_ == instance_index_);  // allocated pages mod back to this BPI
}

```

<img src="数据库设计与实现/image-20230103150109582.png" alt="image-20230103150109582" style="zoom:50%;" />



#### 缓冲区替换策略



```c++
class LRUReplacer{
    struct DLinkedNode {
    frame_id_t key_;
    DLinkedNode() = default;
    explicit DLinkedNode(frame_id_t k) : key_(k) {}
    std::shared_ptr<DLinkedNode> pre_;
    std::shared_ptr<DLinkedNode> next_;
  };
  int cap_;
  int size_;
  std::mutex mutex_;
  std::shared_ptr<DLinkedNode> head_;
  std::shared_ptr<DLinkedNode> tail_;
  std::unordered_map<frame_id_t, std::shared_ptr<DLinkedNode>> hash_;
}



LRUReplacer::LRUReplacer(size_t num_pages) {
  size_ = 0;
  cap_ = num_pages;
  head_ = std::make_shared<DLinkedNode>();
  tail_ = std::make_shared<DLinkedNode>();
  head_->next_ = tail_;
  head_->pre_ = tail_;
  tail_->next_ = head_;
  tail_->pre_ = head_;
}

LRUReplacer::~LRUReplacer() {
  while (head_) {
    std::shared_ptr<DLinkedNode> temp = head_->next_;
    head_->next_ = nullptr;
    head_ = temp;
  }
  head_ = nullptr;

  while (tail_) {
    std::shared_ptr<DLinkedNode> temp = tail_->pre_;
    tail_->pre_ = nullptr;
    tail_ = temp;
  }
  tail_ = nullptr;
}

void LRUReplacer::Print() {
  std::shared_ptr<LRUReplacer::DLinkedNode> pt = head_;
  std::shared_ptr<LRUReplacer::DLinkedNode> pd = tail_;
  while (pt != nullptr && pt != pd) {
    printf("key = %d\n", pt->key_);
    pt = pt->next_;
  }
}

// 使用LRU策略删除一个victim frame，frame_id需要赋值
bool LRUReplacer::Victim(frame_id_t *frame_id) {
  std::lock_guard<std::mutex> guard(mutex_);
  if (size_ == 0) {
    *frame_id = -1;
    return false;
  }
  *frame_id = (head_->next_->key_);
  head_->next_->next_->pre_ = head_;
  head_->next_ = head_->next_->next_;
  hash_.erase(*frame_id);
  size_--;
  return true;
}

// 有线程 pin这个frame, 表明它不应该成为victim（则在replacer中移除该frame_id）
void LRUReplacer::Pin(frame_id_t frame_id) {
  std::lock_guard<std::mutex> guard(mutex_);
  std::unordered_map<frame_id_t, std::shared_ptr<DLinkedNode>>::iterator des = hash_.find(frame_id);
  if (des != hash_.end()) {
    des->second->pre_->next_ = des->second->next_;
    des->second->next_->pre_ = des->second->pre_;
    hash_.erase(frame_id);
    if (size_ > 0) {
      size_--;
    }
  }
}

// 没有线程pin这个frame, 表明它可以成为victim（则将该frame_id添加到replacer）
void LRUReplacer::Unpin(frame_id_t frame_id) {
  std::lock_guard<std::mutex> guard(mutex_);
  if (size_ >= cap_) {
    return;
  }
  std::unordered_map<frame_id_t, std::shared_ptr<DLinkedNode>>::iterator des = hash_.find(frame_id);
  if (des == hash_.end()) {
    std::shared_ptr<DLinkedNode> temp = std::make_shared<DLinkedNode>(frame_id);
    tail_->pre_->next_ = temp;
    temp->pre_ = tail_->pre_;
    temp->next_ = tail_;
    tail_->pre_ = temp;
    size_++;
    hash_.insert(std::pair<frame_id_t, std::shared_ptr<DLinkedNode>>(frame_id, temp));
  }
}
```



#### 读写锁



```c++
//===----------------------------------------------------------------------===//
//
//                         BusTub
//
// rwmutex.h
//
// Identification: src/include/common/rwlatch.h
//
// Copyright (c) 2015-2019, Carnegie Mellon University Database Group
//
//===----------------------------------------------------------------------===//

#pragma once

#include <climits>
#include <condition_variable>  // NOLINT
#include <mutex>               // NOLINT

#include "common/macros.h"

namespace bustub {

/**
 * Reader-Writer latch backed by std::mutex.
 */
class ReaderWriterLatch {
  using mutex_t = std::mutex;
  using cond_t = std::condition_variable;
  static const uint32_t MAX_READERS = UINT_MAX;

 public:
  ReaderWriterLatch() = default;
  ~ReaderWriterLatch() { std::lock_guard<mutex_t> guard(mutex_); }

  DISALLOW_COPY(ReaderWriterLatch);

  /**
   * Acquire a write latch. 如果已有写锁，读者等待。如果有读者，写者等待。
   */
  void WLock() {
    std::unique_lock<mutex_t> latch(mutex_);
    while (writer_entered_) {
      reader_.wait(latch);
    }
    writer_entered_ = true;
    while (reader_count_ > 0) {
      writer_.wait(latch);
    }
  }

  /**
   * Release a write latch. 
   */
  void WUnlock() {
    std::lock_guard<mutex_t> guard(mutex_);
    writer_entered_ = false;
    reader_.notify_all();
  }

  /**
   * Acquire a read latch.
   */
  void RLock() {
    std::unique_lock<mutex_t> latch(mutex_);
    while (writer_entered_ || reader_count_ == MAX_READERS) {
      reader_.wait(latch);
    }
    reader_count_++;
  }

  /**
   * Release a read latch.
   */
  void RUnlock() {
    std::lock_guard<mutex_t> guard(mutex_);
    reader_count_--;
    if (writer_entered_) {
      if (reader_count_ == 0) {
        writer_.notify_one();
      }
    } else {
      if (reader_count_ == MAX_READERS - 1) {
        reader_.notify_one();
      }
    }
  }

 private:
  mutex_t mutex_;
  cond_t writer_;
  cond_t reader_;
  uint32_t reader_count_{0};
  bool writer_entered_{false};
};

}  // namespace bustub

```





## HASH表

通常用于存储内部的元数据或充当临时的数据结构



- 线性（开放地址）哈希

当key对应的地址有元素时，延顺一个位置，知道位置空出

![image-20221203003040689](数据库设计与实现/image-20221203003040689.png)

删除元素时有两种措施

1：tom，删除时设立一个标志标识该位置有元素删除

2：move，删除时整理哈希表，补上空位

**当key对应多值时**

![image-20221203003339852](数据库设计与实现/image-20221203003339852.png)



- Robbing Hash

开一个辅助val记录各个元素被顺移的数位移量

当hash冲突时，比较两个元素顺移的位移量，位移量更低的往下偏移

![image-20221203004047536](数据库设计与实现/image-20221203004047536.png)

--因为E的偏移量2 》 d的偏移量1 所以E取代了D的位置，D往下移

![image-20221203004058507](数据库设计与实现/image-20221203004058507.png)



- 拉链式hash

hash冲突时，元素不再顺移，而是在冲突的位置接一个链表

![image-20221203004710680](数据库设计与实现/image-20221203004710680.png)

java：

当拉链过长时，链表转为红黑树

go：

第一个桶存放八个元素，溢出桶存放n个



- 线性哈希表









### 可扩容哈希

用拉链法来解决哈希冲突。用扩展哈希解决桶过深的情况。

 hash 方式为链式哈希，使用 bucket （桶）这么个东西来存储 page；不同于常规的 chained hashing 那样 hash(key) 不变，指向的 buckets 桶链表可以往下延伸（最坏情况下又会退化成O（n）的遍历）,链式法解决哈希冲突



<img src="CMU15445/image-20220620172118260.png" alt="image-20220620172118260" style="zoom:67%;" />

这里的 extendible 可扩展性具体指的是通过 mask 这个算子来完成对不同 bucket 的映射（计算方式与子网掩码相同）

<img src="CMU15445/image-20220620172204522.png" alt="image-20220620172204522" style="zoom:67%;" />

我们维护一个全局的 `global_mask` (用于定位key)以及每个桶都有自己的 `local_mask`，对于一个到来的 hash 值，我们首先用 `global_mask`计算出这个 key 应该被归到哪个桶（注意多个 slot 可以指向同一个 bucket）

<img src="CMU15445/image-20220620172251013.png" alt="image-20220620172251013" style="zoom:67%;" />

当bucket被填满，由于‘10’标志位无法容纳下那么多的 key，所以我们需要把这个超限的桶拆分成两个，并且把`local_mask`标志位都加 1（`global_mask`维护的是所有桶 mask 标志位的最大值所以也需要同步加 1）。在 global slot 完成重定向，以及两桶的数据拆分

<img src="CMU15445/image-20220620172659501.png" alt="image-20220620172659501" style="zoom:67%;" />






![image-20220620223140444](数据库设计与实现/image-20220620223140444.png)

#### 目录表

![image-20230102201710092](数据库设计与实现/image-20230102201710092.png)

```c++
#pragma once

#include <cassert>
#include <climits>
#include <cstdlib>
#include <string>

#include "storage/index/generic_key.h"
#include "storage/page/hash_table_page_defs.h"

namespace bustub {

#define MAX_BUCKET_DEPTH 9
/**
 *
 * Directory Page for extendible hash table.
 *
 * Directory format (size in byte):
 * --------------------------------------------------------------------------------------------
 * | LSN (4) | PageId(4) | GlobalDepth(4) | LocalDepths(512) | BucketPageIds(2048) | Free(1524)
 * --------------------------------------------------------------------------------------------
 */
class HashTableDirectoryPage {
 public:

 private:
  page_id_t page_id_;
  lsn_t lsn_;
  //目录页的深度，2^global_depth_=桶页的数量
  uint32_t global_depth_{0};
  //桶页的深度，2^local_depths_=桶页内元素的数量
  uint8_t local_depths_[DIRECTORY_ARRAY_SIZE];
  //bucket_page_ids_.size=2^global_depth_
  //
  page_id_t bucket_page_ids_[DIRECTORY_ARRAY_SIZE];
};

}  // namespace bustub

```



```c++
page_id_t HashTableDirectoryPage::GetPageId() const { return page_id_; }

void HashTableDirectoryPage::SetPageId(bustub::page_id_t page_id) { page_id_ = page_id; }

lsn_t HashTableDirectoryPage::GetLSN() const { return lsn_; }

void HashTableDirectoryPage::SetLSN(lsn_t lsn) { lsn_ = lsn; }

page_id_t HashTableDirectoryPage::GetBucketPageId(uint32_t bucket_idx) { return bucket_page_ids_[bucket_idx]; }

void HashTableDirectoryPage::SetBucketPageId(uint32_t bucket_idx, page_id_t bucket_page_id) {
  bucket_page_ids_[bucket_idx] = bucket_page_id;
}

uint32_t HashTableDirectoryPage::GetGlobalDepth() { return global_depth_; }

uint32_t HashTableDirectoryPage::GetLocalDepthMask(uint32_t bucket_idx) { return (1 << local_depths_[bucket_idx]) - 1; }

uint32_t HashTableDirectoryPage::GetGlobalDepthMask() { 
    // depth:1->1  2->11
    return (1 << global_depth_) - 1; }
//增加全局深度，oldidx*2=newidx
void HashTableDirectoryPage::IncrGlobalDepth() {
  assert(global_depth_ < MAX_BUCKET_DEPTH);
  int old_size = Size();
  for (int st = 0, newst = old_size; st < old_size; st++, newst++) {
    bucket_page_ids_[newst] = bucket_page_ids_[st];
    local_depths_[newst] = local_depths_[st];
  }
  global_depth_++;
}

void HashTableDirectoryPage::DecrGlobalDepth() { global_depth_--; }

bool HashTableDirectoryPage::CanShrink() {
  int size = Size();
  for (int i = 0; i < size; i++) {
    if (local_depths_[i] == global_depth_) {
      return false;
    }
  }
  return true;
}

uint32_t HashTableDirectoryPage::Size() { return (1 << global_depth_); }

uint32_t HashTableDirectoryPage::GetLocalDepth(uint32_t bucket_idx) { return local_depths_[bucket_idx]; }

void HashTableDirectoryPage::SetLocalDepth(uint32_t bucket_idx, uint8_t local_depth) {
  assert(local_depth <= global_depth_);
  local_depths_[bucket_idx] = local_depth;
}

void HashTableDirectoryPage::IncrLocalDepth(uint32_t bucket_idx) {
  assert(local_depths_[bucket_idx] < global_depth_);
  local_depths_[bucket_idx]++;
}

void HashTableDirectoryPage::DecrLocalDepth(uint32_t bucket_idx) { local_depths_[bucket_idx]--; }

//bucket_idx，has（key）的值
uint32_t HashTableDirectoryPage::GetSplitImageIndex(uint32_t bucket_idx) {
  return bucket_idx ^ (1 << (local_depths_[bucket_idx] - 1));
}


```



#### 桶页

![image-20230102205429023](数据库设计与实现/image-20230102205429023.png)

```c++
//===----------------------------------------------------------------------===//
//
//                         BusTub
//
// hash_table_bucket_page.h
//
// Identification: src/include/storage/page/hash_table_bucket_page.h
//
// Copyright (c) 2015-2021, Carnegie Mellon University Database Group
//
//===----------------------------------------------------------------------===//

#pragma once

#include <utility>
#include <vector>

#include "common/config.h"
#include "storage/index/int_comparator.h"
#include "storage/page/hash_table_page_defs.h"

namespace bustub {
/**
 * Store indexed key and and value together within bucket page. Supports
 * non-unique keys.
 *
 * Bucket page format (keys are stored in order):
 *  ----------------------------------------------------------------
 * | KEY(1) + VALUE(1) | KEY(2) + VALUE(2) | ... | KEY(n) + VALUE(n)
 *  ----------------------------------------------------------------
 *
 *  Here '+' means concatenation.
 *  The above format omits the space required for the occupied_ and
 *  readable_ arrays. More information is in storage/page/hash_table_page_defs.h.
 *
 */
template <typename KeyType, typename ValueType, typename KeyComparator>
class HashTableBucketPage {
 public:
  // Delete all constructor / destructor to ensure memory safety
  HashTableBucketPage() = delete;

  /**
   * Scan the bucket and collect values that have the matching key
   *
   * @return true if at least one key matched
   */
  bool GetValue(KeyType key, KeyComparator cmp, std::vector<ValueType> *result);

  /**
   * Attempts to insert a key and value in the bucket.  Uses the occupied_
   * and readable_ arrays to keep track of each slot's availability.
   *
   * @param key key to insert
   * @param value value to insert
   * @return true if inserted, false if duplicate KV pair or bucket is full
   */
  bool Insert(KeyType key, ValueType value, KeyComparator cmp);

  /**
   * Removes a key and value.
   *
   * @return true if removed, false if not found
   */
  bool Remove(KeyType key, ValueType value, KeyComparator cmp);

  /**
   * Gets the key at an index in the bucket.
   *
   * @param bucket_idx the index in the bucket to get the key at
   * @return key at index bucket_idx of the bucket
   */
  KeyType KeyAt(uint32_t bucket_idx) const;

  /**
   * Gets the value at an index in the bucket.
   *
   * @param bucket_idx the index in the bucket to get the value at
   * @return value at index bucket_idx of the bucket
   */
  ValueType ValueAt(uint32_t bucket_idx) const;

  /**
   * Remove the KV pair at bucket_idx
   */
  void RemoveAt(uint32_t bucket_idx);

  /**
   * Returns whether or not an index is occupied (key/value pair or tombstone)
   *
   * @param bucket_idx index to look at
   * @return true if the index is occupied, false otherwise
   */
  bool IsOccupied(uint32_t bucket_idx) const;

  /**
   * SetOccupied - Updates the bitmap to indicate that the entry at
   * bucket_idx is occupied.
   *
   * @param bucket_idx the index to update
   */
  void SetOccupied(uint32_t bucket_idx);

  /**
   * Returns whether or not an index is readable (valid key/value pair)
   *
   * @param bucket_idx index to lookup
   * @return true if the index is readable, false otherwise
   */
  bool IsReadable(uint32_t bucket_idx) const;

  /**
   * SetReadable - Updates the bitmap to indicate that the entry at
   * bucket_idx is readable.
   *
   * @param bucket_idx the index to update
   */
  void SetReadable(uint32_t bucket_idx);

  /**
   * @return the number of readable elements, i.e. current size
   */
  uint32_t NumReadable();

  /**
   * @return whether the bucket is full
   */
  bool IsFull();

  /**
   * @return whether the bucket is empty
   */
  bool IsEmpty();

  // reset occupied_ and readable_
  void Init();

  MappingType *GetMappingTypeArray();
  /**
   * Prints the bucket's occupancy information
   */
  void PrintBucket();

 private:
  //  For more on BUCKET_ARRAY_SIZE see storage/page/hash_table_page_defs.h
  char occupied_[(BUCKET_ARRAY_SIZE - 1) / 8 + 1];
  // 0 if tombstone/brand new (never occupied), 1 otherwise.
  //先判断位置上是否有元素，如果没有元素直接跳过
  char readable_[(BUCKET_ARRAY_SIZE - 1) / 8 + 1];
  //define MappingType std::pair<KeyType,ValueType>
  MappingType array_[BUCKET_ARRAY_SIZE];
};

}  // namespace bustub
```



```c++
#include "storage/page/hash_table_bucket_page.h"
#include "common/logger.h"
#include "common/util/hash_util.h"
#include "storage/index/generic_key.h"
#include "storage/index/hash_comparator.h"
#include "storage/table/tmp_tuple.h"

namespace bustub {

template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_BUCKET_TYPE::GetValue(KeyType key, KeyComparator cmp, std::vector<ValueType> *result) {
  bool res = false;
  for (size_t i = 0; i < BUCKET_ARRAY_SIZE; ++i) {
    if (IsReadable(i) && cmp(key, array_[i].first) == 0) {
      result->push_back(array_[i].second);
      res = true;
    }
  }
  return res;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_BUCKET_TYPE::Insert(KeyType key, ValueType value, KeyComparator cmp) {
  int64_t free_slot = -1;
  for (size_t i = 0; i < BUCKET_ARRAY_SIZE; i++) {
    if (IsReadable(i)) {
      if (cmp(key, array_[i].first) == 0 && value == array_[i].second) {
        // already existed the same key & value
        //                LOG_DEBUG("Same kv");
        return false;
      }
    } else if (free_slot == -1) {
      free_slot = i;
    }
  }

  if (free_slot == -1) {
    // is full
    LOG_DEBUG("Bucket is full");
    return false;
  }

  // insert it and return true
  SetOccupied(free_slot);
  SetReadable(free_slot);
  array_[free_slot] = MappingType(key, value);
  return true;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_BUCKET_TYPE::Remove(KeyType key, ValueType value, KeyComparator cmp) {
  for (size_t i = 0; i < BUCKET_ARRAY_SIZE; i++) {
    if (IsReadable(i)) {
      if (cmp(key, array_[i].first) == 0 && value == array_[i].second) {
        // find it
        RemoveAt(i);
        return true;
      }
    }
  }
  return false;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
KeyType HASH_TABLE_BUCKET_TYPE::KeyAt(uint32_t bucket_idx) const {
  return array_[bucket_idx].first;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
ValueType HASH_TABLE_BUCKET_TYPE::ValueAt(uint32_t bucket_idx) const {
  return array_[bucket_idx].second;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_BUCKET_TYPE::RemoveAt(uint32_t bucket_idx) {
  SetReadable(bucket_idx, false);
}

template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_BUCKET_TYPE::IsOccupied(uint32_t bucket_idx) const {
  char c = occupied_[bucket_idx / 8];
  uint32_t need = bucket_idx % 8;
  uint32_t mask = 1;
  mask = mask << need;
  return (mask & c) > 0;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_BUCKET_TYPE::SetOccupied(uint32_t bucket_idx) {
  SetOccupied(bucket_idx, true);
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_BUCKET_TYPE::SetOccupied(uint32_t bucket_idx, bool status) {
  char c = occupied_[bucket_idx / 8];
  uint8_t ic = static_cast<uint8_t>(c);
  uint8_t need = bucket_idx % 8;
  if (status) {
    uint8_t mask = 1 << need;
    ic = (ic | mask);
  } else {
    uint32_t mask = 1;
    mask = mask << need;
    mask = ~mask;
    ic = (ic & mask);
  }
  occupied_[bucket_idx / 8] = static_cast<char>(ic);
}

template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_BUCKET_TYPE::IsReadable(uint32_t bucket_idx) const {
  char c = readable_[bucket_idx / 8];
  uint32_t need = bucket_idx % 8;
  uint32_t mask = 1;
  mask = mask << need;
  return (mask & c) > 0;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_BUCKET_TYPE::SetReadable(uint32_t bucket_idx) {
  SetReadable(bucket_idx, true);
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_BUCKET_TYPE::SetReadable(uint32_t bucket_idx, bool status) {
  char c = readable_[bucket_idx / 8];
  uint8_t ic = static_cast<uint8_t>(c);
  uint8_t need = bucket_idx % 8;
  if (status) {
    uint8_t mask = 1 << need;
    ic = (ic | mask);
  } else {
    uint32_t mask = 1;
    mask = mask << need;
    mask = ~mask;
    ic = (ic & mask);
  }
  readable_[bucket_idx / 8] = static_cast<char>(ic);
}
//整个页面已满
//#define BUCKET_ARRAY_SIZE (4 * PAGE_SIZE / (4 * sizeof(MappingType) + 1))
template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_BUCKET_TYPE::IsFull() {
  u_int8_t mask = 255;
  size_t times = BUCKET_ARRAY_SIZE / 8;
  for (size_t i = 0; i < times; i++) {
    char c = readable_[i];
    uint8_t ic = static_cast<uint8_t>(c);
    if ((ic & mask) != mask) {
      return false;
    }
  }

  size_t remain = BUCKET_ARRAY_SIZE % 8;
  if (remain > 0) {
    char c = readable_[times];
    uint8_t ic = static_cast<uint8_t>(c);
    for (size_t i = 0; i < remain; i++) {
      if ((ic & 1) != 1) {
        return false;
      }
      ic = ic >> 1;
    }
  }
  return true;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
uint32_t HASH_TABLE_BUCKET_TYPE::NumReadable() {
  uint32_t num = 0;
  size_t times = BUCKET_ARRAY_SIZE / 8;
  for (size_t i = 0; i < times; i++) {
    char c = readable_[i];
    uint8_t ic = static_cast<uint8_t>(c);
    for (uint32_t j = 0; j < 8; j++) {
      if ((ic & 1) > 0) {
        num++;
      }
      ic = ic >> 1;
    }
  }

  size_t remain = BUCKET_ARRAY_SIZE % 8;
  if (remain > 0) {
    char c = readable_[times];
    uint8_t ic = static_cast<uint8_t>(c);
    for (size_t i = 0; i < remain; i++) {
      if ((ic & 1) == 1) {
        num++;
      }
      ic = ic >> 1;
    }
  }
  return num;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_BUCKET_TYPE::IsEmpty() {
  u_int8_t mask = 255;
  for (size_t i = 0; i < sizeof(readable_) / sizeof(readable_[0]); i++) {
    char c = readable_[i];
    if ((c & mask) > 0) {
      return false;
    }
  }
  return true;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
MappingType *HASH_TABLE_BUCKET_TYPE::GetArrayCopy() {
  uint32_t num = NumReadable();
  MappingType *copy = new MappingType[num];
  for (uint32_t i = 0, index = 0; i < BUCKET_ARRAY_SIZE; i++) {
    if (IsReadable(i)) {
      copy[index++] = array_[i];
    }
  }
  return copy;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_BUCKET_TYPE::PrintBucket() {
  uint32_t size = 0;
  uint32_t taken = 0;
  uint32_t free = 0;
  for (size_t bucket_idx = 0; bucket_idx < BUCKET_ARRAY_SIZE; bucket_idx++) {
    if (!IsOccupied(bucket_idx)) {
      break;
    }

    size++;

    if (IsReadable(bucket_idx)) {
      taken++;
    } else {
      free++;
    }
  }

  LOG_INFO("Bucket Capacity: %lu, Size: %u, Taken: %u, Free: %u", BUCKET_ARRAY_SIZE, size, taken, free);
}
template <typename KeyType, typename ValueType, typename KeyComparator>
void HashTableBucketPage<KeyType, ValueType, KeyComparator>::Clear() {
  LOG_DEBUG("clear");
  memset(occupied_, 0, sizeof(occupied_));
  memset(readable_, 0, sizeof(readable_));
  memset(array_, 0, sizeof(array_));
}

// DO NOT REMOVE ANYTHING BELOW THIS LINE
template class HashTableBucketPage<int, int, IntComparator>;

template class HashTableBucketPage<GenericKey<4>, RID, GenericComparator<4>>;
template class HashTableBucketPage<GenericKey<8>, RID, GenericComparator<8>>;
template class HashTableBucketPage<GenericKey<16>, RID, GenericComparator<16>>;
template class HashTableBucketPage<GenericKey<32>, RID, GenericComparator<32>>;
template class HashTableBucketPage<GenericKey<64>, RID, GenericComparator<64>>;

// template class HashTableBucketPage<hash_t, TmpTuple, HashComparator>;

}  // namespace bustub

```



#### 扩容操作



- 获取目录页

<img src="数据库设计与实现/image-20230103152655910.png" alt="image-20230103152655910" style="zoom:80%;" />



```c++

/* 获取HashTableDirectoryPage,如果没有,首先创建，如果有则直接获取
   从buffer_pool_manager中获取Page,Page中是一个Directory对象
*/
template <typename KeyType, typename ValueType, typename KeyComparator>
HashTableDirectoryPage *HASH_TABLE_TYPE::FetchDirectoryPage() {
  HashTableDirectoryPage *dir_page;
  directory_lock_.lock();
  if (directory_page_id_ == INVALID_PAGE_ID) {
    page_id_t page_id_dir;
    Page *page = buffer_pool_manager_->NewPage(&page_id_dir);
    dir_page = reinterpret_cast<HashTableDirectoryPage *>(page->GetData());
    directory_page_id_ = page_id_dir;
    dir_page->SetPageId(directory_page_id_);
	//dirpage新建时深度为1，对应一个桶页面，所以新建一个痛页面
    page_id_t page_id_bucket;
    page = buffer_pool_manager_->NewPage(&page_id_bucket);
    dir_page->SetBucketPageId(0, page_id_bucket);
    //记得将页面Unpin移进缓存池，因为在new和fetech时buffer_pool会先pin住页面
    buffer_pool_manager_->UnpinPage(page_id_dir, true);
    buffer_pool_manager_->UnpinPage(page_id_bucket, true);
  }
  directory_lock_.unlock();
  Page *page = buffer_pool_manager_->FetchPage(directory_page_id_);
  dir_page = reinterpret_cast<HashTableDirectoryPage *>(page->GetData());
  return dir_page;
}

```



- 获取桶页

![image-20230103155011748](数据库设计与实现/image-20230103155011748.png)



```c++

template <typename KeyType, typename ValueType, typename KeyComparator>
uint32_t HASH_TABLE_TYPE::Hash(KeyType key) {
  return static_cast<uint32_t>(hash_fn_.GetHash(key));
}

template <typename KeyType, typename ValueType, typename KeyComparator>
inline uint32_t HASH_TABLE_TYPE::KeyToDirectoryIndex(KeyType key, HashTableDirectoryPage *dir_page) {
  return Hash(key) & dir_page->GetGlobalDepthMask();
}

template <typename KeyType, typename ValueType, typename KeyComparator>
inline uint32_t HASH_TABLE_TYPE::KeyToPageId(KeyType key, HashTableDirectoryPage *dir_page) {
  return dir_page->GetBucketPageId(KeyToDirectoryIndex(key, dir_page));
}

template <typename KeyType, typename ValueType, typename KeyComparator>
Page *HASH_TABLE_TYPE::FetchPage(page_id_t bucket_page_id) {
  Page *page = buffer_pool_manager_->FetchPage(bucket_page_id);
  return page;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
HASH_TABLE_BUCKET_TYPE *HASH_TABLE_TYPE::FetchBucketPage(Page *page) {
  return reinterpret_cast<HASH_TABLE_BUCKET_TYPE *>(page->GetData());
}

```



- 分裂操作

  - 加表级写锁

  - 获取目录和当前 bucket 的数据,当前bucket_idx=Hash(key) & (1 << (golbal_depth_ - 1))

  - 判断 directory 里面 global_depth 是否需要增加（local depth == global depth），此时除了增加全局深度，其他的数组也要扩容，参见上面的 `Grow()`。然后当前 bucket 的 depth 也要自增

  - 新建一个 bucket，new_bucket_index=bucket_idx ^ (1 << (local_depths_[bucket_idx] - 1))

  - 遍历一遍原来的 bucket，获取原 bucket 的所有 kv pair ，然后再把原 bucket 重置一遍

  - 最后把 copy 到的所有 kv pair 重新算一遍 index 决定要放到哪个 bucket 里面，

    Hash(temp_old_pairs[i].first) & dir_page->GetLocalDepthMask(bucket_idx)=bucket_idx?new_bucket_idx



<img src="数据库设计与实现/image-20230107005924524.png" alt="image-20230107005924524" style="zoom:50%;" />



![image-20230107010841141](数据库设计与实现/image-20230107010841141.png)



```c++

/*****************************************************************************
 * INSERTION
 *****************************************************************************/
template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_TYPE::Insert(Transaction *transaction, const KeyType &key, const ValueType &value) {
  table_latch_.RLock();
  HashTableDirectoryPage *dir_page = FetchDirectoryPage();
  page_id_t page_id = KeyToPageId(key, dir_page);
  Page *page = FetchPage(page_id);
  page->WLatch();
  HASH_TABLE_BUCKET_TYPE *bucket_page = FetchBucketPage(page);
  if (!bucket_page->IsFull()) {
    bool ok = bucket_page->Insert(key, value, comparator_);
    page->WUnlatch();
    buffer_pool_manager_->UnpinPage(page_id, true);
    buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
    table_latch_.RUnlock();
    return ok;
  }
  page->WUnlatch();
  buffer_pool_manager_->UnpinPage(page_id, false);
  buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
  table_latch_.RUnlock();
  return SplitInsert(transaction, key, value);
}

template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_TYPE::SplitInsert(Transaction *transaction, const KeyType &key, const ValueType &value) {
  table_latch_.WLock();  // writers are splits and merges
  HashTableDirectoryPage *dir_page = FetchDirectoryPage();
  //Hash(key) & (1 << (golbal_depth_ - 1))
  uint32_t bucket_id = KeyToDirectoryIndex(key, dir_page);
  uint32_t bucket_local_depth = dir_page->GetLocalDepth(bucket_id);

  // hash表已经不能再扩容了
  if (bucket_local_depth >= MAX_GLOBAL_DEPTH) {
    buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
    table_latch_.WUnlock();
    return false;
  }

  // hash表可以再扩容，但是bucket_local_depth == global_depth
  // 需要首先扩容Directory表
  if (bucket_local_depth == dir_page->GetGlobalDepth()) {
    dir_page->IncrGlobalDepth();
  }

  // 先增加local_depth,这一步很关键，想想逻辑
  dir_page->IncrLocalDepth(bucket_id);

  // 更新old bucket的信息
  page_id_t bucket_page_id = KeyToPageId(key, dir_page);
  Page *old_page = FetchPage(bucket_page_id);
  old_page->WLatch();
  HASH_TABLE_BUCKET_TYPE *old_bucket = FetchBucketPage(old_page);
  uint32_t num = old_bucket->NumReadable();
  MappingType *temp_old_pairs = old_bucket->GetMappingTypeArray();
  old_bucket->Init();

  // 创建一个新的bucket
  page_id_t image_page_id;
  Page *image_page = buffer_pool_manager_->NewPage(&image_page_id);
  assert(image_page != nullptr);
  image_page->WLatch();
  HASH_TABLE_BUCKET_TYPE *image_bucket = FetchBucketPage(image_page);
  //bucket_idx ^ (1 << (local_depths_[bucket_idx] - 1))
  uint32_t split_image_index = dir_page->GetSplitImageIndex(bucket_id);
  dir_page->SetLocalDepth(split_image_index, dir_page->GetLocalDepth(bucket_id));
  //重要的是这步
  dir_page->SetBucketPageId(split_image_index, image_page_id);

  for (uint32_t i = 0; i < num; i++) {
    uint32_t new_bucket_id = Hash(temp_old_pairs[i].first) & dir_page->GetLocalDepthMask(bucket_id);
    page_id_t temp_page_id = dir_page->GetBucketPageId(new_bucket_id);
    assert(temp_page_id == bucket_page_id || temp_page_id == image_page_id);
    //如果pageid和old_bucket pageid一样，插入到旧桶
    if (temp_page_id == bucket_page_id) {
      old_bucket->Insert(temp_old_pairs[i].first, temp_old_pairs[i].second, comparator_);
    } else {
      image_bucket->Insert(temp_old_pairs[i].first, temp_old_pairs[i].second, comparator_);
    }
  }
  delete[] temp_old_pairs;

  // 上面只修改了原bucket与image_bucket的相关信息，
  // 实际上可能之前存在许多bucket映射到bucket对应的page上,这些信息也要相应的修改
  uint32_t step = 1 << (dir_page->GetLocalDepth(bucket_id));
  for (uint32_t i = bucket_id; i >= step; i -= step) {
    dir_page->SetBucketPageId(i, bucket_page_id);
    dir_page->SetLocalDepth(i, dir_page->GetLocalDepth(bucket_id));
  }
  for (uint32_t i = bucket_id; i < dir_page->Size(); i += step) {
    dir_page->SetBucketPageId(i, bucket_page_id);
    dir_page->SetLocalDepth(i, dir_page->GetLocalDepth(bucket_id));
  }
  for (uint32_t i = split_image_index; i >= step; i -= step) {
    dir_page->SetBucketPageId(i, image_page_id);
    dir_page->SetLocalDepth(i, dir_page->GetLocalDepth(split_image_index));
  }
  for (uint32_t i = split_image_index; i < dir_page->Size(); i += step) {
    dir_page->SetBucketPageId(i, image_page_id);
    dir_page->SetLocalDepth(i, dir_page->GetLocalDepth(split_image_index));
  }

  old_page->WUnlatch();
  image_page->WUnlatch();

  // Unpin 这三页数据
  buffer_pool_manager_->UnpinPage(bucket_page_id, true);
  buffer_pool_manager_->UnpinPage(image_page_id, true);
  buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), true);
  table_latch_.WUnlock();

  // 再次尝试插入数据
  return Insert(transaction, key, value);
}

```





- 加表级写锁
- 获取目录和当前 bucket 的数据
- 判断当前 bucket 的深度，如果为 0 就不进行收缩
- 如果当前 bucket 与其 split image bucket 深度不同，说明两个中的一个已经进行拆分了，这时候也不收缩
- 给当前 bucket page 加上读锁，再判断一次是否非空（考虑到并发是有可能存在乱入的情况的），这时候也不收缩
- 这时候才能认为 bucket 已空，真正进行删除操作
- 接着设置原 bucket 的 page为 split image 的 page，即合并 target 和 split
- 最后遍历整个 directory，将所有指向原 bucket page 的 bucket 全部重新指向 split image bucket

```c++
// ===----------------------------------------------------------------------===//
//
//                         BusTub
//
// extendible_hash_table.cpp
//
// Identification: src/container/hash/extendible_hash_table.cpp
//
// Copyright (c) 2015-2021, Carnegie Mellon University Database Group
//
// ===----------------------------------------------------------------------===//

#include <iostream>
#include <string>
#include <utility>
#include <vector>

#include "common/exception.h"
#include "common/logger.h"
#include "common/rid.h"
#include "container/hash/extendible_hash_table.h"
#define MAX_GLOBAL_DEPTH 9

namespace bustub {

template <typename KeyType, typename ValueType, typename KeyComparator>
HASH_TABLE_TYPE::ExtendibleHashTable(const std::string &name, BufferPoolManager *buffer_pool_manager,
                                     const KeyComparator &comparator, HashFunction<KeyType> hash_fn)
    : buffer_pool_manager_(buffer_pool_manager), comparator_(comparator), hash_fn_(std::move(hash_fn)) {
  //  implement me!
  directory_page_id_ = INVALID_PAGE_ID;
}

/*****************************************************************************
 * HELPERS
 *****************************************************************************/
/**
 * Hash - simple helper to downcast MurmurHash's 64-bit hash to 32-bit
 * for extendible hashing.
 *
 * @param key the key to hash
 * @return the downcasted 32-bit hash
 */
/*****************************************************************************
 * SEARCH
 * 根据key获取数据
 *****************************************************************************/
template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_TYPE::GetValue(Transaction *transaction, const KeyType &key, std::vector<ValueType> *result) {
  table_latch_.RLock();  // Readers includes inserts and removes
  HashTableDirectoryPage *dir_page = FetchDirectoryPage();
  //bucket_page_ids_[Hash(key) & dir_page->GetGlobalDepthMask()]
  page_id_t page_id = KeyToPageId(key, dir_page);
  Page *page = FetchPage(page_id);
  page->RLatch();
  HASH_TABLE_BUCKET_TYPE *bucket_page = FetchBucketPage(page);
  bool ok = bucket_page->GetValue(key, comparator_, result);
  page->RUnlatch();

  buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
  buffer_pool_manager_->UnpinPage(page_id, false);
  table_latch_.RUnlock();
  return ok;
}

/*****************************************************************************
 * REMOVE
 *****************************************************************************/
template <typename KeyType, typename ValueType, typename KeyComparator>
bool HASH_TABLE_TYPE::Remove(Transaction *transaction, const KeyType &key, const ValueType &value) {
  table_latch_.RLock();  // Readers includes inserts and removes
  HashTableDirectoryPage *dir_page = FetchDirectoryPage();
  uint32_t bucket_id = KeyToDirectoryIndex(key, dir_page);
  page_id_t bucket_page_id = dir_page->GetBucketPageId(bucket_id);
  Page *page = FetchPage(bucket_page_id);
  page->WLatch();
  HASH_TABLE_BUCKET_TYPE *bucket = FetchBucketPage(page);
  bool ok = bucket->Remove(key, value, comparator_);

  // 如果当前bucket空了，则执行合并
  if (bucket->IsEmpty()) {
    page->WUnlatch();
    // Unpin
    buffer_pool_manager_->UnpinPage(bucket_page_id, true);
    buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
    table_latch_.RUnlock();
    Merge(transaction, key, value);
    return ok;
  }
  page->WUnlatch();
  buffer_pool_manager_->UnpinPage(bucket_page_id, true);
  buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
  table_latch_.RUnlock();
  return ok;
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_TYPE::Merge(Transaction *transaction, const KeyType &key, const ValueType &value) {
  table_latch_.WLock();  // writers are splits and merges
  HashTableDirectoryPage *dir_page = FetchDirectoryPage();
  uint32_t bucket_id = KeyToDirectoryIndex(key, dir_page);
  page_id_t bucket_page_id = dir_page->GetBucketPageId(bucket_id);
  uint32_t image_bucket_id = dir_page->GetSplitImageIndex(bucket_id);

  // local depth为0说明已经最小了，不收缩
  uint32_t local_depth = dir_page->GetLocalDepth(bucket_id);
  if (local_depth == 0) {
    buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
    table_latch_.WUnlock();
    return;
  }

  // 如果该bucket与其split image深度不同，也不收缩
  if (local_depth != dir_page->GetLocalDepth(image_bucket_id)) {
    buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
    table_latch_.WUnlock();
    return;
  }

  // 下面之所以在检查一遍是否为空是因为并发执行的原因，在上一个函数已经完全释放了锁
  // 当执行到此处时，其他线程可能已经修改了此bucket，导致此时bucket不为空了，所以需要再检查一遍
  Page *bucket_page = FetchPage(bucket_page_id);
  bucket_page->RLatch();
  HASH_TABLE_BUCKET_TYPE *bucket = FetchBucketPage(bucket_page);
  if (!bucket->IsEmpty()) {
    bucket_page->RUnlatch();
    buffer_pool_manager_->UnpinPage(bucket_page_id, false);
    buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), false);
    table_latch_.WUnlock();
    return;
  }

  bucket_page->RUnlatch();
  // 删除bucket，此时该bucket已经为空
  buffer_pool_manager_->UnpinPage(bucket_page_id, false);
  buffer_pool_manager_->DeletePage(bucket_page_id);

  // 执行合并
  page_id_t image_page_id = dir_page->GetBucketPageId(image_bucket_id);
  dir_page->SetBucketPageId(bucket_id, image_page_id);
  dir_page->DecrLocalDepth(bucket_id);
  dir_page->DecrLocalDepth(image_bucket_id);
  assert(dir_page->GetLocalDepth(bucket_id) == dir_page->GetLocalDepth(image_bucket_id));

  // 遍历整个directory，将所有指向bucket_page的bucket全部重新指向image_bucket_page
  for (uint32_t i = 0; i < dir_page->Size(); i++) {
    page_id_t temp_page_id = dir_page->GetBucketPageId(i);
    if (temp_page_id == bucket_page_id || temp_page_id == image_page_id) {
      dir_page->SetBucketPageId(i, image_page_id);
      dir_page->SetLocalDepth(i, dir_page->GetLocalDepth(image_bucket_id));
    }
  }

  // 判断global_depth是否需要缩减
  while (dir_page->CanShrink()) {
    dir_page->DecrGlobalDepth();
  }

  assert(buffer_pool_manager_->UnpinPage(dir_page->GetPageId(), true));
  table_latch_.WUnlock();
}

/*****************************************************************************
 * GETGLOBALDEPTH - DO NOT TOUCH
 *****************************************************************************/
template <typename KeyType, typename ValueType, typename KeyComparator>
uint32_t HASH_TABLE_TYPE::GetGlobalDepth() {
  table_latch_.RLock();
  HashTableDirectoryPage *dir_page = FetchDirectoryPage();
  uint32_t global_depth = dir_page->GetGlobalDepth();
  buffer_pool_manager_->UnpinPage(directory_page_id_, false);
  table_latch_.RUnlock();
  return global_depth;
}

/*****************************************************************************
 * VERIFY INTEGRITY - DO NOT TOUCH
 *****************************************************************************/
template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_TYPE::VerifyIntegrity() {
  table_latch_.RLock();
  HashTableDirectoryPage *dir_page = FetchDirectoryPage();
  dir_page->VerifyIntegrity();
  assert(buffer_pool_manager_->UnpinPage(directory_page_id_, false, nullptr));
  table_latch_.RUnlock();
}

/*****************************************************************************
 * TEMPLATE DEFINITIONS - DO NOT TOUCH
 *****************************************************************************/
template class ExtendibleHashTable<int, int, IntComparator>;

template class ExtendibleHashTable<GenericKey<4>, RID, GenericComparator<4>>;
template class ExtendibleHashTable<GenericKey<8>, RID, GenericComparator<8>>;
template class ExtendibleHashTable<GenericKey<16>, RID, GenericComparator<16>>;
template class ExtendibleHashTable<GenericKey<32>, RID, GenericComparator<32>>;
template class ExtendibleHashTable<GenericKey<64>, RID, GenericComparator<64>>;

}  // namespace bustub
```







## B+树

![img](数据库设计与实现/1743182-20220323212218655-1254182214.png)





## 索引

数据库索引,是数据库管理系统中一个排序的数据结构,以协助快速查询,更新数据库中表的数据.

除了数据之外,数据库系统还维护为满足特定查找算法的数据结构,这些数据结构以某种方式引用数据.这种数据结构就是索引

注意：索引并不是逻辑页面就是物理页面。查找的tuple不是存储在索引页面，**索引页面通常存储的是value所在的物理位置。**

**应该在哪些列上创建索引呢**
①经常需要搜索的列上

②作为主键的列上

③经常用在连接的列上,这些列主要是一些外键,可以加快连接的速度

④经常需要根据范围进行搜索的列上

⑤经常需要排序的列上

⑥经常使用在where子句上面的列上

**不应该在哪些列上创建索引**
①查询中很少用到的列

②对于那些具有很少数据值的列.比如人事表的性别列,bit数据类型的列

③对于那些定义为text,image的列.因为这些列的数据量相当大

④当对修改性能的要求远远大于搜索性能时.因为当增加索引时,会提高搜索性能,但是会降低修改性能

**按照逻辑分类，索引可分为：**

- **主键索引：**一张表只能有一个主键索引，不允许重复、不允许为 NULL；
- **[唯一索引](https://www.zhihu.com/search?q=唯一索引&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"2317003638"})：**数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，但是一个唯一索引只能包含一列，比如身份证号码、卡号等都可以作为唯一索引；
- **[普通索引](https://www.zhihu.com/search?q=普通索引&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"2317003638"})：**一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插入；
- **全文索引：**让搜索关键词更高效的一种索引。

**按照物理分类，索引可分为：**

- **聚集索引：**表记录的排列顺序和索引的排列顺序一致,所以查询效率快,只要找到第一个索引值记录,其余连续性的记录在物理上一样连续存放.聚集索引的缺点就是修改慢,因为为了使表记录和索引的排列顺序一致,在插入记录的时候,会对数据页重新排序，一般是表中的主键索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为 NULL 的唯一索引，如果还是没有的话，就采用 Innodb 存储引擎为每行数据内置的 6 字节 ROWID 作为聚集索引。每张表只有一个聚集索引，因为聚集索引的键值的逻辑顺序决定了表中相应行的物理顺序。聚集索引在**精确查找**和**范围查找**方面有良好的性能表现（相比于普通索引和全表扫描），聚集索引就显得弥足珍贵，聚集索引选择还是要慎重的（一般不会让没有语义的自增 id 充当聚集索引）；
- **[非聚集索引](https://www.zhihu.com/search?q=非聚集索引&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"2317003638"})：**表记录和索引的排列顺序不一定一致,两种索引都采用B+树的结构,非聚集索引的**叶子层并不和实际数据页相重叠,而采用叶子层包含一个指向表记录的指针.**非聚集索引层次多,不会造成数据重排，该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同（非主键的那一列），一个表中可以拥有多个非聚集索引。



### 哈希索引

bus的哈希索使用的上面的可扩容哈希作为索引数据结构。

与B+树的叶子页面直接作slot页面不同，哈希索引的索引页面和slot页面是分开的，需要先查询哈希索引得到tuple的物理位置，在读取相应页面读写tuple

<img src="数据库设计与实现/image-20230115213835240.png" alt="image-20230115213835240" style="zoom:80%;" />

```c++
KeyType：GenericKey<size_t>

template <typename KeyType, typename ValueType, typename KeyComparator>
HASH_TABLE_INDEX_TYPE::ExtendibleHashTableIndex(std::unique_ptr<IndexMetadata> &&metadata,
                                                BufferPoolManager *buffer_pool_manager,
                                                const HashFunction<KeyType> &hash_fn)
    : Index(std::move(metadata)),
      comparator_(GetMetadata()->GetKeySchema()),
      container_(GetMetadata()->GetName(), buffer_pool_manager, comparator_, hash_fn) {}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_INDEX_TYPE::InsertEntry(const Tuple &key, RID rid, Transaction *transaction) {
  // construct insert index key
  KeyType index_key;
  index_key.SetFromKey(key);
  /*
  	char data_[KeySize];
  	inline void SetFromKey(const Tuple &tuple) {
    	// intialize to 0
    	memset(data_, 0, KeySize);
    	memcpy(data_, tuple.GetData(), tuple.GetLength());
  	}
  */
  container_.Insert(transaction, index_key, rid);
  //ExtendibleHashTable->Insert(*txn,&key,&value);
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_INDEX_TYPE::DeleteEntry(const Tuple &key, RID rid, Transaction *transaction) {
  // construct delete index key
  KeyType index_key;
  index_key.SetFromKey(key);

  container_.Remove(transaction, index_key, rid);
}

template <typename KeyType, typename ValueType, typename KeyComparator>
void HASH_TABLE_INDEX_TYPE::ScanKey(const Tuple &key, std::vector<RID> *result, Transaction *transaction) {
  // construct scan index key
  KeyType index_key;
  index_key.SetFromKey(key);

  container_.GetValue(transaction, index_key, result);
}
```



### B+树索引



# 查询执行



## 事务

A账户给B账户转账一个亿(T1)，买一块地盖房子。在这种交易的过程中，有几个问题值得思考：

- 如何**同时保证**上述交易中，A账户总金额减少一个亿，B账户总金额增加一个亿？ A
- A账户如果同时在和C账户交易(T2)，如何让这两笔交易互不影响？ I
- 如果交易完成时数据库突然崩溃，如何保证交易数据成功保存在数据库中？ D
- 如何在支持大量交易的同时，保证数据的合法性(没有钱凭空产生或消失) ？ C

要保证交易正常可靠地进行，数据库就得解决上面的四个问题，这也就是`事务`诞生的背景，它能解决上面的四个问题，对应地，它拥有四大特性：

- 原子性（**A**tomicity）: 事务`要么全部完成，要么全部取消`。 如果事务崩溃，状态回到事务之前（事务回滚）。
- 隔离性（**I**solation）: 如果2个事务 T1 和 T2 同时运行，事务 T1 和 T2 最终的结果是相同的，不管 T1和T2谁先结束。
- 持久性（**D**urability）: 一旦事务提交，不管发生什么（崩溃或者出错），数据要保存在数据库中。
- 一致性（**C**onsistency）: 只有合法的数据（依照关系约束和函数约束）才能写入数据库。

**ACID**

接下来详细地了解这四大特性：

- **原子性**，确保不管交易过程中发生了什么意外状况（服务器崩溃、网络中断等），不能出现A账户少了一个亿，但B账户没到帐，或者A账户没变，但B账户却凭空收到一个亿（数据不一致）。A和B账户的金额变动要么同时成功，要么同时失败(保持原状)。
- **隔离性**，如果A在转账1亿给B（T1），同时C又在转账3亿给A（T2），不管T1和T2谁先执行完毕，最终结果必须是A账户增加2亿，而不是3亿，B增加1亿，C减少3亿。
- **持久性**，确保如果 T1 刚刚提交，数据库就发生崩溃，T1执行的结果依然会保持在数据库中。
- **一致性**，确保钱不会在系统内凭空产生或消失， 依赖原子性和隔离性。

可以看出，原子性、隔离性、一致性的根本问题，是不同的事务同时对同一份数据(A账户)进行`写操作`(修改、删除、新增)，如果事务中都只是读数据的话，那么它们可以随意地同时进行，反正读到的数据都是一样的。

如果，几个互不知晓的事务在同时修改同一份数据，那么很容易出现后完成的事务覆盖了前面的事务的结果，导致不一致。 事务在最终提交之前都有可能会回滚，撤销所有修改：

1. 如果T1事务修改了A账户的数据，
2. 这时T2事务读到了更新后的A账户数据，并进行下一步操作，
3. 但此时T1事务却回滚了，撤销了对A账户的修改，
4. 那么T2读取到的A账户数据就是非法的，这会导致数据不一致。

这些问题都是事务需要避免的。



### 原子性

当我们使用git时，不能一键将更改的部分提交到云端，而是先add更改的部分再commit。git如此做的原因就是为了保证原子性：

```c++
begin; -- 开始一个事务
update table set A = A - 1亿; -- 伪sql，仅作示意
update table set B = B + 1亿;
-- 其他读写操作
commit; -- 提交事务
```

一个事务包含了许多操作，为了保证事务的原子性---此事务的所有操作“一次性”都成功，不能一些成功，一些失败，就得等`begin`和`commit`之间的操作全部成功完成后，才将结果统一提交给数据库保存，如果途中任意一个操作失败，就撤销前面的操作，且操作不会提交数据库保存,这样就保证了`同生共死`。

bus定义了两个class来追踪对table和index的操作，这两个class分别记录了新tuple和旧tuple和这个tuple所在的page

```c++

/**
 * WriteRecord tracks information related to a write.
 */
class TableWriteRecord {
 public:
  TableWriteRecord(RID rid, WType wtype, const Tuple &tuple, TableHeap *table)
      : rid_(rid), wtype_(wtype), tuple_(tuple), table_(table) {}

  RID rid_;
  WType wtype_;
  /** The tuple is only used for the update operation. */
  Tuple tuple_;
  /** The table heap specifies which table this write record is for. */
  TableHeap *table_;
};

/**
 * WriteRecord tracks information related to a write.
 */
class IndexWriteRecord {
 public:
  IndexWriteRecord(RID rid, table_oid_t table_oid, WType wtype, const Tuple &tuple, index_oid_t index_oid,
                   Catalog *catalog)
      : rid_(rid), table_oid_(table_oid), wtype_(wtype), tuple_(tuple), index_oid_(index_oid), catalog_(catalog) {}

  /** The rid is the value stored in the index. */
  RID rid_;
  /** Table oid. */
  table_oid_t table_oid_;
  /** Write type. */
  WType wtype_;
  /** The tuple is used to construct an index key. */
  Tuple tuple_;
  /** The old tuple is only used for the update operation. */
  Tuple old_tuple_;
  /** Each table has an index list, this is the identifier of an index into the list. */
  index_oid_t index_oid_;
  /** The catalog contains metadata required to locate index. */
  Catalog *catalog_;
};
```



#### 两阶段提交（悲观锁）

为了保证原子性和提高性能，我们通常会使用多线程+加锁，而不恰当的加锁顺序经常会导致死锁，所以通过两阶段提交来限制加锁的顺序。

该协议将事务分成两个阶段，
**Growing phase**：事务可以获取锁，但是不能释放任何锁。
**Shringking phase**：事务可以释放锁，但是不能获取锁。

也就是当有lock未锁时，即使你的操作已经结束，也不能释放锁！！

```c++

/**
 * Transaction states for 2PL:
 *
 *     _________________________
 *    |                         v
 * GROWING -> SHRINKING -> COMMITTED   ABORTED
 *    |__________|________________________^
 *
 * Transaction states for Non-2PL:
 *     __________
 *    |          v
 * GROWING  -> COMMITTED     ABORTED
 *    |_________________________^
 *
 **/
enum class TransactionState { GROWING, SHRINKING, COMMITTED, ABORTED };

/**
 * Transaction isolation level.
 */
enum class IsolationLevel { READ_UNCOMMITTED, REPEATABLE_READ, READ_COMMITTED };
```

最开始事务处于Growing phase，可以随意获取锁，一旦事务释放了锁，该事务进入Shringking phase，之后就不能再获取锁。
按照two-phase locking协议重写之前的转账事务：
事务一从账户B向账户A转移50。

```scss
T1:



lock-X(B);



read(B);



B := B - 50;



write(B);



lock-X(A);



read(A);



A := A + 50;



write(A);



unlock(B);



unlock(A).
```

事务二展示账户A和B的总和。

```scss
T2:



lock-S(A);



read(A);



lock-S(B);



read(B);



display(A+B).



unlock(A);



unlock(B);
```

现在无论如何都不会出现数据不一致的情况了。

**two-phase locking正确性证明**

课本的课后题15.1也要求我们证明two-phase locking（以下称2PL rule）的正确性。我看了下解答，用的是反正法。我还看到一个用归纳法证的，比较有趣。
前提：

1. 假设T1, T2, ... Tn，n个事务遵循two-phase locking协议。
2. Sn是T1, T2, ... Tn并发执行的一个schdule。

目标：
证明Sn是conflict serializable的schedule。

证明开始：
**起始步骤，n = 1的情况**：
T1遵守2PL rule。
S1这个schedule只包含T1。
显然S1是conflict serializable的schedule。

**迭代步骤**：
迭代假设：假设Sn-1是T1, T2, ... Tn−1形成的一个schedule，并且Sn-1是conflict serializable的schedule。我们需要证明Sn-1是conflict serializable的schedule，Sn也是conflict serializable的schedule。

假设Ui(•)是事务i的解锁操作，并且是schedule Sn中第一个解锁的操作：
![lab3_1_proof.PNG](数据库设计与实现/lab3_1_proof.PNG)

可以证明，我们可以将事务i所有ri(•) and wi(•)操作移到Sn的最前面，而不会引起conflict。
证明如下：
令Wi(Y)是事务i的任意操作，Wj(Y)是事务j的一个操作，并且和Wi(Y)conflict。等价于证明不会出现如下这种情况：
![lab3_2_proof.PNG](数据库设计与实现/lab3_2_proof.PNG)

假设出现了这种情况，那么必然有如下加解锁顺序：
![lab3_3_proof.PNG](数据库设计与实现/lab3_3_proof.PNG)

又因为所有事务都遵守2PL rule，所以必然有如下加解锁顺序：
![lab3_4_proof.PNG](数据库设计与实现/lab3_4_proof.PNG)

冲突出现了，Ui(•)应该是Sn中第一个解锁操作，但是现在却是Uj(Y)。所以假设不成立，所以结论："我们可以将事务i所有ri(•) and wi(•)操作移到Sn的最前面，而不会引起conflict"成立。

我们将事务i的所有操作移到schedule最前面，
![lab3_5_proof.PNG](数据库设计与实现/lab3_5_proof.PNG)

又因为Sn-1是conflict serializable的所以Sn是conflict serializable的。

证明完毕

**two-phase locking不能保证不会死锁**

two-phase locking可以保证conflict serializable，但可能会出现死锁的情况。
考虑这个schedule片段：

```scss
      T1                      T2



lock-X(B);



read(B);



B := B - 50;



write(B);



                          lock-S(A);



                          read(A);



                          lock-S(B);



 lock-X(A);
```

T1和T2都遵循2PL rule，但是T2等待T1释放B上的锁，T1等待T2释放A上的锁，造成死锁。

**2pl可能会造成级联回滚**

```c++
      T1                      T2


lock-X(A);
lock-X(B);

R(A);
W(A);

Unlock(A);				
						lock-X(A);
						R(A);
						W(A);

ABORT;
```

T1操作完后释放锁，T2获得锁操作A，此时T1回滚了，T2也必须回滚，因为之前T1修改过的数据没有commit，所以T2脏读了

- 强2pl锁：

  没有shrinking阶段，上锁之后直到commit时才能unlock，意味着这个事务操作的所有数据直到数据结束都不会被其他事务读写。

不会造成级联回滚，回滚时不需要在遍历log回滚恢复，只需要记录最开始的状态即可。





#### 基于时间戳的并发控制（乐观锁）



### **隔离性**

原子性的问题解决了，但是如果有另外的事务在同时修改数据A怎么办呢？ 虽然可以保证事务的同生共死，但是数据一致性会被破坏。 此时需要引入数据的[隔离机制](https://www.zhihu.com/search?q=隔离机制&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})，确保同时只能有一个事务在修改A，一个修改完了，另一个才来修改。 这需要对数据A加上[互斥锁](https://www.zhihu.com/search?q=互斥锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})：

- 先获得了锁，然后才能修改对应的数据A
- 事务完成后释放锁，给下一个要修改数据A的事务
- 同一时间，只能有一个事务持有数据A的互斥锁
- 没有获取到锁的事务，需要等待锁释放

以上面的事务为例，称作T1，T1在更新A的时候，会给A加上互斥锁，保证同时只能有一个事务在修改A。 那么这个锁什么时候释放呢？ 当A更新完毕后，正在更新B时(T1还没有提交)，有另外一个事务T2想要更新A，它能获取到A的互斥锁吗？

答案是不能， 如果T1在更新完A后，就释放了互斥锁，此时T2获取到T1的最新值，并做修改， 如果一且正常，则万事大吉。 但是如果在T2更新A时，T1因为后面的语句执行失败而回滚了呢？

1. 此时T1会撤销对A的修改，
2. T2得到的A数据就是脏数据，更新脏数据就会导致数据不一致。

所以，在事务中更新某条数据获得的互斥锁，**只有在事务提交或失败之后才会释放**，在此之前，其他事务是只能读，不能写这条数据的。

这就是隔离性的关键，针对隔离性的强度，有以下四的级别([引用自这篇文章](https://link.zhihu.com/?target=http%3A//blog.jobbole.com/100349/))：

- 串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的"世界", [串行执行](https://www.zhihu.com/search?q=串行执行&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})。
- 可重复读（Repeatable read，MySQL默认模式）：如果一个事务成功执行并且**添加了新数据**(事务提交)，这些数据对其他正在执行的事务是可见的。**但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。**所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。
- 读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。这叫不可重复读（non-repeatable read）。
- 读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。这叫[脏读](https://www.zhihu.com/search?q=脏读&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})（dirty read）。

接下来详细解释，假设有下面两个事务**同时执行**：

```sql
begin; -- 事务1
insert into table1 (somevaue); -- 随意写的伪sql
update table2 set aa = aa + 1 where id = 1;
commit;
```



```sql
begin; -- 事务2
select count(*) from table1; -- 第一次读count
select aa from table2 where id = 1; -- 第一次读aa
-- 假设在这个点 事务1成功提交
select count(*) from table1; -- 第二次读count
select aa from table2 where id = 1; -- 第二次读aa
commit;
```

串行化不用解释了，依次执行，不会产生冲突。
**可重复读**是什么意思呢？ 事务2执行到一半时，事务1 成功提交：

- 事务2中 `第二次读count`得到的值和`第一次读count`得到的值不一样(因为事务1新增了一条数据)，这叫**[幻读](https://www.zhihu.com/search?q=幻读&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})**，不隔离新增的数据。
- 事务2中 `第一次读aa` 和`第二次读aa`得到的值是一样的，**对刚更新的值不可见**，隔离已经存在的数据。 可以重复读，读到的数据都是一样的。



**读取已提交**是什么意思呢？ 事务2执行到一半时，事务1 成功提交：

- 事务2中 `第二次读count`得到的值和`第一次读count`得到的值不一样(因为事务1新增了一条数据)，这叫**幻读**，不隔离新增的数据。
- 事务2中 `第一次读aa` 和`第二次读aa`得到的值是不一样的，**对刚提交（修改）的值可见**，不隔离已经存在的数据。 不可以重复读，读到的数据是不一样的(如果成功修改)。



**读取未提交**是什么意思呢？ 事务2执行到一半时，事务1 还未提交：

- 事务2中 `第二次读count`得到的值和`第一次读count`得到的值不一样(因为事务1新增了一条数据)，这叫**幻读**，不隔离新增的数据。
- 事务2中 `第一次读aa` 和`第二次读aa`得到的值是不一样的（事务1未提交），对最新版本的值可见，不隔离已经存在的数据。 不可以重复读，读到的数据是不一样的。
- 如果此时事务1因为其他原因回滚了，事务2第二次读到的数据是无意义的，因为修改没有发生(回滚了)，这叫**脏读** 。



在现实环境中，串行化一般不会被使用，因为性能太低。

如果对一致性有要求，比如转账交易，那么要使用可重复读，并发性能相对较差。 原因是，为了实现可重复读，在对更新记录加锁时，除了使用记录锁，还可能会使用`间隙锁`锁住区间(看update语句的where条件)，这会增加其他事务等待时间。

如果对一致性要求不高，一般使用[读取已提交](https://www.zhihu.com/search?q=读取已提交&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"}), 由于不考虑重复读，在加锁时一般只加[记录锁](https://www.zhihu.com/search?q=记录锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})，不会使用间隙锁，并发性较好，据说使用的最多。

### **持久性**

隔离性的问题解决了，但是如果在事务提交后，事务的数据还没有真正落到磁盘上，此时数据库奔溃了，事务对应的数据会不会丢？

事务会保证数据不会丢，当数据库因不可抗拒的原因奔溃后重启，它会保证：

- 成功提交的事务，数据会保存到磁盘
- 未提交的事务，相应的数据会回滚

### **事务日志**

数据库通过事务日志来达到这个目标。 事务的每一个操作（增/删/改）产生一条日志，内容组成大概如下：

- LSN：一个按时间顺序分配的[唯一日志序列号](https://www.zhihu.com/search?q=唯一日志序列号&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})，靠后的操作的LSN比靠前的大。
- TransID：产生操作的事务ID。
- PageID：被修改的数据在磁盘上的位置，数据以页为单位存储。
- PrevLSN：同一个事务产生的上一条日志记录的指针。
- UNDO：取消本次操作的方法，按照此方法回滚。
- REDO：重复本次操作的方法，如有必要，重复此方法保证操作成功。

![img](数据库设计与实现/v2-72a7bf8a9178714da62fe47ebbbc806b_b.jpg)

来自jobbole.com

磁盘上每个页（保存数据的，不是保存日志的）都记录着最后一个修改该数据操作的LSN。数据库会通过解析事务日志，将修改真正落到磁盘上(写盘)，随后清理事务日志(正常情况下)。

这也是数据库在保证`数据安全`和`性能`这两个点之前的折中办法：

- 如果每次更新都写盘，由于数据是随机的，会造成大量的随机IO，性能会非常差
- 如果每次更新不马上写盘，那一旦数据库崩溃，数据就会丢失

折中的办法就是：

- 将数据的变更以事务日志的方式，按照时间先后追加到日志缓冲区，由特定算法写入事务日志，这是顺序IO，性能较好
- 通过[数据管理器](https://www.zhihu.com/search?q=数据管理器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"43493165"})解析事务日志，由特定的算法择机进行写盘

**数据库恢复**

当数据库从崩溃中恢复时，会有以下几个步骤：

- 解析存在的事务日志，分析哪些事务需要回滚，哪些需要写盘(还没来得及写盘，数据库就崩溃了)。
- Redo，进行写盘。检测对应数据所在数据页的LSN，如果数据页的LSN>=事务操作的LSN，说明已经写过盘，不然进行写盘操作。
- Undo, 按照LSN倒序进行回滚

经过这几个阶段，在数据库恢复后，可以达到奔溃前的状态，也保证了数据的一致性。

over

### 死锁处理

有两类基本思路：

1. 死锁预防，这类方法在死锁出现前就能发现可能导致死锁的操作。
2. 死锁检测，这类方法定期执行死锁检测算法，看是否发生死锁，如果发生了，执行死锁恢复算法。

这里介绍**wait-die和wound-wait**这种死锁预防机制，该机制描述如下：
事务Ti请求某个数据项，该数据项已经被事务Tj获取了锁，Ti允许等待当且仅当Ti的时间戳小于Tj（老人等新人），否则Ti将被roll back。

老事务请求某个数据项，该数据项已经被年轻事务获取了锁，老事务直接强过锁并让年轻事务回滚。反之年轻事务只能等待老事务。

**wait-die正确性证明**

**为什么该机制能保证，不会出现死锁的情况呢？**
如果Ti等待Tj释放锁，我们记Ti->Tj。那么系统中所有的事务将组成一个称作**wait-for graph**的有向图。容易证明：wait-for graph出现环和系统将出现死锁等价。
wait-die这种机制就能防止出现wait-for graph出现环。为什么？因为wait-die机制只允许时间戳小的等待时间戳大的事务，也就是说在wait-for graph中任意一条边Ti->Tj，Ti的时间戳都小于Tj，显然不可能出现环。所以不会出现环，也就不可能出现死锁。



**总结**

从某种意义上来说，这两者很类似，都是老事务优先(否则就会有饿死现象)
两个方法都保证事务执行是单向的(要么老的等新的(等现存的持有锁的新事务结束，而不是说等所有新的事务申请结束了才执行老的)，要么新的等老的)，不会出现循环等待，从而避免了死锁，也都确保了老事务的优先权，不会活锁


- 完全回滚

回滚事务的全部操作

- 部分回滚

先判断是哪几个sql语句造成死锁，回滚到死锁前的状态





### 实现事务

bus关于事务有两个类

- txn类负责事务微观的操作，记录更改的数据，记录事务的隔离级别，页面id，事务状态等待
- txn管理类负责事务宏观的操作，事务的开始提交回滚。

```c++
private:
  /** The current transaction state. */
  TransactionState state_;
  /** The isolation level of the transaction. */
  IsolationLevel isolation_level_;
  /** The thread ID, used in single-threaded transactions. */
  std::thread::id thread_id_;
  /** The ID of this transaction. */
  txn_id_t txn_id_;

  /** The undo set of table tuples. */
  std::shared_ptr<std::deque<TableWriteRecord>> table_write_set_;
  /** The undo set of indexes. */
  std::shared_ptr<std::deque<IndexWriteRecord>> index_write_set_;
  /** The LSN of the last record written by the transaction. */
  lsn_t prev_lsn_;

  /** Concurrent index: the pages that were latched during index operation. */
  std::shared_ptr<std::deque<Page *>> page_set_;
  /** Concurrent index: the page IDs that were deleted during index operation.*/
  std::shared_ptr<std::unordered_set<page_id_t>> deleted_page_set_;

  /** LockManager: the set of shared-locked tuples held by this transaction. */
  std::shared_ptr<std::unordered_set<RID>> shared_lock_set_;
  /** LockManager: the set of exclusive-locked tuples held by this transaction. */
  std::shared_ptr<std::unordered_set<RID>> exclusive_lock_set_;
```

事务管理

```c++

namespace bustub {
class LockManager;

/**
 * TransactionManager keeps track of all the transactions running in the system.
 */
class TransactionManager {
 public:
  explicit TransactionManager(LockManager *lock_manager, LogManager *log_manager = nullptr)
      : lock_manager_(lock_manager), log_manager_(log_manager) {}

  ~TransactionManager() = default;

  /**
   * Begins a new transaction.开启一个事务，创建一个事务
   * @param txn an optional transaction object to be initialized, otherwise a new transaction is created.
   * @param isolation_level an optional isolation level of the transaction.
   * @return an initialized transaction
   */
  Transaction *Begin(Transaction *txn = nullptr, IsolationLevel isolation_level = IsolationLevel::REPEATABLE_READ);
     {
  // Acquire the global transaction latch in shared mode.
  global_txn_latch_.RLock();

  if (txn == nullptr) {
    txn = new Transaction(next_txn_id_++, isolation_level);
  }

  txn_map[txn->GetTransactionId()] = txn;
  return txn;
}

  /**
   * Commits a transaction.提交事务--如果事务有删除操作在这部删除
   * @param txn the transaction to commit
   */
  void Commit(Transaction *txn);
     {
  txn->SetState(TransactionState::COMMITTED);

  // Perform all deletes before we commit.
  auto write_set = txn->GetWriteSet();
  while (!write_set->empty()) {
    auto &item = write_set->back();
    auto table = item.table_;
    if (item.wtype_ == WType::DELETE) {
      // Note that this also releases the lock when holding the page latch.
      table->ApplyDelete(item.rid_, txn);
    }
    write_set->pop_back();
  }
  write_set->clear();

  // Release all the locks.
  ReleaseLocks(txn);
  // Release the global transaction latch.
  global_txn_latch_.RUnlock();
}

  /**
   * Aborts a transaction 事务回滚----根据之前记录的log回滚复原
   * @param txn the transaction to abort
   */
  void Abort(Transaction *txn);
     {
  txn->SetState(TransactionState::ABORTED);
  // Rollback before releasing the lock.
  auto table_write_set = txn->GetWriteSet();
  while (!table_write_set->empty()) {
    auto &item = table_write_set->back();
    auto table = item.table_;
    if (item.wtype_ == WType::DELETE) {
      table->RollbackDelete(item.rid_, txn);
    } else if (item.wtype_ == WType::INSERT) {
      // Note that this also releases the lock when holding the page latch.
      table->ApplyDelete(item.rid_, txn);
    } else if (item.wtype_ == WType::UPDATE) {
      table->UpdateTuple(item.tuple_, item.rid_, txn);
    }
    table_write_set->pop_back();
  }
  table_write_set->clear();
  // Rollback index updates
  auto index_write_set = txn->GetIndexWriteSet();
  while (!index_write_set->empty()) {
    auto &item = index_write_set->back();
    auto catalog = item.catalog_;
    // Metadata identifying the table that should be deleted from.
    TableInfo *table_info = catalog->GetTable(item.table_oid_);
    IndexInfo *index_info = catalog->GetIndex(item.index_oid_);
    auto new_key = item.tuple_.KeyFromTuple(table_info->schema_, *(index_info->index_->GetKeySchema()),
                                            index_info->index_->GetKeyAttrs());
    if (item.wtype_ == WType::DELETE) {
      index_info->index_->InsertEntry(new_key, item.rid_, txn);
    } else if (item.wtype_ == WType::INSERT) {
      index_info->index_->DeleteEntry(new_key, item.rid_, txn);
    } else if (item.wtype_ == WType::UPDATE) {
      // Delete the new key and insert the old key
      index_info->index_->DeleteEntry(new_key, item.rid_, txn);
      auto old_key = item.old_tuple_.KeyFromTuple(table_info->schema_, *(index_info->index_->GetKeySchema()),
                                                  index_info->index_->GetKeyAttrs());
      index_info->index_->InsertEntry(old_key, item.rid_, txn);
    }
    index_write_set->pop_back();
  }
  table_write_set->clear();
  index_write_set->clear();

  // Release all the locks.
  ReleaseLocks(txn);
  // Release the global transaction latch.
  global_txn_latch_.RUnlock();
}

  /**
   * Global list of running transactions
   */

  /** The transaction map is a global list of all the running transactions in the system. */
  static std::unordered_map<txn_id_t, Transaction *> txn_map;

  /**
   * Locates and returns the transaction with the given transaction ID.
   * @param txn_id the id of the transaction to be found, it must exist!
   * @return the transaction with the given transaction id
   */
  static Transaction *GetTransaction(txn_id_t txn_id) {
    assert(TransactionManager::txn_map.find(txn_id) != TransactionManager::txn_map.end());
    auto *res = TransactionManager::txn_map[txn_id];
    assert(res != nullptr);
    return res;
  }

  /** Prevents all transactions from performing operations, used for checkpointing. */
  void BlockAllTransactions();

  /** Resumes all transactions, used for checkpointing. */
  void ResumeTransactions();

 private:
  /**
   * Releases all the locks held by the given transaction.
   * @param txn the transaction whose locks should be released
   */
  void ReleaseLocks(Transaction *txn) {
    std::unordered_set<RID> lock_set;
    for (auto item : *txn->GetExclusiveLockSet()) {
      lock_set.emplace(item);
    }
    for (auto item : *txn->GetSharedLockSet()) {
      lock_set.emplace(item);
    }
    for (auto locked_rid : lock_set) {
      lock_manager_->Unlock(txn, locked_rid);
    }
  }

  std::atomic<txn_id_t> next_txn_id_{0};
  LockManager *lock_manager_ __attribute__((__unused__));
  LogManager *log_manager_ __attribute__((__unused__));

  /** The global transaction latch is used for checkpointing. */
  ReaderWriterLatch global_txn_latch_;
};

}  // namespace bustub

```



# 并发控制

### 意向锁

①在mysql中有表锁，

LOCK TABLE my_tabl_name READ;  用读锁锁表，会阻塞其他事务修改表数据。

LOCK TABLE my_table_name WRITe; 用写锁锁表，会阻塞其他事务读和写。

②Innodb引擎又支持行锁，行锁分为

[共享锁](https://www.zhihu.com/search?q=共享锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"127777478"})，一个事务对一行的共享只读锁。

[排它锁](https://www.zhihu.com/search?q=排它锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"127777478"})，一个事务对一行的排他[读写锁](https://www.zhihu.com/search?q=读写锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"127777478"})。



③这两中类型的锁共存的问题

考虑这个例子：

事务A锁住了表中的**一行**，让这一行只能读，不能写。

之后，事务B申请**整个表**的写锁。

如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。

数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了[行锁](https://www.zhihu.com/search?q=行锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"127777478"})。

数据库要怎么判断这个冲突呢？

step1：判断表是否已被其他事务用表锁锁表

step2：判断表中的每一行是否已被行锁锁住。

注意step2，这样的判断方法效率实在不高，因为需要遍历整个表。

于是就有了[意向锁](https://www.zhihu.com/search?q=意向锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"127777478"})。

在意向锁存在的情况下，事务A必须先申请表的[意向共享锁](https://www.zhihu.com/search?q=意向共享锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"127777478"})，成功后再申请一行的行锁。

在意向锁存在的情况下，上面的判断可以改成

step1：不变

step2：发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。



注意：申请意向锁的动作是数据库完成的，就是说，事务A申请一行的行锁的时候，数据库会自动先开始申请表的意向锁，不需要我们程序员使用代码来申请。

需要强调一下，意向锁是一种不与行级锁冲突表级锁，这一点非常重要。意向锁分为两种：

- **意向共享锁**（intention shared lock, IS）：事务有意向对表中的某些行加**共享锁**（S锁）

```text
-- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。
SELECT column FROM table ... LOCK IN SHARE MODE; 
```

- **意向排他锁**（intention exclusive lock, IX）：事务有意向对表中的某些行加**排他锁**（X锁）

```text
-- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。
SELECT column FROM table ... FOR UPDATE; 
```

即：意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。

**意向锁要解决的问题**

我们先来看一下百度百科上对意向锁存在意义的描述：

> 如果另一个任务试图在该表级别上应用共享或排它锁，则受到由第一个任务控制的表级别意向锁的阻塞。第二个任务在锁定该表前不必检查各个页或行锁，而只需检查表上的意向锁。**因此 IS 和 IX 的作用就是在上表级锁的时候，可以快速判断是否可以上锁，而不需要遍历表中的所有记录**。
>
> 所以 IS 和 IX 互相之间是不会冲突的，因为它们的作用只是打个标记

为了确保事务操作的正确交错，DBMS 将使用锁管理器 （LM） 来控制何时允许事务访问数据项。 LM 的基本思想是它维护一个关于活动事务当前持有的锁的内部数据结构。 然后，事务在允许它们访问数据项之前向 LM 发出锁定请求。 LM 将授予对调用事务的锁定、阻止该事务或中止该事务。注意：LM实现的是底层原理的锁，而不是对锁（mutex）的二次封装！

事务管理器LockManager对外提供四个接口函数：

1. `LockShared(Transaction, RID)`: 事务 **txn** 尝试在记录 ID **rid** 上获取共享锁。这应该在等待时被阻止，并在授予时返回 true。如果事务回滚（中止），则返回 false。
2. `LockExclusive(Transaction, RID)`: 事务 **txn** 尝试对记录 ID **rid** 进行独占锁定。这应该在等待时被阻止，并在授予时返回 true。如果事务回滚（中止），则返回 false。
3. `LockUpgrade(Transaction, RID)`: 事务 **txn** 尝试将记录 ID **rid** 上的共享锁定升级为独占锁。这应该在等待时被阻止，并在授予时返回 true。如果事务回滚（中止），则返回 false。这也应该中止事务，如果另一个事务已经在等待升级其锁，则返回 false。
4. `Unlock(Transaction, RID)`: 解锁由事务持有的给定记录 ID 标识的记录。

可以用如下数据结构来实现：
![lab3_6_lock_manager.PNG](数据库设计与实现/lab3_6_lock_manager.PNG)

共享和独占锁可以参考读写锁的实现，共享独占锁需要做的不仅仅是简单的加锁更重要的是通过线程间通信实现**主动让锁，主动等锁**，而因为实质上，锁的本质就是线程通信，实现锁就是实现线程同步！！



### 读写锁

举个例子：同样是读写锁

<img src="数据库设计与实现/20180518194810329" alt="这里写图片描述" style="zoom:67%;" />

写只有一位！！读可以有多位！！

三种关系：（1）读和读之间没有关系              

​				   （2） 写和写之间是互斥关系          

​			       （3）读和写之间是同步互斥关系 

ps：同步---->读和写在同时竞争锁的时候，写会优先的得到锁    

​        互斥--->读的时候写阻塞，写的时候读阻塞

Dylar的写法：

使用mutex来实现对临界区加锁，并且根据RAII思想，对mutex封装，构造函数对mutex lock，析构函数对mutex unlock，避免了因为异常（忘了解锁或在解锁之前线程崩溃）而死锁的问题。对于同一线程重复上锁的问题，定义线程局部的变量来判断是否已经上锁

```c++
thread_local bool is_lock=false;
class RWmutex
	{
	public:
		RWmutex() {
			pthread_rwlock_init(&m_mutex, NULL);
		}
		~RWmutex() {
			pthread_rwlock_destroy(&m_mutex);
		}
		void rdlock() {
			pthread_rwlock_rdlock();
		}
		void wrlock() {
			pthread_rwlock_wrlock();
		}
		void unlock() {
			pthread_rwlock_unlock(&m_mutex);
		}
	private:
		pthread_rwlock_t m_mutex;
	};
	class  Dmutex
	{
	public:
		Dmutex() { pthread_mutex_init(&m_mutex, NULL); }
		~Dmutex() { pthread_mutex_destroy(&m_mutex); }
		void lock() {
			pthread_mutex_lock(&m_mutex);
		}
		void unlock() {
			pthread_mutex_unlock(&m_mutex);
		}
	private:
		pthread_mutex_t m_mutex;
	};

	template<class T>
	class Dlock {
	public:
		Dlock(T& mutex,int lock_idx_=0) :
			m_dmutex(mutex) {
            if(is_lock){
				return ;
            }
            switch(lock_idx_){
                case 0:m_dmutex.lock();
                case 1:m_dmutex.rdlock();
                case 2:m_dmutex.wrlock();
            }
			
		}
		~Dlock() {
            if(!is_lock){
                return ;
            }
			m_dmutex.unlock();
            is_lock=false;
		}
	private:
		T& m_dmutex;
	};
```

bus的实现：

bus通过两个条件变量来实现互斥访问(**互斥锁的lock并不是对临界区lock，而是对条件变量lock，临界区的lock是由条件变量实现的**！------lock是wait，unlock是notify)。注意：使用条件变量对唤醒和沉睡时的条件要用while循环判断！！因为可能出现虚假唤醒的问题。

**unique_lock 和 lock_guard**

lock_guard:构造时加锁，析构时解锁

unique_lock:在构造函数加锁，然后可以利用unique.unlock()来解锁，所以当你觉得锁的粒度太多的时候，可以利用这个来解锁，而析构的时候会判断当前锁的状态来决定是否解锁，如果当前状态已经是解锁状态了，那么就不会再次解锁，而如果当前状态是加锁状态，就会自动调用unique.unlock()来解锁。而lock_guard在析构的时候一定会解锁，也没有中途解锁的功能。

三种关系：（1）读和读之间没有关系（不会阻塞）            

​				   （2） 写和写之间是互斥关系          

​			       （3）读和写之间是同步互斥关系  （读结束了可以写，写结束了可以读）

ps：同步---->读和写在同时竞争锁的时候，写会优先的得到锁    

​        互斥--->读的时候写阻塞，写的时候读阻塞

```c++

/**
 * Reader-Writer latch backed by std::mutex.
 */
class ReaderWriterLatch {
  using mutex_t = std::mutex;
  using cond_t = std::condition_variable;
  static const uint32_t MAX_READERS = UINT_MAX;

 public:
  ReaderWriterLatch() = default;
  ~ReaderWriterLatch() { std::lock_guard<mutex_t> guard(mutex_); }

  DISALLOW_COPY(ReaderWriterLatch);

  /**
   * Acquire a write latch.如果有比我先来的写者或还有读者，让出锁，直到成为第一写者或没有读者。
   */
  void WLock() {
    std::unique_lock<mutex_t> latch(mutex_);
    //实现先写先锁：排队上锁。
    //如果已经有写锁,等待写锁解锁
    while (writer_entered_) {
      //原子地解锁 lock ，阻塞当前执行线程，并将它添加到于 *this 上等待的线程列表。线程将在执行 notify_all() 或 notify_one() 时被解除阻塞。解阻塞时，无关乎原因， lock 再次锁定且 wait 退出。
      reader_.wait(latch);
    }
    writer_entered_ = true;
    //如果有读，让出锁
    while (reader_count_ > 0) {
      writer_.wait(latch);
    }
  }

  /**
   * Release a write latch.
   */
  void WUnlock() {
    //lock_guard的构造时就自动调用lock析构时自动调用unlock，无需再lock
    std::lock_guard<mutex_t> guard(mutex_);
    writer_entered_ = false;
    //唤醒所有读者
    reader_.notify_all();
  }

  /**
   * Acquire a read latch.当全是读锁时，不会阻塞。
   */
  void RLock() {
    std::unique_lock<mutex_t> latch(mutex_);
    //如果有写锁或读者到上限，等待解锁。
    while (writer_entered_ || reader_count_ == MAX_READERS) {
      reader_.wait(latch);
    }
    reader_count_++;
  }

  /**
   * Release a read latch.
   */
  void RUnlock() {
    std::lock_guard<mutex_t> guard(mutex_);
    reader_count_--;
    if (writer_entered_) {
      if (reader_count_ == 0) {
        writer_.notify_one();
      }
    } else {
      if (reader_count_ == MAX_READERS - 1) {
        reader_.notify_one();
      }
    }
  }

 private:
  mutex_t mutex_;
  //什么时候能写
  cond_t writer_;
  //什么时候能读
  cond_t reader_;
  uint32_t reader_count_{0};
  bool writer_entered_{false};
};

```





## MVCC

多版本并发控制（MVCC：Multi-Version Concurrency Control）的DBMS在内部会维护着单个逻辑数据的多个物理版本。当一个事务修改某数据时，DBMS会创建一个新的版本；当一个事务读取某数据时，该事务开始时刻之前的数据最新版本将会返回给此事务。如果保留数据的所有历史版本，DBMS 甚至能够支持读取任意历史版本的数据，即time-travel。

使用mvcc最核心的特征是：读不阻塞写，写不阻塞读

只读事务可以不用加锁，读一个连续的数据快照，而不受外界事务的干扰。快照存储了各个时刻（时间戳代表的版本号）数据的信息，按事务所需读取需要的时刻的数据。

**成功的例1**

事务T1和T2分别获得时间戳1和2，二者的执行过程如下图所示。开始前，数据库存有数据A的原始版本A0，T1先读取 A 数据：



![img](数据库设计与实现/v2-de1cbf88bc01f8fdf85067949a3ac1a9_720w.webp)



然后T2修改A数据。这时DBMS中将增加A数据的新版本A1，同时标记A1的开始时间戳记录为2，A0的结束时间戳为2：



![img](数据库设计与实现/v2-f6da0c04b1c617030b6b61b34ca22df0_720w.webp)



T1再次读取A。因为它的时间戳为1，根据记录的信息，DBMS将A0返回给T1 ：



![img](数据库设计与实现/v2-a3cee9170fe51ed114b150f1e45e2595_720w.webp)



**失败的例2**

T1先修改数据A。



![img](数据库设计与实现/v2-0995695a72a9e07fc193be1b72cdf419_720w.webp)



此时T2读取A，由于**T2时间戳晚于T1，且T1尚未提交**，因此T2 只能读取A0：



![img](数据库设计与实现/v2-eaa396b43e77f9310e0c9dfcc70df3a2_720w.webp)



T2想修改A，但由于有另一个活跃的事务T1正在修改A ，T2需要等待T1提交后才能继续推进：



![img](数据库设计与实现/v2-3293ee3f15d8f2027e539b953e38b129_720w.webp)



T1提交后，T2创建了 A 的下一个版本A2 ：



![img](数据库设计与实现/v2-3d8bf3cae6e0c75d2ccb7b384eebe9a1_720w.webp)

在只是用mvcc的情况下，得到的结果显然是错误的！！

我们要使用MVCC实现序列化就必须让MVCC和

- 时间戳(T/O)：为每个事务赋予时间戳，并用以决定执行顺序
- 乐观的并发控制：为每个事务创建私有空间，并将事务分为读，有效性检查和写3个阶段处理
- 两段封锁：按照 2PL 的约定获取和释放锁

结合。几乎所有的数据库都实现了MVCC。

有了MVCC我们在查询数据的时候，可以修改数据，我们在修改数据的时候，可以查询数据。也就是说，**有读锁，依然可以使用写锁；有写锁，依然可以使用读锁；但是，在有写锁的情况下，其他事务不能再对当前数据添加写锁**，因为要保证数据的一致性。

### 版本存储

DBMS通常会为每个数据设置一条版本链表 (version chain)，所有相关的索引都会指到这个链表的头节点。DBMS可以利用它找到一个事务应该访问到的版本。目前主要有3种存储版本信息的方式：

- Append-Only Storage：新版本通过追加的方式存储在同一张表中
- Time-Travel Storage：老版本被复制到单独的一张表中
- Delta Storage：老版本数据的被修改的字段值被复制到一张单独的增量表 (delta record space) 中

#### Append-Only Storage

同一个逻辑数据的所有物理版本都被存储在同一张表上，每次更新时，就往表上追加一个新的版本记录，并在旧版本的数据上增加一个指针指向新版本：



![img](数据库设计与实现/v2-7c6ca967d09a89d90e711f45a24d28ac_720w.webp)



再次更新的行为类似：



![img](数据库设计与实现/v2-c4e155ac72056e7b38a540d4bdf1c9ec_720w.webp)



指针的方向可以从新到旧，也可以从旧到新。

#### Time-Travel Storage

单独拿一张表 (Time-Travel Table) 来存历史数据，每当更新数据时，就把当前版本复制到 TTT 表中，并更新指针：



![img](数据库设计与实现/v2-7ca31ca17ace0102807c12db43962c6f_720w.webp)





![img](数据库设计与实现/v2-adfd9ea6ec93d3725266928d0c06dfc9_720w.webp)





![img](数据库设计与实现/v2-42c42d1272dd25e2c7fab69189adce53_720w.webp)



#### Delta Storage

每次更新，仅将变化的字段信息存储到 delta storage segment 中：



![img](数据库设计与实现/v2-04808fadf9e18dc5c2d7df086960e965_720w.webp)





![img](数据库设计与实现/v2-8d11c8e181f9654c732660198271eac9_720w.webp)





![img](数据库设计与实现/v2-21b3297abdf13f56f670633f37fcfbf1_720w.webp)





![img](数据库设计与实现/v2-538135b70e5f0292571c77a4ff165d4c_720w.webp)



DBMS可以通过delta数据逆向恢复数据到之前的版本。

### 垃圾回收

随着时间的推移，DBMS中数据的旧版本可能不再会被用到，比如已经没有活跃的事务需要看到该版本或者该版本是被一个已经中止的事务创建的。这时候 DBMS 就需要删除这些可以回收的物理版本，这个过程也被称为GC。设计GC时可以从两个角度出发：

- 元组级别管理：直接检查每条数据的旧版本数据
- 事务级别管理：每个事务负责跟踪数据的旧版本，DBMS 不需要亲自检查单条数据

#### 元组级别管理的GC

**Background Vacuuming**

如下图所示，假设有2个活跃事务，它们的时间戳分别为12和25：



![img](数据库设计与实现/v2-65baf8961a9ee9434d3047c011b37882_720w.webp)



这时有个Vacuum线程会周期性地检查每条数据的不同版本。如果某条数据版本的结束时间小于当前活跃事务的最小时间戳，则将其删除：



![img](数据库设计与实现/v2-754c41b527eb3c341b655be2728527ca_720w.webp)



为了加快GC的速度，DBMS还可以再维护一个脏页位图(dirty page bitmap)，利用它Vacuum线程可以只检查发生过改动的数据，用空间换时间。该方法对任何的版本存储方法都适用。

**Cooperative Cleaning**

当worker thread查询数据时，顺便将不再使用物理数据版本删除。需要注意的是，使用该方案的化，版本链表只能从旧节点指向新节点。



![img](数据库设计与实现/v2-898a96e13d72b8d2b4b24e0c02a1cb00_720w.webp)





![img](数据库设计与实现/v2-a8178df53306a9f37a3677dcc9aa09fe_720w.webp)



#### 事务级别管理的GC

让每个事务都保存着它的读写数据集合 (read/write set)，当DBMS决定什么时候这个事务创建的各版本数据可以被回收时，就按照集合内部的数据处理即可。



![img](数据库设计与实现/v2-634302016f1812c7890a8e2d8a92d4b2_720w.webp)





![img](数据库设计与实现/v2-fdebce5817ba22eddd1a02e203d402a4_720w.webp)



### 索引管理

- 主键索引：主键的索引直接指向版本链表的头节点。如果一个事务更新了一个元组的主键，则我们把它当成先删除再添加
- 二级索引：二级索引有两种方式指向数据本身：使用逻辑指针，即使用元组不会改变的标识符，利用中间层来将进行转换以找到相应的版本链。这里可以使用主键值或元组id；也可以 使用物理指针，即存储指向版本链表的头部的指针

**物理指针**



![img](数据库设计与实现/v2-d8d9e3a1c2ff96058f1c33a729c8f5a9_720w.webp)



**指向主键的逻辑指针**



![img](数据库设计与实现/v2-b0a2b33a1c99dc9931b9b0eb84ee0b36_720w.webp)



**指向元组id的逻辑指针**



![img](数据库设计与实现/v2-773d6aaf003563f9b08ca892513e4f4d_720w.webp)





### 共享和独占锁

共享锁，又称之为读锁，简称S锁，当事务对数据加上读锁后，**其他事务只能对该数据加读锁**，不能做任何修改操作，也就是不能添加写锁。只有当数据上的[读锁](https://www.zhihu.com/search?q=读锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"52879825"})被释放后，其他事务才能对其添加写锁。**共享锁的request_queue里只能有共享锁**

排它锁，又称之为写锁，简称X锁，当事务对数据加上写锁后，**其他事务既不能对该数据添加读写，也不能对该数据添加写锁**，写锁与其他锁都是互斥的。只有当前数据写锁被释放后，其他事务才能对其添加写锁或者是读锁。[写锁](https://www.zhihu.com/search?q=写锁&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"52879825"})主要是为了解决在修改数据时，不允许其他事务对当前数据进行修改和读取操作，从而可以有效避免”[脏读](https://www.zhihu.com/search?q=脏读&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"52879825"})”问题的产生。**获得独占锁条件-request_queue必须为空！！！！**

request_queue中的事务就是获得锁了的事务。

```c++

bool LockManager::LockShared(Transaction *txn, const RID &rid) {
  std::unique_lock<std::mutex> ul(latch_);

recheckAfterNotify:

  if (txn->GetState() == TransactionState::ABORTED) {
    return false;
  }
  // 如果隔离级别是READ_UNCOMMITTED，不用读锁
  if (txn->GetIsolationLevel() == IsolationLevel::READ_UNCOMMITTED) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // REPEATABLE_READ, SHRINKING不可获得锁,REPEATABLE_READ是严格遵守两阶段协议的
  if (txn->GetIsolationLevel() == IsolationLevel::REPEATABLE_READ && txn->GetState() == TransactionState::SHRINKING) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // 已经获得锁
  if (txn->IsSharedLocked(rid)) {
    return true;
  }

  LockRequestQueue &rq = lock_table_[rid];
  if (lock_table_.count(rid) != 0U) {
    auto it = rq.request_queue_.begin();
    // bool haveInsert = false;
    while (it != rq.request_queue_.end()) {
      // 当前事务是老事务，队列中已经有的是新事物，根据锁相容，如果新事物都是读锁，则相容，写锁的话，不相容
      // 等待队列中的新事物持有写锁，根据wound-wait,需要Abort这个事务
      Transaction *tra = TransactionManager::GetTransaction(it->txn_id_);
      if (it->txn_id_ > txn->GetTransactionId() && (it->lock_mode_ == LockMode::EXCLUSIVE)) {
        // Abort掉这个新事物
        tra->GetExclusiveLockSet()->erase(rid);
        tra->SetState(TransactionState::ABORTED);
        it = rq.request_queue_.erase(it);
      } else if (it->txn_id_ < txn->GetTransactionId() && (it->lock_mode_ == LockMode::EXCLUSIVE)) {
        // 当前事务是新事物，如果有老事务已经持有写锁，则等待
        rq.cv_.wait(ul);  //可能导致虚假唤醒，所以要在检查一遍。
        goto recheckAfterNotify;
      } else {
        it++;
      }
    }
  }

  txn->SetState(TransactionState::GROWING);
  LockRequest new_add(txn->GetTransactionId(), LockMode::SHARED);
  new_add.granted_ = true;
  rq.request_queue_.emplace_back(new_add);
  txn->GetSharedLockSet()->emplace(rid);
  return true;
}

bool LockManager::LockExclusive(Transaction *txn, const RID &rid) {
  std::unique_lock<std::mutex> ul(latch_);

  // recheckAfterNotify:

  if (txn->GetState() == TransactionState::ABORTED) {
    return false;
  }

  // REPEATABLE_READ, SHRINKING不可获得锁,REPEATABLE_READ是严格遵守两阶段协议的
  if (txn->GetIsolationLevel() == IsolationLevel::REPEATABLE_READ && txn->GetState() == TransactionState::SHRINKING) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // 已经获得锁
  if (txn->IsExclusiveLocked(rid)) {
    return true;
  }

  LockRequestQueue &rq = lock_table_[rid];
  if (lock_table_.count(rid) != 0U) {
    auto it = rq.request_queue_.begin();
    while (it != rq.request_queue_.end()) {
      Transaction *tra = TransactionManager::GetTransaction(it->txn_id_);
    
      if (it->txn_id_ > txn->GetTransactionId()) {
        // 当前事务是老事务，abort掉在等待队列中的新事务
        tra->SetState(TransactionState::ABORTED);
        if (it->lock_mode_ == LockMode::SHARED) {
          tra->GetSharedLockSet()->erase(rid);
        } else {
          tra->GetExclusiveLockSet()->erase(rid);
        }
        it = rq.request_queue_.erase(it);
      } else if (it->txn_id_ < txn->GetTransactionId()) {
        // 当前事务是新事务，等待老事务释放锁
        //如果在这里wait会导致饥饿，因为并没有阻止读者继续读！！！
        //如果有一群老人在读，写者必须阻塞，因为写者阻塞，所以后续的读者增加！！！可能会永远有读者的场景。
        txn->SetState(TransactionState::ABORTED);
        return false;
        // rq.cv_.wait(ul);
        // goto recheckAfterNotify;
      } else {
        it++;
      }
    }
  }

  txn->SetState(TransactionState::GROWING);
  LockRequest new_add(txn->GetTransactionId(), LockMode::EXCLUSIVE);
  new_add.granted_ = true;
  rq.request_queue_.emplace_back(new_add);
  txn->GetExclusiveLockSet()->emplace(rid);
  return true;
}

bool LockManager::LockUpgrade(Transaction *txn, const RID &rid) {
  std::unique_lock<std::mutex> ul(latch_);

recheckAfterNotify:

  if (txn->GetState() == TransactionState::ABORTED) {
    return false;
  }

  // REPEATABLE_READ, SHRINKING不可获得锁,REPEATABLE_READ是严格遵守两阶段协议的
  if (txn->GetIsolationLevel() == IsolationLevel::REPEATABLE_READ && txn->GetState() == TransactionState::SHRINKING) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // 如果事务本身并没有获取到共享锁，则返回false
  if (!txn->IsSharedLocked(rid)) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // 如果已经获得排它锁，则直接返回true
  if (txn->IsExclusiveLocked(rid)) {
    return true;
  }

  LockRequestQueue &rq = lock_table_[rid];
  auto it = rq.request_queue_.begin();

  while (it != rq.request_queue_.end()) {
    Transaction *tra = TransactionManager::GetTransaction(it->txn_id_);
    if (it->txn_id_ > txn->GetTransactionId()) {
      // 当前事务是老事务, Abort掉新事物
      if (it->lock_mode_ == LockMode::SHARED) {
        tra->GetSharedLockSet()->erase(rid);
      } else {
        tra->GetExclusiveLockSet()->erase(rid);
      }
      it = rq.request_queue_.erase(it);
      tra->SetState(TransactionState::ABORTED);
    } else if (it->txn_id_ < txn->GetTransactionId()) {
      // 当前是新事物，等待
      rq.cv_.wait(ul);
      goto recheckAfterNotify;
    } else {
      it++;
    }
  }
  // 此时老事务已经Abort完了，所有新事物应该都等待完毕，与LockExclusive类似，LockExeclusive是获取锁时，一定是队列中第一个
  // LockUpdate此时队列中应该只剩下其自身的lockShared请求
  auto &request_shard = rq.request_queue_.front();
  // std::cout << request_shard.txn_id_ << " " << txn->GetTransactionId() << std::endl;
  assert(request_shard.txn_id_ == txn->GetTransactionId());
  request_shard.lock_mode_ = LockMode::EXCLUSIVE;
  request_shard.granted_ = true;
  txn->GetSharedLockSet()->erase(rid);
  txn->GetExclusiveLockSet()->emplace(rid);
  txn->SetState(TransactionState::GROWING);
  return true;
}

bool LockManager::Unlock(Transaction *txn, const RID &rid) {
  std::unique_lock<std::mutex> ul(latch_);

  // 如果隔离级别是repeatable_read，设置为shrinking阶段
  if (txn->GetState() == TransactionState::GROWING && txn->GetIsolationLevel() == IsolationLevel::REPEATABLE_READ) {
    txn->SetState(TransactionState::SHRINKING);
  }
  LockRequestQueue &rq = lock_table_[rid];
  auto it = rq.request_queue_.begin();
  bool ok = false;
  while (it != rq.request_queue_.end()) {
    if (it->txn_id_ == txn->GetTransactionId()) {
      LockMode mode = it->lock_mode_;
      it = rq.request_queue_.erase(it);
      if (mode == LockMode::SHARED) {
        txn->GetSharedLockSet()->erase(rid);
        rq.cv_.notify_all();
        ok = true;
      } else {
        txn->GetExclusiveLockSet()->erase(rid);
        rq.cv_.notify_all();
        ok = true;
      }
    } else {
      it++;
    }
  }
  return ok;
}
```

**bug:独占锁会导致饥饿**

因为读写锁的特性，写锁lock的条件一定是此时既没有事务读，也没有事务写！！即request_queue为空。bug出现的原因就是request _queue不是单减的！！

**改进：写者优先** 当有写者要写时组织后续读者进队列。这个方案的缺点是可能造成读者饥饿。但是数据库是个读多写少的模型，写者饥饿的概率要远远小于读者饥饿的。

**改进：减少回滚数（会不会造成wound wait失效？？？）**  因为队列中要么是全读，要么是一写。当request queue中有年轻事务时，当前事务可以让其回滚，一直到无法插队为止。而如果回滚的结局还是阻塞的化，前面的回滚就没有太大意义了。连续回滚的大部分都是读操作，而读操作是并发性最好的操作，让其回滚并不会对提前执行有多大的提升。所以先判断是否能全部回滚，如果可以，再执行回滚。如果不行，先阻塞。

```c++

bool LockManager::LockShared(Transaction *txn, const RID &rid) {
  std::unique_lock<std::mutex> ul(latch_);

recheckAfterNotify:

  if (txn->GetState() == TransactionState::ABORTED) {
    return false;
  }
  // 如果隔离级别是READ_UNCOMMITTED，不用读锁
  if (txn->GetIsolationLevel() == IsolationLevel::READ_UNCOMMITTED) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // REPEATABLE_READ, SHRINKING不可获得锁,REPEATABLE_READ是严格遵守两阶段协议的
  if (txn->GetIsolationLevel() == IsolationLevel::REPEATABLE_READ && txn->GetState() == TransactionState::SHRINKING) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // 已经获得锁
  if (txn->IsSharedLocked(rid)) {
    return true;
  }
  LockRequestQueue &rq = lock_table_[rid];
  //如果前面有写者要写，等他写完
  while(rq.writer_entered){
      rq.cv_.wait(ul);
      goto recheckAfterNotify;
  }
...................
}
bool LockManager::LockExclusive(Transaction *txn, const RID &rid) {
  std::unique_lock<std::mutex> ul(latch_);

recheckAfterNotify:

  if (txn->GetState() == TransactionState::ABORTED) {
    return false;
  }

  // REPEATABLE_READ, SHRINKING不可获得锁,REPEATABLE_READ是严格遵守两阶段协议的
  if (txn->GetIsolationLevel() == IsolationLevel::REPEATABLE_READ && txn->GetState() == TransactionState::SHRINKING) {
    txn->SetState(TransactionState::ABORTED);
    return false;
  }

  // 已经获得锁
  if (txn->IsExclusiveLocked(rid)) {
    return true;
  }

  LockRequestQueue &rq = lock_table_[rid];
  if (lock_table_.count(rid) != 0U) {
    auto it = rq.request_queue_.begin();
    while (it != rq.request_queue_.end()) {
      Transaction *tra = TransactionManager::GetTransaction(it->txn_id_);
    
      if (it->txn_id_ > txn->GetTransactionId()) {
        // 当前事务是老事务，abort掉在等待队列中的新事务
        tra->SetState(TransactionState::ABORTED);
        if (it->lock_mode_ == LockMode::SHARED) {
          tra->GetSharedLockSet()->erase(rid);
        } else {
          tra->GetExclusiveLockSet()->erase(rid);
        }
        it = rq.request_queue_.erase(it);
      } else if (it->txn_id_ < txn->GetTransactionId()) {
        // 当前事务是新事务，等待老事务释放锁
        //writer_entered防止读者增加。
        ra.writer_entered=true;
        rq.cv_.wait(ul);
        goto recheckAfterNotify;
      } else {
        it++;
      }
    }
  }

  txn->SetState(TransactionState::GROWING);
  LockRequest new_add(txn->GetTransactionId(), LockMode::EXCLUSIVE);
  new_add.granted_ = true;
  rq.request_queue_.emplace_back(new_add);
  txn->GetExclusiveLockSet()->emplace(rid);
  return true;
}
```



## SQL操作



### 全表扫描

- 预读

如果我们直到要全表扫描，可以提前读取页面

- 缓存池忽略

因为全表扫描的大部分页面都只是这一次被读，后续很少被访问，所以可以不走缓存池直接送到执行器，避免缓存带来的开销，即读即走。

- 并行

多线程读

- Zone maps

对每一页（不是每一个表）做一个统计信息，记录了这个页的max，min，avg.....。读取页面时先读取它的统计信息，如果这一页没有我们想要的数据，直接略过。

**缺点：Zone页在哪存？（不能存在页里）**

需要再另辟蹊径存储统计信息，并且修改页时还要修改统计信息。

- Heap clustering
- 索引扫描

**哪些索引可以用？**

索引是否有需要的属性

索引是否含有需要的输出列

索引包含的值域

索引是unique还是non-unique

索引支持的谓词操作

**多索引筛选**

先执行age索引扫描，在执行dept索引扫描，最后取交集做us索引扫描。

<img src="数据库设计与实现/image-20230116210202985.png" alt="image-20230116210202985" style="zoom:67%;" />

- 晚物化

操作的是tuple的RID，而不是tuple，对tuple的读写直到最后一层返回数据时才根据RID获得tuple

**对列存友好**

### 排序类（order，distinct）



- 内容小时：读取所有页面到内存，直接在内存中对内容排序再写回缓存
- 内容太大时:
  - 外部并归排序，再将排序的结果
    - 早物化：元数据和key值一起排序
    - 晚物化：值排序key值和其id，再根据id到表中查找对应的元数据

![image-20230107014428151](数据库设计与实现/image-20230107014428151.png)



**优化**

![image-20230107014900261](数据库设计与实现/image-20230107014900261.png)

n度缓存：

![image-20230107014927622](数据库设计与实现/image-20230107014927622.png)

使用B+树排序，因为B+树是天然有序的



### 聚集类（Groud by）

![image-20230107015058838](数据库设计与实现/image-20230107015058838.png)

- 排序聚集----先排序再聚集

先筛选，把 grade（等级）是B和C的sid和cid字段 筛选出来，然后做投影去除其他无用列，最后**排序后**删除（Remove Columns）重复的cid。

[![img](数据库设计与实现/Pasted-into-CMU15-445数据库系统：排序与聚集-7.png)](https://gaozhiyuan.net/wp-content/uploads/2022/03/Pasted-into-CMU15-445数据库系统：排序与聚集-7.png)

这样做可以通过排序来实现去重的目的。但是有些 DISTINCE 和 GROUP BY 操作是想涉及排序的，例如 DISTINCE 的目的仅仅是想去重，这时候如果我们非要进行排序就浪费了。下面使用哈希聚集可以解决这个问题。





- 哈希聚集----构建哈希表，相同key的数据在同一个桶

把碰撞的key放在同一个桶里。接下来需要 REHASH。因为相同key的因为碰撞放在了同一个桶中，但是还可能有的key就是因为本身hash函数导致的碰撞被放在了同一个桶中。——这不是我们想看到的。

![image-20230107015112079](数据库设计与实现/image-20230107015112079.png)

REHASH（再次hash）：将桶里的key进行第2次哈希，因为相同的key得到的hash一定也是相同的，所以可以把key本身不同导致的因为hash缺陷而误放在一个桶的key给筛选出来，剩下的在一个桶里的一定就是key相同的key了。

![image-20230107015216549](数据库设计与实现/image-20230107015216549.png)

上面的外部哈希聚集是单纯解决去重问题的，那如果是聚集起来是为了计算呢？例如下面的SQL是为了计算平均值：

[<img src="数据库设计与实现/Pasted-into-CMU15-445数据库系统：排序与聚集-10.png" alt="img" style="zoom:50%;" />](https://gaozhiyuan.net/wp-content/uploads/2022/03/Pasted-into-CMU15-445数据库系统：排序与聚集-10.png)

解决方法就是记录中间结果，二次hash table中再增加一列value列， value 记录下 (个数, 总和)，如果是平均值就保存个数和总和；如果是min就保存最低值；如果是sum就保存总和 … …最后再根据计算函数进行计算即可。

[<img src="数据库设计与实现/Pasted-into-CMU15-445数据库系统：排序与聚集-11.png" alt="img" style="zoom:50%;" />](https://gaozhiyuan.net/wp-content/uploads/2022/03/Pasted-into-CMU15-445数据库系统：排序与聚集-11.png)

### 连接类（join）

**小表一般都放左侧**

- 早物化：输出得到的是数据
- 晚物化：输出的是行id，再到各个表中根据id获取元数据



- 嵌套join

先读R一行，再遍历s表所有行，一个个比

![image-20230107015749750](数据库设计与实现/image-20230107015749750.png)

以页为单位的循环

假设两条是一页，则先读取R表的第一页（前两条），读取S表的前两条，这四条作对比，再读取s表的下一个两条和R表的两条作对比，直到s页全部读完，再到R表的下一页。

![image-20230107015819645](数据库设计与实现/image-20230107015819645.png)

**优点：以页为单位，先将R表读一页，遍历一遍s，再换下一页，遍历一遍s（尽量缓存外表，因为内表是一定会遍历的，即使缓存内表也会提前被后面的缓存刷掉）**

**缺点：重复读，缓冲利用率低**



- 索引join（B+树）

![image-20230107020055689](数据库设计与实现/image-20230107020055689.png)



- 排序join

![image-20230107020616909](数据库设计与实现/image-20230107020616909.png)

**优点：使用于要求按顺序输出，查找的表已经排好序了**



- hash join

先构建外表的hash表，内表去hash表中查找，

<img src="数据库设计与实现/image-20230118221158997.png" alt="image-20230118221158997" style="zoom: 50%;" />

先根据R表构造哈希表，S表每一行都去哈希表里是否有匹配的

哈希表的key-value选什么？

key就是tuple.GetValue(OutSchema()),value有两种，一种是tuple一种是tuple的Rid

key放置连接点。value还是有提前物化和延迟物化两种思路。可以存放R表中的所有字段；也可以存放R表中的部分字段，然后后续需要的话再去page中查询。

**优化：**内表一行行去哈希表匹配太慢了

构造布隆过滤器，查哈希表前先查布隆过滤器，如果布隆过滤器没命中就跳过，如果命中再去哈希表中查找。

![image-20230107020758068](数据库设计与实现/image-20230107020758068.png)

解决中间hash表的存放问题：



![image-20230107020903781](数据库设计与实现/image-20230107020903781.png)

连一块都装不进内存中时，再hash一次直到切成足够小

![image-20230107021009589](数据库设计与实现/image-20230107021009589.png)



## 火山模型

每个算子实现一个next（）函数输出结果，父算子调用子算子的next（），子算子返回结果给父算子。

r.next（）输出r表的所有元素，被r.id=s.id层调用，对r表的所有元素建立哈希表。s.next（）输出s表的所有元素，被s.value>100层调用，对s表中的所有元素筛选出s.value>100的。

![image-20230107021209089](数据库设计与实现/image-20230107021209089.png)

**优点：通用性强**

**缺点：join，order会被阻塞，递归过程性能下降**





**bustub的火山模型**

查询执行的最顶层是一个`ExecutionEngine`，通过调用`Execute`函数执行查询，参数里面主要涉及到 `AbstractPlanNode` 和 `ExecutorContext` 两个主要的类。`AbstractPlanNode`主要定义了该次查询的计划，包括输出的列格式以及子查询计划节点，该抽象类会被具体的查询计划节点所继承，如`SeqScanPlanNode`并在子类中完善各自查询所需要的不同资源；`ExecutorContext` 涉及了事务相关的内容，包括事务类，锁管理，缓冲池管理等，详见下面的构造函数。

<img src="数据库设计与实现/image-20230111205025571.png" alt="image-20230111205025571" style="zoom:80%;" />



**递归创建executor**



```c++
std::unique_ptr<AbstractExecutor> ExecutorFactory::CreateExecutor(ExecutorContext *exec_ctx,
                                                                  const AbstractPlanNode *plan) {
  switch (plan->GetType()) {
    // Create a new sequential scan executor
    case PlanType::SeqScan: {
      return std::make_unique<SeqScanExecutor>(exec_ctx, dynamic_cast<const SeqScanPlanNode *>(plan));
    }

    // Create a new index scan executor
    case PlanType::IndexScan: {
      return std::make_unique<IndexScanExecutor>(exec_ctx, dynamic_cast<const IndexScanPlanNode *>(plan));
    }

    // Create a new insert executor
    case PlanType::Insert: {
      auto insert_plan = dynamic_cast<const InsertPlanNode *>(plan);
      auto child_executor =
          insert_plan->IsRawInsert() ? nullptr : ExecutorFactory::CreateExecutor(exec_ctx, insert_plan->GetChildPlan());
      return std::make_unique<InsertExecutor>(exec_ctx, insert_plan, std::move(child_executor));
    }

    // Create a new update executor
    case PlanType::Update: {
      auto update_plan = dynamic_cast<const UpdatePlanNode *>(plan);
      auto child_executor = ExecutorFactory::CreateExecutor(exec_ctx, update_plan->GetChildPlan());
      return std::make_unique<UpdateExecutor>(exec_ctx, update_plan, std::move(child_executor));
    }

    // Create a new delete executor
    case PlanType::Delete: {
      auto delete_plan = dynamic_cast<const DeletePlanNode *>(plan);
      auto child_executor = ExecutorFactory::CreateExecutor(exec_ctx, delete_plan->GetChildPlan());
      return std::make_unique<DeleteExecutor>(exec_ctx, delete_plan, std::move(child_executor));
    }

    // Create a new limit executor
    case PlanType::Limit: {
      auto limit_plan = dynamic_cast<const LimitPlanNode *>(plan);
      auto child_executor = ExecutorFactory::CreateExecutor(exec_ctx, limit_plan->GetChildPlan());
      return std::make_unique<LimitExecutor>(exec_ctx, limit_plan, std::move(child_executor));
    }

    // Create a new limit executor
    case PlanType::Distinct: {
      auto distinct_plan = dynamic_cast<const DistinctPlanNode *>(plan);
      auto child_executor = ExecutorFactory::CreateExecutor(exec_ctx, distinct_plan->GetChildPlan());
      return std::make_unique<DistinctExecutor>(exec_ctx, distinct_plan, std::move(child_executor));
    }

    // Create a new aggregation executor
    case PlanType::Aggregation: {
      auto agg_plan = dynamic_cast<const AggregationPlanNode *>(plan);
      auto child_executor = ExecutorFactory::CreateExecutor(exec_ctx, agg_plan->GetChildPlan());
      return std::make_unique<AggregationExecutor>(exec_ctx, agg_plan, std::move(child_executor));
    }

    // Create a new nested-loop join executor
    case PlanType::NestedLoopJoin: {
      auto nested_loop_join_plan = dynamic_cast<const NestedLoopJoinPlanNode *>(plan);
      auto left = ExecutorFactory::CreateExecutor(exec_ctx, nested_loop_join_plan->GetLeftPlan());
      auto right = ExecutorFactory::CreateExecutor(exec_ctx, nested_loop_join_plan->GetRightPlan());
      return std::make_unique<NestedLoopJoinExecutor>(exec_ctx, nested_loop_join_plan, std::move(left),
                                                      std::move(right));
    }

    // Create a new nested-index join executor
    case PlanType::NestedIndexJoin: {
      auto nested_index_join_plan = dynamic_cast<const NestedIndexJoinPlanNode *>(plan);
      auto left = ExecutorFactory::CreateExecutor(exec_ctx, nested_index_join_plan->GetChildPlan());
      return std::make_unique<NestIndexJoinExecutor>(exec_ctx, nested_index_join_plan, std::move(left));
    }

    // Create a new hash join executor
    case PlanType::HashJoin: {
      auto hash_join_plan = dynamic_cast<const HashJoinPlanNode *>(plan);
      auto left = ExecutorFactory::CreateExecutor(exec_ctx, hash_join_plan->GetLeftPlan());
      auto right = ExecutorFactory::CreateExecutor(exec_ctx, hash_join_plan->GetRightPlan());
      return std::make_unique<HashJoinExecutor>(exec_ctx, hash_join_plan, std::move(left), std::move(right));
    }

    default:
      UNREACHABLE("Unsupported plan type.");
  }
```



### 执行器

**注意：当你持有着tuple和rid的引用时，不要释放锁！！否则可能会有其他事务拿到锁之后更新tableheap**

bustub有九个执行器，每个执行器用于以下操作：顺序扫描、插入、更新、删除、嵌套循环连接、哈希连接、聚合、限制和区别。对于每个查询计划运算符类型，都有一个实现和方法的相应执行器对象。该方法初始化运算符的内部状态（例如，检索要扫描的对应表）。该方法提供迭代器接口，该接口在每次调用时返回一个元组和相应的RID（或表示执行器已用尽的指示符）

AbstractExecutor实现了Volcano每次元组迭代器模型。提供两种虚函数

- Next（）：输出当前执行器得到的tuple
- GetOutputSchema（）：输出当前执行器得到的col

```c++
/**
 * The AbstractExecutor implements the Volcano tuple-at-a-time iterator model.
 * This is the base class from which all executors in the BustTub execution
 * engine inherit, and defines the minimal interface that all executors support.
 */
class AbstractExecutor {
 public:
  /**
   * Construct a new AbstractExecutor instance.
   * @param exec_ctx the executor context that the executor runs with
   */
  explicit AbstractExecutor(ExecutorContext *exec_ctx) : exec_ctx_{exec_ctx} {}

  /** Virtual destructor. */
  virtual ~AbstractExecutor() = default;

  /**
   * Initialize the executor.
   * @warning This function must be called before Next() is called!
   */
  virtual void Init() = 0;

  /**
   * Yield the next tuple from this executor.
   * @param[out] tuple The next tuple produced by this executor
   * @param[out] rid The next tuple RID produced by this executor
   * @return `true` if a tuple was produced, `false` if there are no more tuples
   */
  virtual bool Next(Tuple *tuple, RID *rid) = 0;

  /** @return The schema of the tuples that this executor produces */
  virtual const Schema *GetOutputSchema() = 0;

  /** @return The executor context in which this executor runs */
  ExecutorContext *GetExecutorContext() { return exec_ctx_; }

 protected:
  /** The executor context in which the executor runs */
  ExecutorContext *exec_ctx_;
};
```



- aggregation_executor.h（聚合操作）

COUNT(),AVE(),MN(),MAX(),SUM()

执行器将来自单个子执行器的多个元组结果合并到单个元组中。实现聚合的常见策略是使用哈希表。这也是本项目中使用的方法，但是，bustub做了一个简化的假设，即聚合哈希表完全适合内存。这意味着您无需担心为哈希聚合实现两阶段（分区、重新哈希）策略，而是可以假设所有聚合结果都可以驻留在内存中哈希表中。

**哈希聚集**



```c++
//哈希聚集
class SimpleAggregationHashTable {
 public:
  /**
   * Construct a new SimpleAggregationHashTable instance.
   * @param agg_exprs the aggregation expressions
   * @param agg_types the types of aggregations
   */
  //根据聚合表达式（COUNT(),AVE(),MN(),MAX(),SUM()）和
  SimpleAggregationHashTable(const std::vector<const AbstractExpression *> &agg_exprs,
                             const std::vector<AggregationType> &agg_types)
      : agg_exprs_{agg_exprs}, agg_types_{agg_types} {}

  /** @return The initial aggregrate value for this aggregation executor */
  AggregateValue GenerateInitialAggregateValue() {
    std::vector<Value> values{};
    for (const auto &agg_type : agg_types_) {
      switch (agg_type) {
        case AggregationType::CountAggregate:
          // Count starts at zero.
          values.emplace_back(ValueFactory::GetIntegerValue(0));
          break;
        case AggregationType::SumAggregate:
          // Sum starts at zero.
          values.emplace_back(ValueFactory::GetIntegerValue(0));
          break;
        case AggregationType::MinAggregate:
          // Min starts at INT_MAX.
          values.emplace_back(ValueFactory::GetIntegerValue(BUSTUB_INT32_MAX));
          break;
        case AggregationType::MaxAggregate:
          // Max starts at INT_MIN.
          values.emplace_back(ValueFactory::GetIntegerValue(BUSTUB_INT32_MIN));
          break;
      }
    }
    return {values};
  }

  /**
   * Combines the input into the aggregation result.
   * @param[out] result The output aggregate value
   * @param input The input value
   */
  void CombineAggregateValues(AggregateValue *result, const AggregateValue &input) {
    for (uint32_t i = 0; i < agg_exprs_.size(); i++) {
      switch (agg_types_[i]) {
        case AggregationType::CountAggregate:
          // Count increases by one.
          result->aggregates_[i] = result->aggregates_[i].Add(ValueFactory::GetIntegerValue(1));
          break;
        case AggregationType::SumAggregate:
          // Sum increases by addition.
          result->aggregates_[i] = result->aggregates_[i].Add(input.aggregates_[i]);
          break;
        case AggregationType::MinAggregate:
          // Min is just the min.
          result->aggregates_[i] = result->aggregates_[i].Min(input.aggregates_[i]);
          break;
        case AggregationType::MaxAggregate:
          // Max is just the max.
          result->aggregates_[i] = result->aggregates_[i].Max(input.aggregates_[i]);
          break;
      }
    }
  }

  /**
   * Inserts a value into the hash table and then combines it with the current aggregation.
   * @param agg_key the key to be inserted
   * @param agg_val the value to be inserted
   */
  void InsertCombine(const AggregateKey &agg_key, const AggregateValue &agg_val) {
    if (ht_.count(agg_key) == 0) {
      ht_.insert({agg_key, GenerateInitialAggregateValue()});
    }
    CombineAggregateValues(&ht_[agg_key], agg_val);
  }

  /** An iterator over the aggregation hash table */
  class Iterator {
   public:
    /** Creates an iterator for the aggregate map. */
    explicit Iterator(std::unordered_map<AggregateKey, AggregateValue>::const_iterator iter) : iter_{iter} {}

    /** @return The key of the iterator */
    const AggregateKey &Key() { return iter_->first; }

    /** @return The value of the iterator */
    const AggregateValue &Val() { return iter_->second; }

    /** @return The iterator before it is incremented */
    Iterator &operator++() {
      ++iter_;
      return *this;
    }

    /** @return `true` if both iterators are identical */
    bool operator==(const Iterator &other) { return this->iter_ == other.iter_; }

    /** @return `true` if both iterators are different */
    bool operator!=(const Iterator &other) { return this->iter_ != other.iter_; }

   private:
    /** Aggregates map */
    std::unordered_map<AggregateKey, AggregateValue>::const_iterator iter_;
  };

  /** @return Iterator to the start of the hash table */
  Iterator Begin() { return Iterator{ht_.cbegin()}; }

  /** @return Iterator to the end of the hash table */
  Iterator End() { return Iterator{ht_.cend()}; }

 private:
  /** The hash table is just a map from aggregate keys to aggregate values */
  std::unordered_map<AggregateKey, AggregateValue> ht_{};
  /** The aggregate expressions that we have */
  //聚集操作
  const std::vector<const AbstractExpression *> &agg_exprs_;
  /** The types of aggregations that we have */
  //聚集类别
  const std::vector<AggregationType> &agg_types_;
};

/**
 * AggregationExecutor executes an aggregation operation (e.g. COUNT, SUM, MIN, MAX)
 * over the tuples produced by a child executor.
 */
class AggregationExecutor : public AbstractExecutor {
 public:
  /**
   * Construct a new AggregationExecutor instance.
   * @param exec_ctx The executor context
   * @param plan The insert plan to be executed
   * @param child_executor The child executor from which inserted tuples are pulled (may be `nullptr`)
   */
  AggregationExecutor(ExecutorContext *exec_ctx, const AggregationPlanNode *plan,
                      std::unique_ptr<AbstractExecutor> &&child);

  /** Initialize the aggregation */
  void Init() override;

  /**
   * Yield the next tuple from the insert.
   * @param[out] tuple The next tuple produced by the insert
   * @param[out] rid The next tuple RID produced by the insert
   * @return `true` if a tuple was produced, `false` if there are no more tuples
   */
  bool Next(Tuple *tuple, RID *rid) override;

  /** @return The output schema for the aggregation */
  const Schema *GetOutputSchema() override { return plan_->OutputSchema(); };

  /** Do not use or remove this function, otherwise you will get zero points. */
  const AbstractExecutor *GetChildExecutor() const;

 private:
  /** @return The tuple as an AggregateKey */
  AggregateKey MakeAggregateKey(const Tuple *tuple) {
    std::vector<Value> keys;
    for (const auto &expr : plan_->GetGroupBys()) {
      keys.emplace_back(expr->Evaluate(tuple, child_->GetOutputSchema()));
    }
    return {keys};
  }

  /** @return The tuple as an AggregateValue */
  AggregateValue MakeAggregateValue(const Tuple *tuple) {
    std::vector<Value> vals;
    for (const auto &expr : plan_->GetAggregates()) {
      vals.emplace_back(expr->Evaluate(tuple, child_->GetOutputSchema()));
    }
    return {vals};
  }

 private:
  /** The aggregation plan node */
  const AggregationPlanNode *plan_;
  /** The child executor that produces tuples over which the aggregation is computed */
  std::unique_ptr<AbstractExecutor> child_;
  /** Simple aggregation hash table */
  SimpleAggregationHashTable aht_;
  /** Simple aggregation hash table iterator */
  SimpleAggregationHashTable::Iterator aht_iterator_;
};
```



```c++
AggregationExecutor::AggregationExecutor(ExecutorContext *exec_ctx, const AggregationPlanNode *plan,
                                         std::unique_ptr<AbstractExecutor> &&child)
    : AbstractExecutor(exec_ctx),
      plan_(plan),
      child_(move(child)),
      aht_(plan_->GetAggregates(), plan_->GetAggregateTypes()),
      aht_iterator_(aht_.Begin()) {}

void AggregationExecutor::Init() {
  child_->Init();
  Tuple tuple;
  RID rid;
  while (child_->Next(&tuple, &rid)) {
    aht_.InsertCombine(MakeAggregateKey(&tuple), MakeAggregateValue(&tuple));
  }
  aht_iterator_ = aht_.Begin();
}

bool AggregationExecutor::Next(Tuple *tuple, RID *rid) {
  if (aht_iterator_ == aht_.End()) {
    return false;
  }
  const AggregateKey &agg_key = aht_iterator_.Key();
  const AggregateValue &agg_val = aht_iterator_.Val();
  ++aht_iterator_;
  if (plan_->GetHaving() == nullptr ||
      plan_->GetHaving()->EvaluateAggregate(agg_key.group_bys_, agg_val.aggregates_).GetAs<bool>()) {
    std::vector<Value> ans;
    for (auto &col : plan_->OutputSchema()->GetColumns()) {
      ans.push_back(col.GetExpr()->EvaluateAggregate(agg_key.group_bys_, agg_val.aggregates_));
    }
    *tuple = Tuple(ans, plan_->OutputSchema());
    return true;
  }
  return Next(tuple, rid);
}

const AbstractExecutor *AggregationExecutor::GetChildExecutor() const { return child_.get(); }

```



#### 顺序扫描

不能简单的就将iter的tuple作为答案返回，因为可能上层只要求该tuple的一部分col。所以返回的是tuple的备份

SeqScan Executor中需要保存一个TableIterator对象作为私有成员。需要在构造函数中初始化这个对象。否则会因为这个对象中的悬空指针造成内存越界问题。

需要注意predicate可能为null，要对此进行判断，否则会有内存越界问题。

注意失败不能返回false，否则上层会误以为遍历结束

**顺序扫描是获取TableHeap中tuple的复制，而不是获取引用。这样做的好处在于可以及时释放TableHeap的锁，有利于减少并发访问的冲突。但是增加了存储开销。**

```c++
bool SeqScanExecutor::Next(Tuple *tuple, RID *rid) {
  if (iter_ == table_heap_->End()) {
    return false;
  }
  RID origin_rid = iter_->GetRid();
  const Schema *out_schema = plan_->OutputSchema();

  // 加锁
  LockManager *lock_manager = GetExecutorContext()->GetLockManager();
  Transaction *txn = GetExecutorContext()->GetTransaction();
  if (lock_manager != nullptr) {
    if (txn->GetIsolationLevel() != IsolationLevel::READ_UNCOMMITTED) {
      lock_manager->LockShared(txn, origin_rid);
    }
  }

  std::vector<Value> ans;
  int out_column_count = out_schema->GetColumnCount();
  ans.reserve(out_column_count);
  //根据out_schema输出一个指定的列
  for (int i = 0; i < out_column_count; i++) {
    //创造一个col需要调用colexpr->evaluate
    ans.push_back(out_schema->GetColumn(i).GetExpr()->Evaluate(
        &(*iter_), &(exec_ctx_->GetCatalog()->GetTable(plan_->GetTableOid())->schema_)));
  }
  /*
  for(auto &col:out_schema->GetColumns){
      ans.emplace_back(col.GetExpr->Evaluate(&(*iter_), &(exec_ctx_->GetCatalog()->GetTable(plan_->GetTableOid())->schema_)));
  }*/
  // 解锁,只要read_commit需要在这里解锁，repeatable_read是在commit阶段才解锁
  if (lock_manager != nullptr && txn->GetIsolationLevel() == IsolationLevel::READ_COMMITTED) {
    lock_manager->Unlock(txn, origin_rid);
  }

  ++iter_;

  Tuple temp_tuple(ans, out_schema);
  const AbstractExpression *predicate = plan_->GetPredicate();
  if (predicate == nullptr || predicate->Evaluate(&temp_tuple, out_schema).GetAs<bool>()) {
    *tuple = temp_tuple;
    *rid = origin_rid;
    return true;
  }
  return Next(tuple, rid);
}
```

**优化：**先判断符不符合谓词，而不必等到最后再判断。

```c++
bool SeqScanExecutor::Next(Tuple *tuple, RID *rid) {
  if (iter_ == table_heap_->End()) {
    return false;
  }
  *test_tuple=*iter;
  RID origin_rid = iter_->GetRid();
  const Schema *out_schema = plan_->OutputSchema();
  const AbstractExpression *predicate = plan_->GetPredicate();
  //如果这个tuple不符合谓词就跳过
  if (predicate != nullptr & !predicate->Evaluate(text_tuple, out_schema).GetAs<bool>()) {
    return Next(tuple, rid);
  }
  // 加锁
  LockManager *lock_manager = GetExecutorContext()->GetLockManager();
  Transaction *txn = GetExecutorContext()->GetTransaction();
  if (lock_manager != nullptr) {
    if (txn->GetIsolationLevel() != IsolationLevel::READ_UNCOMMITTED) {
      lock_manager->LockShared(txn, origin_rid);
    }
  }

  std::vector<Value> ans;
  int out_column_count = out_schema->GetColumnCount();
  ans.reserve(out_column_count);
  //根据out_schema输出一个指定的列
  for (int i = 0; i < out_column_count; i++) {
    //创造一个col需要调用colexpr->evaluate
    ans.push_back(out_schema->GetColumn(i).GetExpr()->Evaluate(
        &(*iter_), &(exec_ctx_->GetCatalog()->GetTable(plan_->GetTableOid())->schema_)));
  }
  /*
  for(auto &col:out_schema->GetColumns){
      ans.emplace_back(col.GetExpr->Evaluate(&(*iter_), &(exec_ctx_->GetCatalog()->GetTable(plan_->GetTableOid())->schema_)));
  }*/
  // 解锁,只要read_commit需要在这里解锁，repeatable_read是在commit阶段才解锁
  if (lock_manager != nullptr && txn->GetIsolationLevel() == IsolationLevel::READ_COMMITTED) {
    lock_manager->Unlock(txn, origin_rid);
  }

  ++iter_;

  Tuple temp_tuple(ans, out_schema);
  *tuple = temp_tuple;
  *rid = origin_rid;
  
  return true;
}
```



#### 增删改查

Delete需要删除tuple并在**index中删除index entry**。与更新一样，要删除的元组是从子执行器（例如实例）中提取的。删除执行器SeqScanExecutor

您可能会假设，始终位于它出现的查询计划的根位置。不应修改其结果集。DeleteExecutorDeleteExecutor

提示：您只需要从子执行器获取并调用TableHeap:：MarkDelete（）即可有效地删除元组。所有删除将在事务提交时应用。ID

提示：您需要更新删除元组的表的所有索引。有关详细信息，请参阅下面的索引更新部分。

**注：**增删时一定要追踪操作了哪些数据，否则可能会重复操作

例子：

从索引最小值开始往上遍历，Andy的工资是1099，这时我们扫到Andy，更改了它的数据并更新了它的索引（1199），继续遍历，由于Andy的工资增加了，它的索引位置也后移了，所以会再被更新一遍！！

<img src="数据库设计与实现/image-20230116210805238.png" alt="image-20230116210805238" style="zoom:67%;" />

**注：**在获取index时，要注意可能这个TableHeap并没有相关的index。这时候就要捕获并处理访问catalog时产生的std::out_of_range error。在捕获error时注意要写成引用( catch (std::out_of_range &e) )，才能通过clang check。

```c++

bool DeleteExecutor::Next([[maybe_unused]] Tuple *tuple, RID *rid) {
  LockManager *lock_mgr = GetExecutorContext()->GetLockManager();
  Transaction *txn = GetExecutorContext()->GetTransaction();
  //对rid加锁（共享锁或独占锁），因为要对事务进行更改所以上独占锁
  while (child_executor_->Next(tuple, rid)) {
    if (txn->IsSharedLocked(*rid)) {
      if (!lock_mgr->LockUpgrade(txn, *rid)) {
        throw TransactionAbortException(txn->GetTransactionId(), AbortReason::DEADLOCK);
      }
    } else {
      if (!lock_mgr->LockExclusive(txn, *rid)) {
        throw TransactionAbortException(txn->GetTransactionId(), AbortReason::DEADLOCK);
      }
    }
	//在slotpage上标记删除
    if (!table_heap_->MarkDelete(*rid, exec_ctx_->GetTransaction())) {
      LOG_DEBUG("Delete failed");
      return false;
    }
	//在indexpage上修改
    for (const auto &index : exec_ctx_->GetCatalog()->GetTableIndexes(table_info_->name_)) {
      index->index_->DeleteEntry(
          tuple->KeyFromTuple(table_info_->schema_, *index->index_->GetKeySchema(), index->index_->GetKeyAttrs()), *rid,
          exec_ctx_->GetTransaction());
      //记录操作，用于事务失败时回滚
      txn->GetIndexWriteSet()->emplace_back(
          IndexWriteRecord(*rid, table_info_->oid_, WType::DELETE, *tuple, index->index_oid_, exec_ctx_->GetCatalog()));
	  //如果隔离级别是读取已提交，解锁
      if (txn->GetIsolationLevel() == IsolationLevel::READ_COMMITTED) {
        if (!lock_mgr->Unlock(txn, *rid)) {
          throw TransactionAbortException(txn->GetTransactionId(), AbortReason::DEADLOCK);
        }
      }
    }
  }

  return false;
}
```

**Delete2.0**

1.0是以tuple为单位，每next一次就执行一次

可以先将下层返回的tuple收集起来，再一次性处理

```c++
bool DeleteExecutor::Next([[maybe_unused]] Tuple *tuple, RID *rid) {
  std::vector<std::pair<Tuple, RID>> delete_tuples;
  //先将所有tuple先收集起来统一处理
  try {
    Tuple temp_tuple;
    RID temp_rid;
    while (child_executor_->Next(&temp_tuple, &temp_rid)) {
      delete_tuples.emplace_back(std::pair<Tuple, RID>(temp_tuple, temp_rid));
    }
  } catch (Exception &e) {
    throw Exception(ExceptionType::UNKNOWN_TYPE, "Insert child execute error.");
    return false;
  }
  LockManager *lock_manager = GetExecutorContext()->GetLockManager();
  Transaction *txn = GetExecutorContext()->GetTransaction();

  for (auto &tuple_t : delete_tuples) {
    // DeleteWithIndex(tuple_t.first, tuple_t.second);
    // 加锁
    if (lock_manager != nullptr) {
      if (txn->IsSharedLocked(tuple_t.second)) {
        lock_manager->LockUpgrade(txn, tuple_t.second);
      } else {
        lock_manager->LockExclusive(txn, tuple_t.second);
      }
    }
    bool ok = table_heap_->MarkDelete(tuple_t.second, exec_ctx_->GetTransaction());

    if (ok) {
      for (auto &indexinfo : catalog_->GetTableIndexes(table_info_->name_)) {
        indexinfo->index_->DeleteEntry(
            tuple_t.first.KeyFromTuple(table_info_->schema_, *(indexinfo->index_->GetKeySchema()),
                                       indexinfo->index_->GetKeyAttrs()),
            tuple_t.second, exec_ctx_->GetTransaction());
        // 更新索引写集
        IndexWriteRecord index_write_record(tuple_t.second, table_info_->oid_, WType::DELETE, tuple_t.first,
                                            indexinfo->index_oid_, catalog_);
        txn->GetIndexWriteSet()->emplace_back(index_write_record);
      }
    }

    //如果不是可重复读
    if (txn->GetIsolationLevel() != IsolationLevel::REPEATABLE_READ && lock_manager != nullptr) {
      lock_manager->Unlock(txn, tuple_t.second);
    }
  }
  return false;
}
```



**Update**

**注意防止可能会对同意个tuple重复操作！！！**

我的方法是先将所有要更改的tuple收集起来，再统一处理。

```c++

bool UpdateExecutor::Next([[maybe_unused]] Tuple *tuple, RID *rid) {
  std::vector<std::pair<Tuple, RID>> update_tuples;
  try {
    Tuple temp_tuple;
    RID temp_rid;
    while (child_executor_->Next(&temp_tuple, &temp_rid)) {
      update_tuples.emplace_back(std::pair<Tuple, RID>(temp_tuple, temp_rid));
    }
  } catch (Exception &e) {
    throw Exception(ExceptionType::UNKNOWN_TYPE, "Insert child execute error.");
    return false;
  }

  LockManager *lock_manager = GetExecutorContext()->GetLockManager();
  Transaction *txn = GetExecutorContext()->GetTransaction();

  for (auto &tuple_t : update_tuples) {
    // UpdateWithIndex(tuple_t.first, tuple_t.second);

    // 加锁
    if (lock_manager != nullptr) {
      if (txn->IsSharedLocked(tuple_t.second)) {
        lock_manager->LockUpgrade(txn, tuple_t.second);
      } else {
        lock_manager->LockExclusive(txn, tuple_t.second);
      }
    }

    Tuple new_tuple = GenerateUpdatedTuple(tuple_t.first);
    bool ok = table_heap_->UpdateTuple(new_tuple, tuple_t.second, exec_ctx_->GetTransaction());

    if (ok) {
      //该table对应的哈希索引
      for (auto &indexinfo : catalog_->GetTableIndexes(table_info_->name_)) {
        // 不要求索引并发处理，只更新索引写集就可
        //将原来的索引删掉，再插入新的索引
        indexinfo->index_->DeleteEntry(
            tuple_t.first.KeyFromTuple(table_info_->schema_, *(indexinfo->index_->GetKeySchema()),
                                       indexinfo->index_->GetKeyAttrs()),
            tuple_t.second, exec_ctx_->GetTransaction());
        indexinfo->index_->InsertEntry(
            new_tuple.KeyFromTuple(table_info_->schema_, *(indexinfo->index_->GetKeySchema()),
                                   indexinfo->index_->GetKeyAttrs()),
            tuple_t.second, exec_ctx_->GetTransaction());
        // 添加索引写集
        IndexWriteRecord index_write_record(tuple_t.second, table_info_->oid_, WType::UPDATE, new_tuple,
                                            indexinfo->index_oid_, catalog_);
        index_write_record.old_tuple_ = tuple_t.first;
        txn->GetIndexWriteSet()->emplace_back(index_write_record);
      }
    }
    // 解锁
    if (txn->GetIsolationLevel() != IsolationLevel::REPEATABLE_READ && lock_manager != nullptr) {
      lock_manager->Unlock(txn, tuple_t.second);
    }
  }
  return false;
}

// void UpdateExecutor::UpdateWithIndex(Tuple &tuple, RID &rid) {
//   Tuple new_tuple = GenerateUpdatedTuple(tuple);
//   bool ok = table_heap_->UpdateTuple(new_tuple, rid, exec_ctx_->GetTransaction());
//   if (ok) {
//     for (auto &indexinfo : catalog_->GetTableIndexes(table_info_->name_)) {
//       indexinfo->index_->DeleteEntry(tuple.KeyFromTuple(table_info_->schema_, *(indexinfo->index_->GetKeySchema()),
//                                                         indexinfo->index_->GetKeyAttrs()),
//                                      rid, exec_ctx_->GetTransaction());
//       indexinfo->index_->InsertEntry(new_tuple.KeyFromTuple(table_info_->schema_,
//       *(indexinfo->index_->GetKeySchema()),
//                                                             indexinfo->index_->GetKeyAttrs()),
//                                      rid, exec_ctx_->GetTransaction());
//     }
//   }
// }
//根据提供的tuple生成一个用来更新的tuple
Tuple UpdateExecutor::GenerateUpdatedTuple(const Tuple &src_tuple) {
  const auto &update_attrs = plan_->GetUpdateAttr();
  Schema schema = table_info_->schema_;
  uint32_t col_count = schema.GetColumnCount();
  std::vector<Value> values;
  for (uint32_t idx = 0; idx < col_count; idx++) {
    //如果该col不再更新col中，不动他
    if (update_attrs.find(idx) == update_attrs.cend()) {
      values.emplace_back(src_tuple.GetValue(&schema, idx));
    } else {  //否则将改col改成要更新的col
      const UpdateInfo info = update_attrs.at(idx);
      Value val = src_tuple.GetValue(&schema, idx);
      //col是要加值还是要重设值
      switch (info.type_) {
        case UpdateType::Add:
          values.emplace_back(val.Add(ValueFactory::GetIntegerValue(info.update_val_)));
          break;
        case UpdateType::Set:
          values.emplace_back(ValueFactory::GetIntegerValue(info.update_val_));
          break;
      }
    }
  }
  return Tuple{values, &schema};
}

```



**Insert**

我们需要支持两种不同的插入模式，一种是从 child_executor 获取 tuple 来做插入，另一种是直接插入 tuple。并且这两种插入不仅需要修改表本身数据，还要对索引进行相应的插入

```c++

InsertExecutor::InsertExecutor(ExecutorContext *exec_ctx, const InsertPlanNode *plan,
                               std::unique_ptr<AbstractExecutor> &&child_executor)
    : AbstractExecutor(exec_ctx), plan_(plan), table_heap_(nullptr), child_executor_(move(child_executor)) {}

void InsertExecutor::Init() {
  table_heap_ = exec_ctx_->GetCatalog()->GetTable(plan_->TableOid())->table_.get();
  catalog_ = exec_ctx_->GetCatalog();
  tableinfo_ = catalog_->GetTable(plan_->TableOid());
}

bool InsertExecutor::Next([[maybe_unused]] Tuple *tuple, RID *rid) {
    std::vector<Tuple> insert_tuples_;
    if (plan_->IsRawInsert()) {
    for (const auto &row_value : plan_->RawValues()) {
      insert_tuples_.emplace_back(Tuple(row_value, &(tableinfo_->schema_)));
    }
  } else {
    child_executor_->Init();
    Tuple temp_tuple;
    RID temp_rid;
    while (child_executor_->Next(&temp_tuple, &temp_rid)) {
      insert_tuples_.emplace_back(temp_tuple);
    }
  }
  
  for(auto &insert_tuple:insert_tuples_){
      if (!table_heap_->InsertTuple(*tuple, rid, exec_ctx_->GetTransaction())) {
    	LOG_DEBUG("INSERT FAIL");
    	return false;
  		}

  	  Transaction *txn = GetExecutorContext()->GetTransaction();
  	  LockManager *lock_mgr = GetExecutorContext()->GetLockManager();

   	  if (txn->IsSharedLocked(*rid)) {
    	if (!lock_mgr->LockUpgrade(txn, *rid)) {
      		throw TransactionAbortException(txn->GetTransactionId(), AbortReason::DEADLOCK);
    	}
  	  } else {
      if (!lock_mgr->LockExclusive(txn, *rid)) {
      	throw TransactionAbortException(txn->GetTransactionId(), AbortReason::DEADLOCK);
    	}
  	  }

  	  for (const auto &index : catalog_->GetTableIndexes(table_info_->name_)) {
    	index->index_->InsertEntry(
        	tuple->KeyFromTuple(table_info_->schema_, *index->index_->GetKeySchema(), index->index_-				>GetKeyAttrs()), *rid,exec_ctx_->GetTransaction());
  	  }

  	  if (txn->GetIsolationLevel() != IsolationLevel::REPEATABLE_READ) {
    	if (!lock_mgr->Unlock(txn, *rid)) {
      	throw TransactionAbortException(txn->GetTransactionId(), AbortReason::DEADLOCK);
    	}
  	  }
  }

}

// 注意写操作的时候要更新事务的写集，以及索引写集，以为了undo
void InsertExecutor::InsertIntoTableWithIndex(Tuple *tuple) {
  RID new_rid;
  // 有个疑问没解决，插入时因为无法拿到rid没法加锁，但是在后面更新索引的时候，需要加锁，那怎么保证的整个过程是原子性的呢？
  // 例如在table_heap_->InsertTuple，与下面加锁前有对tuple的update操作，那下面索引与更新够的值对应不上了
  bool okinsert = table_heap_->InsertTuple(
      *tuple, &new_rid, exec_ctx_->GetTransaction());  // table_write_set由table_heap_->InsertTuple来维护

  // 加锁
  LockManager *lock_manager = GetExecutorContext()->GetLockManager();
  Transaction *txn = GetExecutorContext()->GetTransaction();
  if (lock_manager != nullptr) {
    if (txn->IsSharedLocked(new_rid)) {
      lock_manager->LockUpgrade(txn, new_rid);
    } else {
      lock_manager->LockExclusive(txn, new_rid);
    }
  }

  if (okinsert) {
    for (auto &indexinfo : catalog_->GetTableIndexes(tableinfo_->name_)) {
      indexinfo->index_->InsertEntry(tuple->KeyFromTuple(tableinfo_->schema_, *(indexinfo->index_->GetKeySchema()),indexinfo->index_->GetKeyAttrs()),new_rid, exec_ctx_->GetTransaction());
      txn->GetIndexWriteSet()->emplace_back(
          IndexWriteRecord(new_rid, tableinfo_->oid_, WType::INSERT, *tuple, indexinfo->index_oid_, catalog_));
    }
  }

  if (txn->GetIsolationLevel() != IsolationLevel::REPEATABLE_READ && lock_manager != nullptr) {
    lock_manager->Unlock(txn, new_rid);
  }
}
```



#### LoopJoin

NestedLoopJoinExecutor实现了一个基本的嵌套循环连接，它将两个子执行器的元组组合在一起。

这个执行器实现简单嵌套循环连接算法。也就是说，对于联接外部表中的每个元组，您应该考虑联接内部表中的每一个元组，如果满足联接谓词，则发出一个输出元组。

在嵌套循环连接计划节点中使用谓词。特别是看一下AbstractExpression:：EvaluateJoin，它处理左元组和右元组及其各自的模式。注意，这将返回一个Value，您可以调用GetAs＜bool＞（）将结果作为本机C++布尔类型进行计算。

```c++
	case PlanType::NestedLoopJoin: {
      auto nested_loop_join_plan = dynamic_cast<const NestedLoopJoinPlanNode *>(plan);
      //scan_plan1
      auto left = ExecutorFactory::CreateExecutor(exec_ctx, nested_loop_join_plan->GetLeftPlan());
      //scan_plan2
      auto right = ExecutorFactory::CreateExecutor(exec_ctx, nested_loop_join_plan->GetRightPlan());
      return std::make_unique<NestedLoopJoinExecutor>(exec_ctx, nested_loop_join_plan, std::move(left),
                                                      std::move(right));
    }
```



```c++
NestedLoopJoinExecutor::NestedLoopJoinExecutor(ExecutorContext *exec_ctx, const NestedLoopJoinPlanNode *plan, std::unique_ptr<AbstractExecutor> &&left_executor,std::unique_ptr<AbstractExecutor> &&right_executor)
    : AbstractExecutor(exec_ctx),
      plan_(plan),
      left_executor_(move(left_executor)),
      right_executor_(move(right_executor)),
      st_(0) {}

void NestedLoopJoinExecutor::Init() {
  Tuple left_tuple;
  Tuple right_tuple;
  RID left_rid;
  RID right_rid;
  left_executor_->Init();
  //bug:不能在外面right_executor_->Init();否则内层一次循环就到头了，因为right的iter_没法归位置
  while (left_executor_->Next(&left_tuple, &left_rid)) {
    right_executor_->Init();
    while (right_executor_->Next(&right_tuple, &right_rid)) {
      const Schema *output_schema = plan_->OutputSchema();
      //如果这两列满足条件
      if (plan_->Predicate() == nullptr || plan_->Predicate()->EvaluateJoin(&left_tuple, left_executor_->GetOutputSchema(),&right_tuple, right_executor_->GetOutputSchema()).GetAs<bool>()) {
        std::vector<Value> temp_ans;
        //将两tuple连接起来
        for (auto &column : output_schema->GetColumns()) {
          Value temp_v = column.GetExpr()->EvaluateJoin(&left_tuple, left_executor_->GetOutputSchema(), &right_tuple,right_executor_->GetOutputSchema());
          temp_ans.push_back(temp_v);
        }
        result_.emplace_back(Tuple(temp_ans, output_schema));
      }
    }
  }
}

bool NestedLoopJoinExecutor::Next(Tuple *tuple, RID *rid) {
  if (st_ == result_.size()) {
    return false;
  }
  *tuple = result_[st_];
  *rid = result_[st_].GetRid();
  ++st_;
  return true;
}
```



#### Hashjoin

hashjoin的构造函数和上面一样，左右子执行器都是seq_scan

```c++
	// Create a new hash join executor
    case PlanType::HashJoin: {
      auto hash_join_plan = dynamic_cast<const HashJoinPlanNode *>(plan);
      //scan_exe1
      auto left = ExecutorFactory::CreateExecutor(exec_ctx, hash_join_plan->GetLeftPlan());
      //scan_exe2
      auto right = ExecutorFactory::CreateExecutor(exec_ctx, hash_join_plan->GetRightPlan());
      return std::make_unique<HashJoinExecutor>(exec_ctx, hash_join_plan, std::move(left),std::move(right));
    }
```

GetLeftJoinKey（）和GetRightJoinKey（）返回左右两表的hash（key）

**仿照Aggr构造hashtable**

```c++
namespace bustub {
struct HashKey {
  Value column_key_;

  bool operator==(const HashKey &other) const {
    return column_key_.CompareEquals(other.column_key_) == CmpBool::CmpTrue;
  }
};
//一个key可以对应多个Tuple
struct HashValue {
  std::vector<Tuple> tuple_;
};
}  // namespace bustub

// 模仿AggregateKey来写
namespace std {

template <>
/** Implements std::hash on HashKey */
struct hash<bustub::HashKey> {
  std::size_t operator()(const bustub::HashKey &agg_key) const {
    size_t curr_hash = 0;
    auto &key = agg_key.column_key_;
    if (!key.IsNull()) {
      curr_hash = bustub::HashUtil::CombineHashes(curr_hash, bustub::HashUtil::HashValue(&key));
    }
    return curr_hash;
  }
};

}  // namespace std

namespace bustub {

class HashTable {
 public:
  void Insert(Value& hkey,std::vector<Tuple> &tuple) {
    if (!ht_.count(hkey)) {
        HashValue value(tuple);
        ht_.insert(value);
    }
  }
 private:
  /** The hash table is just a map from aggregate keys to aggregate values */
  std::unordered_map<HashKey, HashValue> ht_{};
};
}
```



```c++
void HashJoinExecutor::Init() {
  left_child_->Init();
  right_child_->Init();
  Tuple left_tuple;
  RID left_rid;
  // 对左表构建哈希表
  while (left_child_->Next(&left_tuple, &left_rid)) {
    HashKey hashkey;
    hashkey.column_key_ = plan_->LeftJoinKeyExpression()->Evaluate(&left_tuple, left_child_->GetOutputSchema());
    if (map_.count(hashkey) != 0) {
      map_[hashkey].emplace_back(left_tuple);
    } else {
      map_[hashkey] = std::vector{left_tuple};
    }
  }
  Tuple right_tuple;
  RID right_rid;
  // hash Join
  while (right_child_->Next(&right_tuple, &right_rid)) {
    HashKey hashkey;
    hashkey.column_key_ = plan_->RightJoinKeyExpression()->Evaluate(&right_tuple, right_child_->GetOutputSchema
    //如果能在哈希表中查到。
    if (map_.count(hashkey) != 0) {
      std::vector<Tuple> &temp = map_[hashkey];
      for (auto &left_tuple_temp : temp) {
        std::vector<Value> output;
        //join后tuple要得到的col
        for (const auto &col : plan_->OutputSchema()->GetColumns()) {
          output.push_back(col.GetExpr()->EvaluateJoin(&left_tuple_temp, left_child_->GetOutputSchema(), &right_tuple,right_child_->GetOutputSchema()));
        }
        result_.emplace_back(Tuple(output, plan_->OutputSchema()));
      }
    }
  }
}

bool HashJoinExecutor::Next(Tuple *tuple, RID *rid) {
  if (st_ == result_.size()) {
    return false;
  }
  *tuple = result_[st_];
  *rid = result_[st_].GetRid();
  ++st_;
  return true;
}
```



#### Aggr

聚合用于将来自单个子执行器的多个元组结果组合为单个元组。在这个项目中，我们要求您实现COUNT、SUM、MIN和MAX。

我们为您提供了一个SimpleAggregationHashTable。我们强烈建议您使用这个哈希表。

**AggrHashtable**

还记得之前 如果是聚集起来是为了计算 的问题吗。我们的答案是再开一列value用来存储记录中间结果。

在hashtable中，aggrvalue（vector<value> ans）就是承担这个作用。

根据不同的操作类型，value[i]存储对应的中间结果。比如aggr_type[0]对应的是min[]操作，那么value[0]存储的就是按照Gorup（Aggrkey）分组后的最小值。

aggrkey（vector<value > Group）分组后的colvalue 例如：select Min （）Count()  Group By id，

Group[0]=1,ans[0]=2, ans[1]=3  .id=1的tuple中最小的数是2，id=1的tuple有三个。。。

,Group[1]=3..... ans[]....

```c++
void AggregationExecutor::Init() {
  child_->Init();
  Tuple tuple;
  RID rid;
  while (child_->Next(&tuple, &rid)) {
    aht_.InsertCombine(MakeAggregateKey(&tuple), MakeAggregateValue(&tuple));
  }
  aht_iterator_ = aht_.Begin();
}

bool AggregationExecutor::Next(Tuple *tuple, RID *rid) {
  if (aht_iterator_ == aht_.End()) {
    return false;
  }
  const AggregateKey &agg_key = aht_iterator_.Key();
  const AggregateValue &agg_val = aht_iterator_.Val();
  ++aht_iterator_;
  //满不满足谓词条件
  if (plan_->GetHaving() == nullptr ||
      plan_->GetHaving()->EvaluateAggregate(agg_key.group_bys_, agg_val.aggregates_).GetAs<bool>()) {
    std::vector<Value> ans;
    for (auto &col : plan_->OutputSchema()->GetColumns()) {
        //我们要的是Group还是mncs
      ans.push_back(col.GetExpr()->EvaluateAggregate(agg_key.group_bys_, agg_val.aggregates_));
    }
    *tuple = Tuple(ans, plan_->OutputSchema());
    return true;
  }
  return Next(tuple, rid);
}

const AbstractExecutor *AggregationExecutor::GetChildExecutor() const { return child_.get(); }
```



### 表达器

Expression以树的形式递归地表示一个表达式。Expression共包含Const、Comparison、Column、Aggregation四种类型，分别用于不同的场合。运行Expression->Evaluate来执行相应谓词的操作

<img src="数据库设计与实现/image-20230113221701023.png" alt="image-20230113221701023" style="zoom:80%;" />

Expression不支持AND/OR，也不支持四则运算。只支持最基本的Comparison类型。

Const Expression最简单，永远返回一个常数。

Column Expression接受一个tuple做参数，返回这个tuple中特定column处的值。此外，Column Expression还用在Column类中，用于实现projection。

Aggregate Expression既可以表示一个GroupBy值(如Col2)，也可以表示一个Aggregation值（如Max(Col1)、Sum(Col2)等）。

Const、Column、Aggregation 三种Expression负责给Comparison Expression提供操作数。

```c++

  const Schema *MakeOutputSchema(const std::vector<std::pair<std::string, const AbstractExpression *>> &exprs) {
    std::vector<Column> cols;
    cols.reserve(exprs.size());
    for (const auto &input : exprs) {
      if (input.second->GetReturnType() != TypeId::VARCHAR) {
        cols.emplace_back(input.first, input.second->GetReturnType(), input.second);
      } else {
        cols.emplace_back(input.first, input.second->GetReturnType(), MAX_VARCHAR_SIZE, input.second);
      }
    }
    allocated_output_schemas_.emplace_back(std::make_unique<Schema>(cols));
    return allocated_output_schemas_.back().get();
  }

```



-   ColumnValueExpression

列表达式接受一个tuple做参数，返回这个tuple中特定column处的值或join两个table中相同的col。用于获取特定的col

常用他的返回值来创建新tuple

```c++
  //SELECT col_a, col_b
  auto *col_a = MakeColumnValueExpression(schema, 0, "colA");
  auto *col_b = MakeColumnValueExpression(schema, 0, "colB");
  auto *out_schema = MakeOutputSchema({{"colA", col_a}, {"colB", col_b}});
```

```c++

  const AbstractExpression *MakeColumnValueExpression(const Schema &schema, uint32_t tuple_idx,
                                                      const std::string &col_name) {
    uint32_t col_idx = schema.GetColIdx(col_name);
    auto col_type = schema.GetColumn(col_idx).GetType();
    allocated_exprs_.emplace_back(std::make_unique<ColumnValueExpression>(tuple_idx, col_idx, col_type));
    return allocated_exprs_.back().get();
  }
```



```c++
class ColumnValueExpression : public AbstractExpression {
 public:
  /**
   * ColumnValueExpression is an abstraction around "Table.member" in terms of indexes.
   * @param tuple_idx {tuple index 0 = left side of join, tuple index 1 = right side of join}
   * @param col_idx the index of the column in the schema
   * @param ret_type the return type of the expression
   */
  ColumnValueExpression(uint32_t tuple_idx, uint32_t col_idx, TypeId ret_type)
      : AbstractExpression({}, ret_type), tuple_idx_{tuple_idx}, col_idx_{col_idx} {}

  Value Evaluate(const Tuple *tuple, const Schema *schema) const override { return tuple->GetValue(schema, col_idx_); }

  Value EvaluateJoin(const Tuple *left_tuple, const Schema *left_schema, const Tuple *right_tuple,
                     const Schema *right_schema) const override {
    return tuple_idx_ == 0 ? left_tuple->GetValue(left_schema, col_idx_)
                           : right_tuple->GetValue(right_schema, col_idx_);
  }

  Value EvaluateAggregate(const std::vector<Value> &group_bys, const std::vector<Value> &aggregates) const override {
    BUSTUB_ASSERT(false, "Aggregation should only refer to group-by and aggregates.");
  }

  uint32_t GetTupleIdx() const { return tuple_idx_; }
  uint32_t GetColIdx() const { return col_idx_; }

 private:
  /** Tuple index 0 = left side of join, tuple index 1 = right side of join */
  uint32_t tuple_idx_;
  /** Column index refers to the index within the schema of the tuple, e.g. schema {A,B,C} has indexes {0,1,2} */
  uint32_t col_idx_;
};
```



- ConstantValueExpression

永远返回一个常量value

```c++
class ConstantValueExpression : public AbstractExpression {
 public:
  /** Creates a new constant value expression wrapping the given value. */
  explicit ConstantValueExpression(const Value &val) : AbstractExpression({}, val.GetTypeId()), val_(val) {}

  Value Evaluate(const Tuple *tuple, const Schema *schema) const override { return val_; }

  Value EvaluateJoin(const Tuple *left_tuple, const Schema *left_schema, const Tuple *right_tuple,
                     const Schema *right_schema) const override {
    return val_;
  }

  Value EvaluateAggregate(const std::vector<Value> &group_bys, const std::vector<Value> &aggregates) const override {
    return val_;
  }

 private:
  Value val_;
};
```



- AggregateValueExpression

Aggregate Expression既可以表示一个GroupBy值(如Col2)，也可以表示一个Aggregation值（如Max(Col1)、Sum(Col2)等）。

```c++
	//SELECT COUNT(col_a), SUM(col_a), min(col_a), max(col_a)
	const AbstractExpression *count_a = MakeAggregateValueExpression(false, 0);
    const AbstractExpression *sum_a = MakeAggregateValueExpression(false, 1);
    const AbstractExpression *min_a = MakeAggregateValueExpression(false, 2);
    const AbstractExpression *max_a = MakeAggregateValueExpression(false, 3);
```

```c++
 const AbstractExpression *MakeAggregateValueExpression(bool is_group_by_term, uint32_t term_idx) {
    allocated_exprs_.emplace_back(
        std::make_unique<AggregateValueExpression>(is_group_by_term, term_idx, TypeId::INTEGER));
    return allocated_exprs_.back().get();
  }
```



```c++

class AggregateValueExpression : public AbstractExpression {
 public:
  /**
   * Creates a new AggregateValueExpression.
   * @param is_group_by_term true if this is a group by
   * @param term_idx the index of the term
   * @param ret_type the return type of the aggregate value expression
   */
  AggregateValueExpression(bool is_group_by_term, uint32_t term_idx, TypeId ret_type)
      : AbstractExpression({}, ret_type), is_group_by_term_{is_group_by_term}, term_idx_{term_idx} {}

  /** Invalid operation for `AggregateValueExpression` */
  Value Evaluate(const Tuple *tuple, const Schema *schema) const override {
    UNREACHABLE("Aggregation should only refer to group-by and aggregates.");
  }

  /** Invalid operation for `AggregateValueExpression` */
  Value EvaluateJoin(const Tuple *left_tuple, const Schema *left_schema, const Tuple *right_tuple,
                     const Schema *right_schema) const override {
    UNREACHABLE("Aggregation should only refer to group-by and aggregates.");
  }

  /**
   * Returns the value obtained by evaluating the aggregates.
   * @param group_bys The group by values
   * @param aggregates The aggregate values
   * @return The value obtained by checking the aggregates and group-bys
   */
  Value EvaluateAggregate(const std::vector<Value> &group_bys, const std::vector<Value> &aggregates) const override {
    return is_group_by_term_ ? group_bys[term_idx_] : aggregates[term_idx_];
  }

 private:
  /** The flag indicating if this expression is a group-by term */
  bool is_group_by_term_;
  /** The index of the term in the collection of aggregates */
  uint32_t term_idx_;
};
```



- ComparisonExpression

ComparisonExpression对col，aggr，cont的返回值（value）做相应谓词检测。

```c++
//WHERE col_a < 500
auto *predicate = MakeComparisonExpression(col_a, const500, ComparisonType::LessThan);
```

```c++
  const AbstractExpression *MakeComparisonExpression(const AbstractExpression *lhs, const AbstractExpression *rhs, ComparisonType comp_type) {
    allocated_exprs_.emplace_back(std::make_unique<ComparisonExpression>(lhs, rhs, comp_type));
    return allocated_exprs_.back().get();
  }

```



```c++

class ComparisonExpression : public AbstractExpression {
 public:
  /** Creates a new comparison expression representing (left comp_type right). */
  ComparisonExpression(const AbstractExpression *left, const AbstractExpression *right, ComparisonType comp_type)
      : AbstractExpression({left, right}, TypeId::BOOLEAN), comp_type_{comp_type} {}

  Value Evaluate(const Tuple *tuple, const Schema *schema) const override {
    Value lhs = GetChildAt(0)->Evaluate(tuple, schema);
    Value rhs = GetChildAt(1)->Evaluate(tuple, schema);
    return ValueFactory::GetBooleanValue(PerformComparison(lhs, rhs));
  }

  Value EvaluateJoin(const Tuple *left_tuple, const Schema *left_schema, const Tuple *right_tuple,
                     const Schema *right_schema) const override {
    Value lhs = GetChildAt(0)->EvaluateJoin(left_tuple, left_schema, right_tuple, right_schema);
    Value rhs = GetChildAt(1)->EvaluateJoin(left_tuple, left_schema, right_tuple, right_schema);
    return ValueFactory::GetBooleanValue(PerformComparison(lhs, rhs));
  }

  Value EvaluateAggregate(const std::vector<Value> &group_bys, const std::vector<Value> &aggregates) const override {
    Value lhs = GetChildAt(0)->EvaluateAggregate(group_bys, aggregates);
    Value rhs = GetChildAt(1)->EvaluateAggregate(group_bys, aggregates);
    return ValueFactory::GetBooleanValue(PerformComparison(lhs, rhs));
  }

 private:
  CmpBool PerformComparison(const Value &lhs, const Value &rhs) const {
    switch (comp_type_) {
      case ComparisonType::Equal:
        return lhs.CompareEquals(rhs);
      case ComparisonType::NotEqual:
        return lhs.CompareNotEquals(rhs);
      case ComparisonType::LessThan:
        return lhs.CompareLessThan(rhs);
      case ComparisonType::LessThanOrEqual:
        return lhs.CompareLessThanEquals(rhs);
      case ComparisonType::GreaterThan:
        return lhs.CompareGreaterThan(rhs);
      case ComparisonType::GreaterThanOrEqual:
        return lhs.CompareGreaterThanEquals(rhs);
      default:
        BUSTUB_ASSERT(false, "Unsupported comparison type.");
    }
  }

  std::vector<const AbstractExpression *> children_;
  ComparisonType comp_type_;
};
```







### 任务器

**1.从顶向下**

从根节点开始拉去子节点的数据，从根节点的函数开始调用

**2.从底向上**

从叶子节点开始并将叶子节点的数据上传给父节点，（对控制pipelines的caches/registers更友好.）



## 早物化模型

![image-20230107022028542](数据库设计与实现/image-20230107022028542.png)

**优点：适用于事务型（点查询）**



## 矢量模型

适用于OLAP，因为函数调用和中间结果集的大小更符合OLAP的特性。更适合SIMD指令集（高并行）。

![image-20230107022324255](数据库设计与实现/image-20230107022324255.png)





## 并发控制

